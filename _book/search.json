[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "공부하는 언론인을 위한 R기반 데이터 저널리즘",
    "section": "",
    "text": "서문\n저널리즘이 위기라는 이야기가 들려온지 벌써 십수년이 지났습니다. 그간 언론은 디지털화, 소비자 컨텐츠 발굴 등 여러 혁신을 시도해 보았지만, 많은 시도들이 인터넷의 정보 유통 구조 변화를 쫓는 방식으로 귀결되면서, 미디어가 새로운 자생력을 얻는데 이르지 못하고, 플랫폼 기업들에게 수익 구조를 내맡겨야 하는 결과를 피하지 못했습니다. 그 때문에 해외의 많은 언론사들은 최근 미디어의 본질인 독보적인 콘텐츠의 생산과 이를 통한 독자적인 수익 구조를 추구하는 방식으로 회귀하는 경향을 보이고 있습니다.\n독자적 수익을 창출할 수 있는 독보적 컨텐츠의 생산. 이것은 산업으로서의 저널리즘의 본질이면서도, 어쩌면 그간 이어온 한국의 미디어 혁신에서 가장 간과되었던 것들 중 하나입니다. 누구나 취재와 출판, 유통이 가능한 시대에 독보적 컨텐츠는 어떻게 가능하고, 보도의 전문성은 어떻게 확보될 수 있을까요? 데이터 저널리즘은 그 대답 중 하나 입니다. 큰 자본력과 언론 조직을 보유하고 있는 리거시 미디어 뿐만 아니라, 미디어 스타트업, 지역 언론사, 제3세계 언론사, 그리고 탐사 저널리즘 등 다양한 유형의 언론사들이 스스로 표방하는 저널리즘의 가치를 성취하기 위한 방법으로 데이터 저널리즘을 채택하고 있습니다. 데이터 저널리즘 접근은 대중들이 접근할 수 없는 사실을 발굴하여 특종을 내기보다는 이미 접근 가능한 대량의 데이터들을 연결하고 분석하고, 전달하는 과정을 통해 새로운 통찰을 전달하려고 합니다.\n문제는 데이터 저널리즘은 기자, 언론사에게 새로운 전문성을 요구한다는 것입니다. 매일 발로 뛰면서 집요하게 진실을 추적하는 전통적인 기자에게 요구되는 덕목과 자질과 달리, 데이터 저널리즘은 책상 앞에서 앉아 데이터들을 발굴하고, 그 안에서 숨어있는 메시지를 찾아내는 능력을 요구합니다. 속보 경쟁을 해야하는 언론인들 대부분에게 이러한 전문성을 발휘하는 것도, 그리고 그러한 전문성을 새로이 습득하기 위한 학습 과정도 사치처럼 여겨질 가능성이 큽니다..\n본 교재는 극심한 취재와 보도 경쟁에 내몰려 있지만, 위기에 빠진 언론의 다음 단계를 모색하는, 공부하는 기자들을 위한 데이터저널리즘 교재 입니다. 본 교재는 데이터 저널리즘에 경험이 없는 언론인들이 가능한 짬을 내어 독학하는 상황을 가정하여 만들었습니다. 따라서 본 교재는 다음과 같은 특징을 가지고 만들어졌습니다.\n그렇다고 해서, 이 교재는 완전히 문외한인 언론인만을 위한 것은 아닙니다. 다양한 학습 경험이 있는 언론인들이 유연성 있게 활용할 수 있도록 하기 위해, 각 챕터를 난이도 별로 구분해서 작성하고자 노력했습니다. 이를 최대한 활용하기 위해, 다음과 같은 수준별 학습 방법을 권합니다.\n그간 데이터 저널리즘에 대한 지식은 여기저기 흩어져 있어, 학습을 원하는 독자들은 조각난 지식들을 모으는데에서 부터 시작해야 했고, 따라서 학습을 포기하기 일수였습니다. 인터넷 언론 &lt;뉴스타파&gt;에서 지난 2022년 좋은 교재를 발간하였으나, 정보공개 청구 등 데이터 수집을 통한 탐사 저널리즘 맥락에 초점을 두고 있다는 점, 파이썬이라는 훌륭하지만 비교적 비전공자에게 접근성이 떨어지는 프로그램 언어를 사용했다는 점, 데이터 스토리텔링, 뉴스 배포 등의 데이터 저널리즘의 중요 측면에 관심을 덜 두었다는 점에서 다소 아쉬운 점도 있었습니다. 교재의 부족 문제는 해외의 경우에도 크게 다르지 않아, 취재와 보도라는 특수한 맥락 보다는 프로그래밍의 측면에 주목한 한 두개의 교재 이외에는 데이터 저널리즘 전체 과정을 포괄하는 교재가 없어, 교수자가 필요에 따라 여러 정보를 짜깁기 해야 하는 상황이 반복되었습니다. 이러한 아쉬움을 달래보고자, 본 교재는 가능한 데이터 저널리즘의 이론, 필요성, 데이터 스토리텔링 전략과 관련된 영상 심리학과 그 구현, 데이터 저널리즘 기반 보도와 뉴스 유통을 원활하게 하기위한 문서 작성과 관리 전략까지 다양한 분야를 최대한 광범위하게 다루기 위해 노력했습니다.\n또 하나, 이 교재의 중요한 특증은, 오픈 텍스트북을 지향한다는 것입니다. 오픈 텍스트북을 위한 첫 삽은 이 교재의 저자인 박찬경과 사영준이 뜨지만, 오픈 사이언스의 도구들을 이용해 누구든 이 교재를 무료로 사용할 수 있을 뿐만 아니라, 이를 수정, 재편집, 재구성하여 본인만의 교재를 다시 구성할 수 있도록 하고자 했습니다. 이를 위해 이 교재는 마크다운(Markdown) 문법을 이용해 작성되었으며, 모든 소스코드는 Github 저장소에 공개되었습니다. 따라서 이 교재는 완성본이 아니라고 할 수 있습니다. 앞으로 언론사, 언론인재교육 기관, 학계와의 협력을 통해 계속해서 진화하는 교재의 기반으로 사용될 수 있기를 기대합니다.\n이 교재는 지난 2년간 경북대학교와 언론재단에서 미디어 커뮤니케이션 전공 대학생들과 현직 기자들을 대상으로 이루어진 강의를 바탕으로 쓰여졌습니다. 강의의 내용을 교재로 구성하고 오픈소스 프로젝트로 변환할 수 있도록 도움을 준 한국언론재단 대구지사 조윤태 지사장, 이민규 과장께 가장 먼저 감사드립니다. 또한 교재를 완성하는데 세세한 세부사항에 신경써 준 경북대학교 고서영, 이신애 학생에게 감사 드립니다. 특히 고서영 학생은 이 교재에 포함된 많은 삽화들을 고생스럽게 그려주었습니다.\n이 교재가 짧게는 데이터 저널리즘 교육에서 교재 가뭄을 해소하고, 길게는 더 많은, 더 좋은 교재가 나오는데 일조하기를 바랍니다. 그리고 무엇보다 데이터 저널리즘이 특정 전공자들만 다룰 수 있는 특수한 영역이 아니라, 조금의 노력만 기울이면 누구나 접근할 수 있는 시도라는 인식이 확산되는데 일조할 수 있기를 기대합니다."
  },
  {
    "objectID": "index.html#to-dos",
    "href": "index.html#to-dos",
    "title": "공부하는 언론인을 위한 R기반 데이터 저널리즘",
    "section": "To-do’s",
    "text": "To-do’s\n\n개인정보 지우기\n챕터명 확정 후 서문 재수정\n그래픽 리사이징."
  },
  {
    "objectID": "journalism.html#데이터-저널리즘의-사례와-요소",
    "href": "journalism.html#데이터-저널리즘의-사례와-요소",
    "title": "1  데이터 저널리즘이란",
    "section": "1.1 데이터 저널리즘의 사례와 요소",
    "text": "1.1 데이터 저널리즘의 사례와 요소\n최근 ’데이터 저널리즘’이라는 용어는 이곳 저곳에서 들어보셨을 것입니다. 그러나 데이터 저널리즘이 무엇인지 명확한 정의를 가지고 있는 분은 많지 않을 것이라고 생각합니다. 그것이 독자 여러분들의 탓은 아닙니다. 사실, ’데이터 저널리즘’에 대한 합의된 정의가 없다고 보아도 무방하기 때문입니다. 그 대신, 데이터 저널리즘을 ’데이터를 이용한 저널리즘’이라고 정의한다면, 그것이 그다지 좋은 정의가 아니라는 점은 분명한 것 같습니다. 저널리즘이 ’사실’을 전달하는 업무인 이상, 사실의 증거가 되는 데이터를 이용하지 않을 방법은 없으니까요. 그것이 통계가 되었든, 인터뷰가 되었든, ’관계자’로 부터 비공식적으로 듣게된 증언이든, 그러한 증거들은 모두 데이터 입니다. 데이터를 이용하지 않는 저널리즘이 애초에 존재하지, 데이터 이용 여부로 데이터 저널리즘이라는 특수한 저널리즘을 정의하기는 어렵습니다.\n어떠한 대상을 정의하기 어려울 때, 우리가 흔히 취하는 방식 중 하나는 그 대상의 ’외연(外延)’을 나열하는 것입니다. 즉, 데이터 저널리즘은 이러한 것이다, 라고 단언하기 어려우니, 우리가 데이터 저널리즘으라고 여기는 사례를 죽 검토해보고, 저널리즘이 이러이러한 것들을 갖추어야 우리는 그것을 데이터 저널리즘이라고 여기는구나, 라는 식으로 경험적으로 접근하는 것이지요. 데이터 저널리즘이 무엇인지를 이해하기 위한 이러한 접근 방법은 어떤 데이터 저널리즘이 좋은 데이터 저널리즘인가를 생각해 보는데에도 도움이 됩니다. 그러니 데이터 저널리즘을 수행하는데 필요한 도구나 방법은 추후에 더 이야기해 보기로 하고, 먼저 데이터 저널리즘의 몇 가지 사례들을 검토해보도록 하지요.\n다음 그림은 코로나 19가 여전히 맹위를 떨치던 2021년 7월, 영국 언론사 파이낸셜 타임즈에선 낸 기사입니다.\n\n\n\n그림 1.1: 파이낸셜 타임즈의 코로나 백신 보도\n\n\n이 보도에서 푸른 색으로 표현된 그래프는 10개 국가의 일자별 코로나 감염자수를 표현하고 있습니다. 반면, 빨간색은 그래프는 사망자수를 거꾸로 표현하지요. 만약 사람들이 백신을 접종하지 않았다면, 파란색 그래프와 빨간색 그래프는 대략적으로 대칭으로 보여야 할 겁니다. 감염자가 많아지면 사망자가 많아지는 것은 당연한 이치이니까요. 실제로 그래프에 표현된 10개의 국가들에서 대부분의 기간동안 그러한 대칭성이 보입니다. 그런데, 그렇지 않은 부분분도 있습니다. 제일 처음 표현된 영국(UK)와 포르투갈(Portugal)의 7월15일 이후 그래프 이지요. 7월15일경 대부분의 위험군에게 백신 접종이 완료되었고, 그 이후에는 사망자가 줄어들면서, 더 이상 파란 그래프와 빨간 그래프가 대칭적이지 않게 되었습니다. 백신이 광범위하게 접종되지 않은 다른 나라들은 물론 그런 일이 일어나지 않았지요. 즉, 영국과 포르투갈은 위험군에 대한 백신 접종 덕분에 코로나 감염자가 늘더라도, 사망자가 그만큼 늘지는 않게 되었다는 것입니다.\n왜 이런 보도가 등장했을까요? 이 때는 ‘안티백서’라고 코로나19 백신 접종에 반대하는 사람들의 주장이 특히 서구 국가들에서 기승을 부리던 시기입니다. 이들은 코로나19 백신은 국가와 제약 자본의 거대한 음모일 뿐, 사실 코로나를 예방하는 데에는 효과가 없다고 주장하였죠. 사실 어떤 신약이 질병에 ’인과적인’ 효과가 있다는 것을 증명하는 것은 대단히 어렵고, 시간이 오래 드는 일입니다. 그리고 그러한 과정을 통해 밝혀낸 효과의 근거를 대중들에게 설명하는 것은 더욱 더 어려운 일이지요. 위의 그래프 역시 사실 뜯어보면 대단히 많은 정보들이 포함되어 있습니다. 하지만, 두 그래프를 반전시켜서 대칭성이라는 시각 요소를 활용하고, 그래프 색깔과 글자의 ‘깔맞춤’(파란색으로 표시된 ’cases’라는 글자와 빨간색으로 표시된 ’deaths’라는 글자를 주목해보세요)을 통해, 많은 양의 정보를 효율적으로 표현하여, 백신의 인과적 효과를 상당히 설득력 있게 전달하고 있지요.\n다음은, 데이터 저널리즘이 대중화되는데 선구적인 역할을 한 미국 언론사 FiveThirtyEight의 스포츠 보도 사례입니다. 스포츠 보도야 말로, 데이터 저널리즘의 힘을 제대로 느낄 수 있는 분야 중 하나죠. 첫번째 그림은 이미 미국프로농구(NBA)의 레전드라고 할 수 있는 르브론 제임스(LeBron James)와 엔소니 데이비스(Anthony Davis)라는 선수가 20-21시즌 LA레이커스에서 29경기(y축) 각 48분(x축) 동안 언제 함께 뛰었고, 언제 혼자 뛰었는지를 시각화한 것입니다. 짙은 파란색은 두 선수가 같이 뛴 시간, 하늘색은 앤소니 데이비스, 분홍색은 르브론 제임스가 혼자 뛴 시간 입니다. 회색은 두 선수 모두 뛰지 않은 시간이라고 하네요. 언뜻 보아도알 수 있듯이, 생각보다 한 경기 안에서 두 명의 스타가 같이 뛰는 시간이 많지 않았습니다. 기사에 따르면, 실제로 레이커스는 전략적인 이유로 두 선수를 번갈아 기용하는 이른바 ’로테이션’을 운용할 필요가 있었다고 하네요.\n\n\n\nLA레이커스: 르브론 제임스와 앤소니 데이비스의 출장 시간\n\n\n다음 그림은 NBA의 또 다른 레전드, 스테픈 커리(Stephen Curry)와 드레이먼드 그린(Draymond Green)이 골든스테이트 워리어스에서 경기중 언제 함께 뛰고 언제 따로 뛰었는지를 시각화한 것입니다. LA 레이커스와는 한 눈에 보아도 확연한 차이를 느낄 수 있지요? 워리어스의 두 선수는 뛰면 함께 뛰고, 안 뛸 때는 같이 빠지고 있네요.\n\n\n\n글든스테이트 워리어스: 스테픈 커리와 드레이먼드 그린의 출장 시간\n\n\n이 기사는 기존의 일반적인 기사들과 다음 두 가지 점에서 차이를 보입니다. 첫째, 이전에는 사용하지 않았던, 혹은 사용하지 못했던 데이터를 사용합니다. 기존의 보도가 이용했던 데이터는 이미 전문가들에 의해 가공된 데이터들이었습니다. 통계청이 되었던, 기업이 되었던, 미리 어느 정도 이해할 수 있는 형태로 재구성해서 비교적 작은 테이블에 담아둔 데이터를 마이크로소프트 엑셀과 같은 스프레드시트로 열어 그룹별 평균을 구하고, 그래프를 그리는 것이 일반적인 보도를 위한 데이터 처리 방식이었죠. 하지만 위와 같은 데이터는 가공된 데이터가 아닙니다. 선수들의 코트위에서의 행동이 그대로 기록된 ’행동 데이터’이죠. 선수가 코트에 나와서 뛰고 있다는 사실은 그 자체로 데이터가 됩니다. 이러한 데이터는 센서를 이용한 데이터 생성과 분석이 스포츠에서 광범위하게 사용되면서 이전에 비해 훨씬 흔해졌습니다. 지난 번 2022년 카타르 월드컵 포르투갈전에서 황희찬 선수가 상의를 탈의했을 때, 브라탑 형태의 센서가 부착된 조끼를 입고 있어서 화제가 된 적이 있었죠? 그러한 장치들이 운동선수의 실시간 행위를 데이터로 만들어내고 있는 것이지요. 사실 데이터의 크기와 상관 없이 이렇게 가공되지 않은 채, 유입되는 실시간 비정형 데이터가 ’빅데이터’의 정의에 가깝습니다. 이러한 데이터들은 이전에는 존재하지 않았거나, 존재했더라도 가공/분석 방법이 없어서, 컴퓨터의 성능이 모자라서, 등 여러 이유로 분석되지 않았습니다. 하지만, 위의 보도 사례를 보면, 과감하게 두 팀, 네 명의 선수들이 29경기 각48분 동안 언제 뛰었는지를 모조리 보여주고 있네요. 빅데이터의 이용이 보도로부터 그리 멀지 않다는 것을 보여주는 사례 입니다.\n두 번째 차이는 시각화 입니다. 이는 앞서 이야기한대로, 이전에는 데이터가 존재했더라도, 어떻게 가공/분석할 줄을 몰라서 사용하지 않았다는 지적과 강한 관련이 있죠. 전통적인 언론 보도들이 데이터를 통한 분석을 제시하는 경우는 많았지만, 그 결과는 작은 표나, 막대 그래프, 선 그래프 등을 이용해 평균 등의 몇 가지 수로 요약해 표현하는 것이 대부분이었습니다. 그에 반에 위의 시각화는 상당히 창의적인 시각화 방식을 동원해서 데이터를 거의 있는 그대로 보여주고 있지요. 그럼에도 불구하고, LA 레이커스와 골든스테이트 워리어스의 차이는 명확했죠? 이것이 뒤에서 이야기 하게 될 ‘데이터 스토리텔링’의 힘입니다. 좋은 시각화 전략은 훨씬 더 많은 정보를 독자들에게 전달할 수 있게 해 줍니다. 그렇게 독자들에게 전달할 수 있어야, ’빅데이터’를 입수했다는 사실이 비로소 의미가 있는 것이겠지요.\n다음 사례는 KBS의 손흥민 선수에 대한 보도입니다. 축구에 큰 관심이 있지 않았던 분들도 손흥민 선수에 대한 보도에서 ’기대득점’이라는 용어를 사용하는 것을 들어보셨을 것입니다. 예컨대, 손흥민 선수가 골을 자주 넣는 ’손흥민존’에서 기대득점이 예를들면 0.03에 불과했는데도 불구하고 골을 넣었다, 그런 식의 보도 말이죠. 그런데, ’기대득점’이 뭘까요? 사실 이건 위에서 이야기한 스포츠 빅데이터와 관련이 있습니다. 이제 워낙 많은 실시간 데이터가 쌓이다 보니, 어떤 선수가, 경기 중 어떤 시점에, 어떤 위치에서, 어떤 팀을 상대로 슛을 시도했을 때 골이 들어갈 확률이 몇%다, 이런 예측을 통계 모형을 통해 할 수가 있게 되었습니다. 즉, 앞서의 시나리오에서라면, 손흥민 선수가 골을 넣은 곳이 과거 데이터에 따른 예측 모형에 따르면 100번 슛을 해야 고작 3번 골이 들어갈 수 있는 지점이었는데, 그럼에도 골을 넣었다는 것이죠. 더 간단히 말해, 어지간 하면 골을 넣지 못할 상황에서 골을 넣었으니, 손흥민 선수가 대단하다, 그런 의미인 것이지요.\n\n\n\n손흥민 기대득점\n\n\n여기서는 통계 모형과 예측이 이용되었다는 점이 중요합니다. 과거 보도에서도 예측은 사용되기도 했지만, 다소 조심스럽게 사용되었습니다. 예컨대 어떤 증권사의 주가 예측이라던지, 부동산 전문가 여러명의 부동산 가격 추이 예측을 ’전문가 의견’으로 참조한다든지 하는 식이죠. 데이터 저널리즘에서는 예측이 조금 더 적극적으로, 객관적 전거로 사용됩니다. 행동 데이터가 다양해지고, 이를 이용한 예측 모형이 발달하면서, 모형의 성능이 훨씬 좋아졌기 때문이죠. 다만, 모든 분야에서 그런 것은 아닙니다. 안타깝게도 주가와 부동산 가격 예측은 여전히 보도에서 객관적 전거로 사용할 수 있을 정도로 정확하지 못합니다.\n통계 모형 이야기가 나왔으니, 관련된 데이터 저널리즘 보도를 하나 더 보도록 하지요. 다음은 서울대 국제정치데이터센터와 MBC가 협업해서 운영하고 있는 여론M이라는 웹사이트 입니다.\n\n\n\n여론M\n\n\n이 시각화 자료들은 정당 지지도와 대통령 국정수행평가에 대한 여론조사 결과를 보여주고 있습니다. 이런 여론조사는 너무도 흔한데, 왜 이러한 보도를 데이터 저널리즘이라고 하는 것일까요? 왜냐하면, 위의 선 그래프가 나타내고 있는 것은 실제 여론조사 결과가 아니라, 여러 여론조사 결과를 통계모형을 통해 합산한 결과이기 때문입니다. 왜 그런 합산을 하냐고요? 독자들이 더 이상 여론조사 결과를 믿지 않기 때문이죠. 정치적 양극화가 극심해지면서, 꽤 많은 독자들이 자신의 정치적 성향에 따라, ‘대통령의 지지율이 낮게 나온 것은 설문조사 기관이 좌파라서’, 또는 ‘민주당 지지율이 낮게 나온 것은 설문조사 기관이 우파라서’ 그렇다고 믿는 것을 여러분들도 생활에서 느끼고 있을 것입니다. 위의 보도는 통계 모형을 이용해 그러한 설문조사 기관의 ‘편향’1을 감안한 ‘진짜’ 여론을 추정해서 보여주는 것입니다. 물론 이 추정된 ‘진짜’ 여론이 ‘진짜로 진짜’ 여론인 것은 아닙니다. 모든 모형은 100% 정확할 수 없기 때문지요. 하지만, 이런 말도 있지요. “모든 모형은 틀렸다. 하지만 어떤 모형은 유용하다”.\n이렇게 모형을 이용한 보도를 ’유용’하게 만들기 위해서 이 프로젝트는 몇가지 툴을 동원했습니다. 첫째, 불확실성을 시각화하는 것입니다. 위의 그래프를 보면 추정된 여론이 선으로 표현되어 있지만, 그 선 주위로 투명한 색깔로 범위가 표현되어 있지요? 이는 추정 모형이 가지고 있는 불확실성을 계산하여 보여주는 것입니다. 만약 국민의힘과 더불어민주당 지지도 사이에 약간의 차이가 있더라도, 그 차이가 저 불확실성의 범위 안에 있다면, 단적으로 어떤 정당의 지지율이 더 높다, 라고 할 수는 없다는 단서조항 같은 역할을 한다고 생각하면 됩니다. 둘째, &lt;여론M&gt; 로고 옆에 보면 추정 모형의 세부사항에 대해 알 수 있는 링크가 있습니다. 이 링크를 따라가 보면, 전문용어로 가득한 문서가 하나 나오는데요, 모형 자체가 복잡하다보니, 그 설명도 복잡합니다. 다만, 이 문서를 이해할 수 있는 전문 지식이 있다면, 웹사이트에서 보여주는 것과 동일한 추정을 할 수 있지요. 물론, 모형의 검증도 가능합니다. 이렇게, 분석 결과만 보여주는 것이 아니라, 분석 방법까지 공개해서 투명성을 확보하는 것입니다. 더 나아가, 해외 데이터 저널리즘 프로젝트 다수는 분석 방법 뿐 아니라, 원 데이터를 공유하기도 하고, 수식 뿐 아니라, 분석, 시각화 프로그램 코드까지 공개해서 바로 재사용할 수 있는 정도로까지 공유하기도 합니다. 마치 컴퓨터 개발자들이 오픈소스 소프트웨어를 개발하는 것처럼요.\n마지막으로 그래프 아래에서 추정된 여론이 아닌 원래 여론조사를 결과를 확인하는 것도 가능합니다. 대부분의 사람은 위의 그래프를 보고 전반적인 여론 추세를 아는데 만족하겠지만, 좀 더 관심이 많은 사람은 각각의 여론조사 결과를 알고 싶은 경우도 있겠지요. 그럴 때는, 각 설문조사에 해당하는 링크를 클릭하면, 중앙선거관리위원회가 확보하고 있는 각 여론조사의 구체적인 정보, 예컨대, 조사인원, 조사기간, 조사지역, 조사일시, 응답자 구성까지 알 수 있습니다. 이 모든 정보를 한 화면에 보여주면 너무도 복잡하겠지만, 월드와이드웹의 기능을 이용해 관심있는 사람은 원데이터의 세부사항을 볼 수 있도록 해 주는 것이지요.\n자, 지금까지 본 사례들에서 기존 언론 보도와 다소 다르게 느껴지는 것들을 꼽아보자면 다음과 같습니다.\n\n새로운 데이터\n시각화\n공개 데이터\n상호작용성\n공유\n통계 모형과 예측\n데이터 스토리텔링\nSurprise!\n\n우리가 데이터 저널리즘이 무엇인가를 정의하는 것은 너무도 어렵지만, 위의 요소들을 포함한 보도를 대체로 데이터 저널리즘이라고 부르는 것 같습니다. 이전에는 사용하지 않았던, 행동 데이터, 빅데이터를 분석한 결과를 보도합니다. 그러한 데이터를 이용할 수 있게 된 것은 여러 과학기술의 발달 때문이기도 하지만, 그것을 분석할 통계/기계학습 모형과 시각화 도구가 생겼기 때문이기도 하지요. 새로운 데이터들은 기자가 노력을 통해 단독으로 입수하는 것도 있지만, 더 많은 경우는 이미 어디엔가 공개되어 있는 것들인 경우가 더 많습니다. 데이터저널리스트에게는 나만 아는 정보를 찾아내는 것보다 이곳 저곳에 존재하는 데이터들을 연결해서 새로운 통찰을 이끌어 내는 능력이 더욱 중요합니다. 하지만, 복잡한 데이터의 분석 결과는 그 자체로 복잡한 경우가 많습니다. 따라서 효율적인 시각화와 글쓰기를 통해 분석 결과로부터 찾아낸 스토리에 집중할 수 있도록 하는 스토리텔링 능력 역시 중요합니다. 그러한 과정에서 생략해야만 했던 세부사항들은 상호작용적 인터페이스를 통해 독자에게 따로 제공하거나, 공유플랫폼을 통해 제공하는 것이지요. 하지만 제일 중요한 것은, 이 모든 요소들을 종합해 독자들을 놀라게 하는 능력이라고 할 수 있겠습니다. 몰랐던 충격적 사실을 알아서가 아니라, 독자도 접근할 수 있었지만, 연결될 줄은 몰랐던 것들의 연결을 깨달음으로써 써 세상에 대한 이해가 넓어질 때 터져나오는 경탄, 그것이 아마도 데이터 저널리즘의 중요한 목표 중요한 목표 중 하나일 것입니다."
  },
  {
    "objectID": "journalism.html#데이터-사이언스와-데이터-스토리텔링으로서의-데이터-저널리즘",
    "href": "journalism.html#데이터-사이언스와-데이터-스토리텔링으로서의-데이터-저널리즘",
    "title": "1  데이터 저널리즘이란",
    "section": "1.2 데이터 사이언스와 데이터 스토리텔링으로서의 데이터 저널리즘",
    "text": "1.2 데이터 사이언스와 데이터 스토리텔링으로서의 데이터 저널리즘\n앞서 이야기 한 것처럼, 데이터 저널리즘에 대한 명확한 정의는 없다고 보아도 무방합니다. 2010년대 후반 이후로 많은 학자들이 데이터 저널리즘을 어떻게 정의할 것인가에 대해서 많은 논쟁들을 해 왔지만, ’데이터’라는 말과 ’저널리즘’이라는 말 모두가 매우 모호한 말이다 보니, 그 합성어인 데이터 저널리즘이라는 말 역시 많은 사람들이 저마다의 방식으로 이해할 뿐입니다. 하지만, 우리가 경험적으로 ’데이터 저널리즘’은 대충 이런 것이라고 느끼고 있는 바는 있습니다. 그것을 저의 방식대로 요약하자면, ’데이터 사이언스를 이용한 보도 방식’이라고 할 수 있을 것 같습니다. 기자들의 전통적인 보도에서는 정보원과의 긴밀한 소통이 강조되었습니다. 그것이 직접 만남을 통한 것이든, 잠입을 통한 것이든, 전화 인터뷰를 통한 것이든, 기자들이 몸으로 뛰어 다니며 정보, 또는 정보원을 캐내는 그 물리적 과정이 참된 저널리스트로서의 중요한 미덕으로 여겨졌던 것이지요. 몸으로 뛰어서 정보를 캐내지 않고, 다른 기자나 다른 누군가가 생산한 정보를 가공해서 만들어낸 2차 보도를 낮추어 보는 것에는 아마 그런 이유도 있었을 것입니다.\n하지만, 우리의 막연한 상상 속에서 데이터 저널리스트는 어떻게 보도를 하나요? 이들은 사무실에서 앉아서 글자와 숫자만 가득한 여러개의 모니터 앞에서 그래프를 만들어 내거나, 커다란 화이트 보드 앞에서 멋들어진 분석을 해내기 위한 토론을 하고 있지 않은가요? 사실 그것은 우리가 데이터 사이언티스트들에게 가지고 있는 스테레오타입 입니다. 그리고 이러한 상상은 다소 과장된 것이기는 하지만, 어느 정도는 사실입니다. 데이터 저널리즘이 막연하지만 무언가 대단히 다르게 느껴지는 이유는 정보를 얻는 방식도, 보도할 내용을 만들어 내는 방식도 전통적인 저널리즘의 그것보다는 데이터 사이언스의 그것에 대단히 가깝기 때문일 것입니다. 그리고 전통적인 저널리즘의 시각에서 보기에 이러한 방식은 ‘저널리즘’ 그 자체와 배치되는 것처럼 보일 수도 있고, 윤리적으로 옳지 않게 보일 수도 있고, 또 지나치게 ‘한가해’ 보일 수도 있겠죠. 전통적인 언론 조직에서 저널리즘이 잘 받아들여지지 않는 이유이기도 합니다.\n위에서, 데이터 저널리즘이 ‘정보를 얻는 방식’과 ’기사를 생산하는 방식’에서 데이터 사이언스를 차용한다고 말했습니다. 사실 여러분들이 이 교재에서 배우게 될 핵심이죠. 그러면 데이터 사이언스에서 이 두 가지는 전통적인 보도와 어떻게 다를까요? 첫째, 데이터 사이언스는 이미 대중에게 공개되어 있는 정보를 얻습니다. 이것은 기자이기에 접할 수 있었던 정보를 수집하는 전통적인 보도 행위와 다르지요. 따라서, 데이터 저널리스트를 ’게이트키퍼’라고 부르기는 쉽지 않습니다. 하지만, 이미 공개되어있는 데이터를 이용한다고 그 데이터를 수집하는 것이 마냥 쉬운 것은 아닙니다. 어떤 경우에는 데이터가 분석하기 어려운 형태나 위치에 있거나, 너무 크거나(빅데이터), 또는 서로 관련이 없는 줄 알았던 이 데이터와 저 데이터가 함께 연결해야만 그 전에는 알지 못했던 함의를 도출할 수 있는 경우도 있습니다. 따라서 필요한 정보를 ’찾아서’, ‘분석할 수 있는 형태로 저장/가공하고’, ‘여러 정보를 잇는’ 작업이 필요합니다. 데이터 사이언스에서는 이를 information retrieval이라고 부릅니다. Information retrieval의 일반적인 번역어는 ’정보검색’인데요, 사실 이는 좋은 번역이라고는 할 수 없습니다. 물론 정보검색 하면 생각나는 검색창과도 관련이 있지만, 그것을 위해 필요한 웹스크레이핑, 크롤링, 인덱싱, 데이터베이싱, 추천 알고리즘 등을 모두 포괄하는 개념이기 때문이지요. 자세한 이야기는 나중에 하기로 하고, 일단 information retrieval이 전통적인 보도에서는 취재 과정에 해당한다고 볼 수 있고, 이것이 발로 뛰는 정보 수집은 아니지만, 그 나름대로 여러 난관과 그것들을 뚫어내기 위한 기술과 노력을 필요로 한다는 것 정도를 이해하면 될 것 같습니다.\n둘째, 데이터 사이언스에서 전달할 내용을 생산하는 방식은 ‘시각화’와 ’데이터스토리텔링’에 의존합니다. 이는 ’글쓰기’가 중요하지 않다는 것을 의미하지는 않습니다. 대부분의 데이터 저널리즘 기반 보도에는 글과 스토리가 있어야만 합니다. 다만, 글의 핵심은 데이터 또는 데이터 분석의 의미를 잘 전달하는데 있다는 것, 그리고 그것을 달성하는데 필요한 것 이상의 텍스트는 최대한 생략하는 것이 좋다는 것이 ’데이터 스토리텔링’에서 대단히 중요한 원칙입니다. 데이터스토리텔링이 그러한 간결성을 추구하는 이유는 데이터 분석을 이용해 전달하려고 하는 정보가 이미 상당히 복잡하기 때문입니다. 여러분들 또한 독자이기에 느끼시겠지만, 독자는, 혹은 인간은 정말이지 한정된 집중력을 가지고 있습니다. 독자들은 기사를 보겠다고 스스로 기사 제목을 클릭했으면서도, 마치 조금만 지루하게 하면 그 기사로부터 도망갈 핑계를 찾고 있는 역설적인 존재들처럼 보이기도 하지요. 따라서, 아주 짧은 기사 조차 처음부터 끝까지 보도록 만드는 것이 대단히 어렵다는 것은 누구나 공감하실 것입니다. 그런 독자들에게 빅데이터를 분석한 결과를 쏟아낸다면 어떨까요? 그 기사를 처음부터 끝까지 만드는 것은 불가능하게 보이기도 합니다. 데이터 사이언스를 이용한 분석 결과는 그 결과조차 복잡한 경우가 허다하거든요. 그렇다면, 글쓰기가 기존의 기사 쓰기와 같아서는 안 될 것입니다. 애써 크고 복잡한 데이터를 훌륭하게 분석했다면, 그 분석 결과를 온젼히 전달하는데에도 많은 노력을 들여야 합니다. 그리고, 그 과정에서 글쓰기로 해결되지 않는 부분을 해결해 주는 것이 바로 ’그림’ 또는 시각화 입니다. 데이터 시각화란 언제든지 기사로부터 달아날 준비가 된 예민한 독자들을 어르고 달래 효과적으로 분석 결과를 전달하기 위한 그림 입니다. 따라서, 데이터 시각화에도 기술이 필요합니다. 물론 더 좋은 것은 간명한 글과 시각화가 잘 결합되어 복잡한 내용을 쉽게 전달하는 것입니다. 이를 ’데이터 스토리텔링’이라고 하는 것이고요.\n따라서, 데이터 저널리즘은 데이터 사이언스를 이용한 저널리즘이다, 라는 정의를 조금 더 구체화하자면, 기존의 취재와 기사 쓰기를 정보검색(더 정확하게는 information retrieval)과 데이터 스토리텔링으로 대체한 저널리즘이라고 보아도 좋습니다. 다만, 이러한 저널리즘이 우리가 ’저널리즘’이라는 직종의 가치에 적합한 것인가를 따질 수는 있습니다. 여기서는 그런 복잡한 논의는 건너뛰기로 하지요. 아무튼 그러한 이유로 이 교재에서는 정보검색과 데이터 스토리텔링에 필요한 다양한 개념과 기술들을 배우게 될 것입니다."
  },
  {
    "objectID": "journalism.html#데이터-저널리즘은-왜-필요한가",
    "href": "journalism.html#데이터-저널리즘은-왜-필요한가",
    "title": "1  데이터 저널리즘이란",
    "section": "1.3 데이터 저널리즘은 왜 필요한가",
    "text": "1.3 데이터 저널리즘은 왜 필요한가\n앞서 설명한 데이터 저널리즘이 갖추고 있는 요소들과 ‘데이터 사이언스를 활용한 저널리즘’이라는 일종의 정의가 데이터 저널리즘이 무엇인지를 이해하는 데에는 어느 정도 도움을 주지만, 아주 만족스러운 것은 아닙니다. 왜냐하면 그런 설명들은 데이터 저널리즘을 방법의 관점에서 바라보고 있기 때문에, 그로부터 어떤 데이터 저널리즘이 사회적으로 ’바람직한’ 데이터 저널리즘인지 이해하는 데에는 한계가 있기 때문이지요. 물론, 이 역시 정답이 있는 문제는 아니지만, 그것을 판단하기 위해서는 이제 데이터 저널리즘이 사회적 필요성에 대해서 조금 이야기해 볼 필요가 있습니다.\n왜 ‘바람직한’ 데이터 저널리즘이 무엇인지 판단하기 위해서 그것의 ‘필요성’에 대해 이야기 하는 것일까요? 만약 데이터 저널리즘이라는 것이 사회적으로 그다지 필요하지 않은 일정의 기술적 유희에 불과하다면, 바람직한 데이터 저널리즘이란 것 자체가 형용 모순이기 때문입니다. 이미 기존의 저널리즘으로 충분하다면, 기자들이 데이터 사이언스를 배워야 한다는 구호는 한낱 유행이거나, 심지어 한정된 자원을 엉뚱한 곳에 쓰게 만드는 낭비에 가까울 것입니다. 만약, 그렇지 않고 데이터 사이언스가 세상의 변화로 인해 발생한 어떤 구멍을 메꾸기 위해 ’필요해진’ 것이라면, 우리는 그러한 사회적 필요성에 적합한 데이터 저널리즘을 ‘바람직한’ 데이터 저널리즘이라고 부를 수도 있겠지요.\n데이터 저널리즘의 필요성으로 두 가지를 들 수 있을 것 같습니다. 첫째, 현대의 독자들은 ‘정보의 부족’이 아니라 ’정보의 과잉’ 때문에 양질의 정보를 소비하지 못하고 있다는 문제입니다. 전통적인 저널리즘은 시민들의 ‘정보의 부족’ 문제를 해결하기 위해 시민사회와 시장이 만들어낸 일종의 솔루션이었다고 볼 수 있습니다. 시민들은 접할 수 없지만, 나름의 조직과 자본을 갖추었을 때 접할 수 있는 정보, 즉, 기자만 접할 수 있는 정보가 있었던 것이지요. 따라서, 기자들은 그러한 정보들 중 독자들이 ‘읽을만 하다’라고 여기는 정보를 전달해 주는 ’게이트키퍼’ 역할을 했던 것입니다. 물론, 이러한 상황이 지금은 사라졌다고 볼 수는 없겠지마는, 최근의 독자들은 기자들이 접할 수 있는 정보에 똑같이 접할 수 있는 경우가 많습니다. 심지어 개인 유튜버들이 기자들보다 더 빨리 정보를 캐내고 기자가 이를 후속 보도하는 경우도 많지요. 하지만, 독자 입장에서 더 큰 문제는 쏟아지는 정보 중에서 어떤 정보가 의미있는 것인지 알기 어렵다는데 있습니다. 다들 먹고 사느라 바쁜데, 그 많은 정보들이 ’접근가능’하다고 해서 개개인에게 ’처리가능’한 것은 아니지요. 데이터 저널리즘이 필요한 것은 바로 이 지점 입니다. 데이터 저널리즘은 이미 접근 가능한 수많은 정보들 중 의미 있는 것들을 찾아내고, 연결해서, 숨겨져 있는 연관을 찾아내고, 그로부터 시민들이 주목해야 할 통찰을 끌어내는데 특화되어 있다는 점에서, 전통적 저널리즘과 다른 사회적 효용을 갖는 것입니다. 즉, 데이터 저널리즘은 지난 밤에 어떤 일이 일어났는지를 보도 했을 때 좋은 저널리즘이 되는 것이 아니라, 주어진 정보들이 어떤 의미를 갖는 것인지를 발견하고 이를 효과적으로 전달할 때 바람직한 저널리즘이 되는 것이라고 할 수 있습니다.\n두 번쨰 데이터 저널리즘의 필요성은 과학 커뮤니케이션의 중요성이라고 할 수 있습니다. 따지고 보면, 세상이 참 많이 변해서 정치권에서 보수와 진보가 싸우는 주제가 참 많이 바뀌었습니다. 예전에는 노동정책, 복지정책, 큰 정부와 작은 정부 이런 것들이 보수와 진보를 나누는 키워드였죠. 물론 이런 주제는 여전히 중요합니다만, 최근에는 예전에는 과학만의 영역이라고 여겨졌던 주제들이 정치권에서 매우 중요한 논쟁 거리가 됩니다. 예컨대, 기후변화, 핵에너지, 환경 오염, 코로나19, 백신, 이런 것들이죠. 과학적 사실에는 옳고 그름이 있어 정쟁의 대상이 되지 않을 것 같지만, 사실은 그 반대입니다. 많은 사람들이 과학은 옳고 그름의 문제라고 생각하기 때문에, 자신이 믿는 ‘옳은’ 과학적 사실에 반대하는 상대방은 단순히 의견을 달리 하는 사람이라기 보다는 ‘바보’라고 믿기 때문이지요. 의견이 다르면 논쟁을 하면 되겠지만, 사람들은 ’바보’와 논쟁하려 하지 않습니다. 단지 배척할 뿐이지요. 이렇게 과학은 정쟁은 주요 대상으로 떠올랐습니다. 하지만, 문제는 과학적 ’사실’ 또는 ’발견’을 대중들에게 전달하는 것은 생각보다 어렵습니다. 앞서 이야기 한 백신의 효과에 대한 논쟁을 떠올려 보세요. 많은 사람들은 ’백신을 맞은 사람들 중에 코로나에 걸릴 확률’과 ’코로나에 걸린 사람들 중 백신을 맞은 사람들의 비율’의 차이를 잘 이해하지 못합니다. 이는 그것을 이해하지 못하는 사람들의 잘못이 아니라, 원래 인간의 두뇌는 과학을 이해하기 위한 그런 중요한 차이를 이해하는데 취약합니다. 이는 노벨 경제학상을 받기도 한 심리학자 다니엘 카네만(Daniel Kahneman)이 밝혀낸 사실이기도 하지요. 물론, 설명을 듣고 가만히 앉아서 5분, 10분 고민하면 누구나 이해할 수 있습니다. 하지만, 백신의 효과를 설명하는 여러분의 기사를 읽는 독자들 중에 몇이나 그런 시간과 공을 들여줄까요? 앞서 설명한 시각화, 데이터 스토리텔링 방법들은 복잡한 과학적 사실을 가능한 적은 자원을 이용하면서 이해할 수 있는 방식으로 독자들에게 전달하는 것을 목적으로 하고 있습니다. 앞서 본 파이낸셜 타이즘의 백신 보도가 그런 예이지요. 그러니, 좋은 데이터 저널리즘은 단지 멋진 시각화를 이용한 보도라기 보다는 그런 수단을 이용해 복잡한 사실을 쉽게 이해할 수 있는 방식으로 전달하는 것이라고 할 수 있겠습니다."
  },
  {
    "objectID": "journalism.html#데이터-저널리즘의-전략",
    "href": "journalism.html#데이터-저널리즘의-전략",
    "title": "1  데이터 저널리즘이란",
    "section": "1.4 데이터 저널리즘의 전략",
    "text": "1.4 데이터 저널리즘의 전략\n지금까지의 이야기를 종합하자면, 데이터 저널리즘은 첨단 기술의 발달로 복잡해져가는 세상을 이해하는데 도움을 중요한 역할을 할 수 있지만, 복잡한 내용을 전달하는 만큼 내용 전달에 더 큰 어려움이 따른다, 라고 할 수 있겠습니다. 따라서 데이터 저널리즘 보도를 위해서는 그 가치를 충분히 활용하기 위한 몇 가지 전략을 따르는 것이 도움이 됩니다. 기술적으로 주어진 데이터와 분석 결과를 어떻게 전달할 것인지에 대한이야기는 후에 ’데이터 스토리텔링’에 관한 장에서 하도록 하고, 어떤 스토리를 짜는 것이 데이터 저널리즘의 가치를 유용하게 활용할 수 있는가에 대한 이야기를 해 보도록 하겠습니다.\n여기서 할 이야기는 앤드류 플라워(Andrew Flower)라고 하는 경제학자이자, 전 FiveThirtyEight의 데이터 사이언티스가 2017년에 한 강연을 바탕으로 해서 다소 수정, 보완을 거친 것입니다.\n앤드류 플라워는 데이터 저널리즘 보도는 일반적으로 다음의 여섯가지 전략을 바탕으로 한다고 정리합니다.\n\n새로움(Novelty)\n예외성(Outlier)\n전형성(Archetype)\n추세(Trend)\n예측(Forecast)\n폭로/반박(Debunk)\n\n첫번째, 새로움은 그 전에 보도에서는 사용하지 않았음직한 데이터를 이용하거나, 전혀 상관이 없을 것 같았던 다른 데이터들을 연결해서 새로운 통찰을 던져주는 것을 의미합니다. 데이터 저널리즘의 등장 배경에 이전에 비해 분석할 수 있는 데이터의 종류와 양의 증가와, 그러한 데이터를 분석하기 위한 분석 방법과 컴퓨팅 파워의 상승이 있다는 것을 생각해 보면, 새로움의 전략은 데이터 저널리즘의 본령, 또는 필요조건 이라고도 할 수 있습니다.\n한국에서 좋은 데이터 저널리즘 보도를 지속적으로 내어놓고 있는 SBS 마부작침의 다음 기초의회 의원의 업무 추진비에 관한 기사를 볼까요? 마부작침 팀은 각 기초의회를 대상으로 정보공개청구를 하여 전국 226개 시군구 기초의회 의장단이 2년간 집행한 업무 추진비 17만 건 가량을 전수 분석했습니다. 이를 통해 몇몇 기초의회 구성원과 특정 식당 간의 유착 관계, 부당한 업무 추진비 집행, 업무 추진비 집행과 관련된 불투명성 문제들을 연속 기사로 발표했지요. 과거에는 가능할 것 같지 않았던 17만개 예산 집행 항목에 대한 보도는 정보공개청구라는 새로운 정보 수집 방법과, 데이터 과학의 방법론을 통해 가능해졌다고 할 수 있겠습니다.\n마부작침 팀의 분석은 보도에 그치지 않았습니다. 제대로 감시 받지 않는 기초의원들의 회의비 지출도 문제지만, 사실 이는 지역 맛집을 알아내기 위한 매우 양질으 데이터이기도 합니다. 요즘 인터넷에서 찾을 수 있는 음식점 리뷰들은 도움이 될 때도 있지만, 젊은 사람들의 취향만을 반영하거나, 해당 서비스의 이용이 적은 지역에서는 정보의양이 적거나, 또는 음식점에서 리뷰 작성에 개입해 신뢰성이 떨어지는 경우도 많죠? 아마 숨겨져 있느 지역 맛집에 관해서 기초의원들의 회의비 지출 영수증 보다 양질의 빅데이터는 찾기 어려울 것입니다. 마부작침 팀은 이에 착안했는지, 자신이 위치한 지역 기초의원들이 가장 많이 회의비를 지출한 식당을 찾아내는 웹서비스를 제공했습니다.\n\n\n\n새로움 전략의 예\n\n\n두번째, 예외성 전략은 보도의 대상이 평균에서 벗어나는 예외적 현상임을 데이터를 통해 보여줌으로써 흥미로운 이야기를 만들어내는 것입니다. 다음은 FiveThirtyEight의 “리오넬 메시는 불가능의 영역에 있다(Lionel Messi Is Impossible”라는 제목으 기사에 실린 시각화 자료 입니다. 여기서 x축은 한 게임에 평균 쏘는 슛의 갯수, y축은 얼마나 많은 슛을 골로 연결했는지를 보여주고 있습니다. 각 점은 모두 한 명의 선수를 나타내고 있지요. 빨간 선은 슛을 쏘는 수와 골을 성공시키는 확률 사이의 ‘평균적인’ 인 관계를 보여줍니다. 즉, 슛을 쏘는 ‘양’이 많은 선수일 수록 슛의 ’질’도 평균적으로 높을 가능성이 크다는 이야기 이지요. 그 중에서도 기사는 두 명의 선수에 주목합니다. 바로 메시와 크리스티아누 호날두 이지요. 이 둘은 다른 선수들에 비해 그래프의 오른쪽에 뚝 떨어져 있지요? 슛을 압도적으로 많이 쏘는 선수라는 뜻입니다. 세계적인 공격수들이니 당연하지요. 그런데, 세계에서 슛을 가장 많이 쏘는 선수인 호날두는 빨간 선 아래 있지요? 이는 저만큼 슛을 쏘는 선수라면 어느 정도는 슛을 자주 성공시켜야 하는데 그에 미치지 못한다는 것입니다. 슛의 양이 높은데, 질이 그에 따라가지는 못한다, 더 안 좋게 이야기 하면 슛을 ’난사’한다고도 할 수 있겠네요. 메시는 어떤가요? 메시 역시 호날두 만큼은 아니지만 대부분의 선수들에 비해 슛을 많이 쏜다는 것을 알 수 있습니다. 그런데, 메시는 그만큼 슛을 쏘는 선수에게 기대하는 슛의 성공 확률에 비해 훨씬 더 높은 확률로 슛을 성공시키고 있습니다. 즉, 슛을 쏘는 양도 많지만, 슛의 질도 좋다는 것이지요. 즉, 메시는 아주 ’예외적인’ 존재라는 것입니다.\n\n\n\n예외성 전략의 예.\n\n\n반대의 전략도 가능합니다. 오히려 보도의 대상이 예외가 아니라 평범한 현상임을 강조하는 세번째 전략, 전형성 전략이지요. 다음 보도 역시 FiveThirtyEight의 미국 미주리주에서 2014년 일어난 퍼거슨 소요에 대한 기사의 한 부분입니다.\n\n\n\n전형성 전략의 예\n\n\n퍼거슨 소요를 기억하실지 모르겠습니다. 2014년 비무장이었던 마이클 브라운 이라는 18세 흑인 청소년이경찰이 쏜 여러발의 총탄에 맞고 사망한 사건이 벌어진 후, 퍼거슨에서 격렬한 시위가 몇 주 동안 이어지고, 방화 약탈까지 일어나는 큰 소요사태였습니다. 이는 Black Lives Matter 운동의 중요한 촉매제가 되기도 했지요. 위 기사는 퍼거슨 이라는 도시에 주목하고 있습니다. 소요 사태에서 드러난 흑인들의 응축된 불만이 퍼거슨에 국한한 것인지를 보여주려는 것이지요. 위 그래프에서 x축은 각 도시의 중위 가구 소득을 의미합니다. y축은 흑인 가구의 중위 가구 소득과 와 백인 가구의 중위 가구 소득 사이의 비율 입니다. 1.0 이하의 수치는 해당 도시에서 흑인 가구가 백인 가구에 비해 적은 소득을 얻고 잇다는 뜻입니다. 흔히 알려져 있듯 그래프에 표시된 절대 다수의 도시가 1.0 아래에 있습니다. 그렇다면 퍼거슨은 어디에 있을까요? 바로 대부분의 도시가 모여있는 부분이 한 가운데에 있습니다. 즉, 퍼거슨은 미국의 다른 도시들보다 특별히 흑인이 못사는 도시도, 흑인들이 백인에 비해 상대적으로 박탈감을 느낄 도시도 아니라는 것입니다. 그야말로 미국 도시의 ’전형’에 불과하다는 것이지요. 그렇다면, 퍼거슨 소요 사태는 흑인 청년의 사망 사건을 촉발된 우연적 사건이라기 보다는 미국 사회의 구조적인 문제를 보여주는 사건이라고 할 수 있겠지요. 다른 평균적인 도시들에서도 발생할 수 있는 사태라는 점도 지적할 수 있겠네요.\n네번째는 추세를 보여주는 전략입니다. 다시 말해 시간에 따른 경향성을 보여줌으로써 특정 변화가 일어나고 있다는 것을 보여주는 것입니다. 추세를 보여주는 데이터 활용 전략은 전통적인 보도에서도 자주 이용되던 전략입니다. 그러나 데이터 저널리즘은 이미 만들어진 데이터가 보여주는 추세, 예컨대 실업률, GDP 성장률, 범죄 발생 등의 추세를 보여주는데 그치지 않고, 여러 정제되지 않은 데이터 속에서 분석을 통해 추세를 발견하고 독자들에게 복잡성과 함께 단순화된 추세를 함께 전달하는 것을 지향하는 경우가 많습니다. 앞서 본 &lt;여론M&gt;의 기사가 좋은 예 입니다. 각 여론조사 기관들이 저마다 알려주는 추세가 너무도 다양해 독자들이 현실을 파악하기 어려우니, 각 많은 여론조사 결과가 만들어 내는 여론의 복잡성과 함께, 그들로 부터 도출한 단순화된 추세를 함께 시각화한 것이지요. 영국의 주간지 &lt;이코노미스트&gt;의 남극 얼음에 대한 다음 기사 역시 참조할만 합니다.\n\n\n\n추세 전략의 예\n\n\n이 그래프는 위성사진 데이터를 이용해 매일매일의 남극 얼음 크기가 그날의 평균으로 얼마나 벗어나는지를 연도별로 보여줍니다. &lt;여론M&gt;이 보여주는 시각화처럼, &lt;이코노미스트&gt;의 이 시각화 역시 하루하루에 해당하는 데이터의 복잡함을 모두 보여줍니다. 이로부터 독자가 알 수 있는 것은 남극 얼음의 크기는 해마나 다르지만, 역사적으로 결국 어느 정도의 범위를 벗어나지는 않았다는 것입니다. 그러나 이 그래프에서 강조한 2022년과 2023년의 그래프는 기후에 대한 우려를 자아냅니다. 2022년의 그래프는 역사적인 변동의 ‘어느 정도의 범위’ 끝자락에 있다면, 2023년 그래프는 남극 얼음의 크기가 관측 역사에서 찾아볼 수 없을 정도로 작어져 있다는 것을 의미하기 때문이지요. 어떻게 보면, 이 시각화는 추세 전략과 예외성 전략을 동시에 사용하고 있다고 볼 수도 있겠네요.\n다섯번째는 예측 전략 입니다. 예측은 과거에 일어난 일을 잘 분석하여 추세, 또는 여러 수치들이 만들어 내는 패턴을 파악해 미래를 예측하는 것입니다. 예측에 대해서는 아까 손흥민 선수의 ’기대득점’에 대해 이야기 하면서 언급했습니다. 전통적인 보도에서는 투자 전문가의 주식/부동산 가격 예측, 경제학 교수의 금리 변동 예상, 유명한 컨설팅 회사의 기술 예측 등, ’전문가 의견’을 이용하는 것이 흔히 이루어지는 예측 보도였지요. 이러한 보도들은 유용한 것도 있었지만, 사실 그 인용된 전문가의 의견이라는 것이 검증이 된 경우도 그렇지 않은 경우도 많았습니다. 또, 경제나 기술 발전에 대한 예측은 예측 모형의 복잡도도 매우 높을 뿐더러, 여전히 그 정확도가 매우 떨어집니다. 반대로 데이터 사이언티스트들이 비교적 쉽게 스스로 예측 모형을 구축할 수 있고, 그 정확도도 비교적 높은 영역이 바로 스포츠 영역 입니다. 그 때문에 최근 스포츠 보도에서는 선수의 행동 데이터와 예측 모형에 기반한 다음과 같은 예측에 기반한 보도들이 자주 이루어지고 있습니다.\n\n\n\n예측 전략의 예.\n\n\n마지막으로 폭로/반박 전략 입니다. 이 전략은 기존의 주장이나 편견을 반박하는 결과를 드러냄으로써 인식을 새롭게 하는 것을 노리는 전략입니다. 앞 서 언급한 것처럼, 데이터 저널리즘의 목적 중 하나가 데이터 과부하가 독자들에게 불러 일으키는 혼란스러움을 해결해 주는 것이라는 것을 상기시켜보면, 데이터 저널리즘이 증거를 통해 잘못된 지식이나 통념을 해소하려 하는 것은 자연스러운 수순이라고 할 수 있겠네요. 다음 시각화는 역시 FiveThirtyEight의 보도에서 가져온 것인데요, 우리가 흔히 보게 되는 “블루베리는 기억력 감퇴를 방지해준다”, “브로콜리는 사실상 마이너스 칼로리이다”와 같은 과학적 발견의 외양을 한 보고들이 얼마나 불안정한 측정치를 바탕으로 하고 있는지를 보여주는 기사 입니다.\n\n\n\n폭로/반박 전략의 예.\n\n\n식품이 신체에 미치는 영향을 과학적으로 검증하기 위해서는 관찰 대상이 되는 사람이 어떤 식품을 얼마나 먹었는지에 대해서 먼저 알아야 되겠지요? 이를 측정하는 방식에는 여러가지가 있습니다만, 가장 흔하게 사용되는 방식은 ‘식품섭취빈도법’, 또는 FFQ라고 불리는 방법입니다. 자세한 방식은 연구마다 다를 수 있지만, 기본적으로 지난 1년 또는 6개월간 해당 음식을 얼마나 자주 먹었는지를 물어보는 방식이지요. 이런 측정 방식은 사람의 장기 기억에 의존하기 때문에 대단히 부정확할 수 있을 것이라는 것은 흔히 생각해볼 수 있습니다. 그에 반해 측정이 어렵지만 더 정확한 방법이 있습니다. 식사기록법, 아래 기사에는 Food diary라고 표현되어 있는 방식이지요. 이는 조사 참여자가 일기를 적듯이 지난 24시간 동안 무엇을 먹었는지를 자세하게 적는 방식입니다. 이 방식은 더 정확하기는 하지만, 조사 참여자가 일기를 자세하게 적도록 유도하는 것도, 그 일기를 분석 가능한 숫자로 만드는 과정에도 대단히 비용이 많이 드는 방식입니다. 따라서, 현실적으로는 FFQ가 꽤 많이 사용됩니다.\n위의 보도에서 폭로/반박을 위해 FiveThirtyEight은 아주 단순하게 세 명의 기자, 크리스티(Christie), 월트(Walt), 안나(Anna)에게 식품섭취빈도법과 식사기록법 두 가지를 모두 이용해 하루에 섭취한 칼로리를 계산하게 하였습니다. 세 기자 각각이 만들어낸 두 개의 측정치를 비교한 것이 바로 위의 시각화 결과 입니다. 하루 에너지 섭취량이 2,000 kcal을 언저리인데, 두 방법의 오차가 1,000 kcal까지 발생하네요. 그렇다면 FFQ에 기반한 그 많은 식품의 효과/부작용에 대한 보고들을 얼마나 믿어야 하는 것일까요?\n----------------------------\n여기까지 데이터 저널리즘이 무엇인지, 왜 필요한지, 그리고 데이터 저널리즘의 가치를 특별하게 하는 효과적인 전략에는 어떠한 것들이 있는지를 이야기했습니다. 하지만, 이러한 것들을 안다고 해서 데이터 저널리즘을 ‘어떻게’ 하는지를 알게 되었다고 볼 수는 없겠지요. 이 교재는 무엇보다 ’어떻게’에 관한 내용을 담으려 하고 있습니다. 따라서 다음 장부터는 데이터 저널리즘의 방법에 대한 이야기를 주로 하도록 하겠습니다.\n앞서 데이터 저널리즘이 무엇인가에 대해 이야기 하면서, 데이터 저널리즘은 데이터 사이언스의 ‘방법’을 이용한 저널리즘이라는 언급을 했습니다. 하지만, ’데이터 사이언스’ 라는 용어 역시 ‘데이터 저널리즘’ 만큼이나 혹은 그 보다 더 자주 들어보았지만, 무엇인지 알 수 없는 용어이기도 하지요. 이 교재의 내용 상 그에 대해 자세히 이야기할 수는 없지만, 일반적으로 ’데이터 사이언스’는 컴퓨터 공학과 통계학 도구와 분석자의 관심 분야에 지식이 결합한 것이라고 말하는 경우가 많습니다. 이 교재의 맥락에서 분석자라고 한다면, 바로 기자일테니, 기자가 관심이 있는 사회 현상에 대한 지식과 컴퓨터 공학, 통계학의 도구를 결합한 것을 기자들의 데이터 사이언스, 즉 데이터 저널리즘이라고 할 수도 있겠네요. 비슷하게 앞서 언급한 앤드류 플라워는 데이터 저널리즘을 ’기한이 짧은 양적 사회과학 분석’이라고 정의하기도 했습니다.\n따라서, 데이터 저널리즘을 잘 하기 위해서는 컴퓨터 공학, 통계학의 도구들을 잘 다루는 것이 먼저 중요합니다. 여기에 대해서는 앞으로 긴 시간을 들여 연습하게 될 것입니다. 하지만, 그 전에 사회 현상이라는 분석하고자 관심 분야를 컴퓨터 공학과 통계학이라는 과학적 도구와 연결시키는 방식 역시 알아야 합니다. 사회 현상은 아무 번역 작업 없이 컴퓨터가 분석할 수 있는 숫자로 표현할 수는 없기 때문이죠. 그래서 다음 장은 그 번역 방법에 대한 이야기를 조금 하려고 합니다. 이는 흔히 대학교 수업 시간에 &lt;사회과학 방법론&gt;, 또는 &lt;사회조사 방법론&gt;이라는 과목에서 배우는 내용과 유사한데요, 여기서는 데이터 저널리즘을 위한 최소한만을 복습한다는 느낌으로 읽어주시면 좋겠습니다.\n데이터 획득을 포함한 데이터 저널리즘의 과정 추가 필요?\n버스 -&gt; 사모펀드 (데이터 저널리즘?)\n하지만, 가치는 저널리즘.\nhttps://blog.devgenius.io/create-an-expected-goals-model-for-any-league-in-minutes-in-python-972b2423dc4b"
  },
  {
    "objectID": "journalism.html#footnotes",
    "href": "journalism.html#footnotes",
    "title": "1  데이터 저널리즘이란",
    "section": "",
    "text": "이러한 이른바 ’편향’은 사실 꼭 기관의 정치적 성향 때문에 나타난다고만은 할 수 없습니다. 응답자를 모으는 방법의 차이 때문에 발생하는 경우도 많기 때문이죠.↩︎"
  },
  {
    "objectID": "ds.html",
    "href": "ds.html",
    "title": "2  보도를 위한 데이터과학 기초",
    "section": "",
    "text": "작성 예정\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다.\n이 페이지는 목차 생성을 위해 임시로 만들어졌습니다."
  },
  {
    "objectID": "install.html#r과-rstudio-처음-보기",
    "href": "install.html#r과-rstudio-처음-보기",
    "title": "3  R과 Rstudio 처음 이용하기",
    "section": "3.1 R과 Rstudio 처음 보기",
    "text": "3.1 R과 Rstudio 처음 보기\n이제 R과 Rstudio를 살펴보도록 하지요. 여기서는 여러분이 R과 Rstudio를 이미 설치했다고 가정할 것입니다. 만약 여러분이 R과 Rstudio을 전혀 접해본 적이 없어 설치부터 시작해야 한다면, 부록으로 실어둔 [Chapter -@appendix-install]을 참조해 주시기 바랍니다.\n먼저, R은 윈도우 시작 버튼을 눌러 실행할 수 있습니다. 시작 화면에서 전체 애플리케이션을 열면, 여러분의 컴퓨터에 설치된R은 보통 다음과 같이 나타납니다.\n\n\n\n윈도우즈에서 R 실행하기\n\n\n제 경우에는 여러 버전의 R을 설치하다보니 여러 가지의 R이 보이는데요, 그 중에서 버전이 가장 높은 것을 선택하시면 됩니다. i386과 x64는 여러분이 사용하는 컴퓨터의 환경과 관련이 있는데, 대부분의 요즘 컴퓨터는 x64라고 생각하시면 됩니다. 따라서 위의 경우에는 R x64 4.1.3을 선택하면 되겠네요. 이를 실행하면 다음과 같은 화면이 나타나게 됩니다.\n\n\n\nR 화면\n\n\n화면에 가장 크게 보이는 하얀 창이 바로 R의 핵심인 콘솔(Console) 입니다. 여기에 이러저러한 명령을 하고 엔터를 치면 R은 해당 명령을 수행한 결과를 표시해 줍니다. R을 사용하는 가장 단순한 방법은 계산기 처럼 활용하는 것입니다. 예컨대 2+1이라는 연산을 한다고 해 볼까요? 그 때는 가장 단순하게 다음과 2+1이라고 콘솔에 쓰시고 엔터키를 치시면 됩니다. 그러면 다음과 같은 결과를 볼 것입니다.\n\n2+1\n\n[1] 3\n\n\n물론, 여러분이 나중에 작성하게될 코드는 이 보다 훨씬 복잡합니다. 간단하게는 몇 줄, 조금 복잡한 분석을 한다면 수백, 수천줄 짜리 코드를 작성하는 일도 많죠 (이 교재에서는 10줄, 고작해야 20줄을 넘는 일도 거의 없을 것입니다. 그 정도로도 당분간 충분하니 걱정마세요!). 그렇다면 코드를 한줄 쓰고 실행하는 이런 단순한 방식은 아무래도 불편하겠지요. 그것이 아니더라도, 위의 화면은 무엇인가 90년대 컴퓨터에서나 돌아갈 것 같은 구닥다리 같은 느낌이 있지요. 사실 앞서 이야기한 R의 다양한 기능을 최대한 활용하기 위해서 대부분의 사람들은 위와 같은 화면에서 R을 사용하지 않습니다. 대신 Rstudio를 사용하지요.\n여러분 컴퓨터에 설치된 Rstudio를 사용하는 가장 간단한 방법은 윈도우즈 화면 하단 시작 버튼 옆의 검색창에 ’Rstudio’라고 검색해 보는 것입니다. Rstudio가 올바르게 설치되어 있다면, 다음과 유사한 화면을 보게 될 것입니다.\n\n\n\nRstudio 시작\n\n\n이제 Rstudio를 선택해서 프로그램을 실행시키면 다음과 같은 화면이 나타납니다.\n\n\n\nRstudio 첫 화면\n\n\n바탕화면은 초기설정에 따라 위와 같이 어두운 색이기도, 밝은 색이기도 합니다. 아무래도 R을 실행했을 때보다 어딘가 프로패셔널해보이기도 하지요? Rstudio는 R을 편리하게 사용할 뿐만 아니라, R의 더 많은 기능을 이끌어내기 위해 만들어낸 인터페이스라고 생각하시면 됩니다. 전문적인 용어로는 통합개발환경(IDE)라고 하지요. 비유하자면, R가 엔진이라면, Rstudio는 여러분이 직접 운전하는 자동차와 같은 관계이지요. 엔진을 이용해 직접 가능한 탈것을 만드는 사람은 극히 제한적이듯, 대부분의 사람들은 Rstudio를 사용하지, R을 직접 사용하지 않습니다. 따라서, 여러분들 역시 앞으로 Rstudio만을 사용하게 될 것입니다.\n\n\n\nR과 Rstudio 간의 관계\n\n\n위 화면에 보이는 가장 큰 공간은 R의 콘솔 입니다. 앞서 본 콘솔과 같은 콘솔이지요. 따라서 앞서 했던 것처럼 2+1라고 치고 엔터를 치면 아까와 같은 결과가 나올 것입니다. 그러면, 결국 모양만 조금 세련되게 바뀐 것이냐고 반문하실 수 있지만, 물론 그렇지 않습니다. 다음 장에서 프로젝트와, Quarto라는 환경을 설명하면서, Rstudio가 어떻게 컴퓨터 연산과 기사 작성을 동시에 효율적으로 할 수 있도록 도와주는지 살펴보겠습니다."
  },
  {
    "objectID": "basic.html#변수-함수-할당",
    "href": "basic.html#변수-함수-할당",
    "title": "4  R 프로그래밍 기초",
    "section": "4.1 변수, 함수, 할당",
    "text": "4.1 변수, 함수, 할당\nR의 작동 방식을 이해하기 위해서, 먼저 컴퓨터가 작동하는 방식에 대해서 간단하게만 복습해 봅시다. 컴퓨터에 데이터를 저장되는 곳은 크게 세 군데가 있습니다.\n연산장치(CPU, GPU) - 메모리 - 저장장치(HDD, SSD)\n이는 ’악마의 두뇌’를 가졌다고 일컬어지기도 하는 저 유명한 수학자 존 폰 노이만(John von Neumann; 1903-1957)이 고안해 낸 컴퓨터의 구조입니다. 아직 소개하지 않았지만, 여러분이 사용할 데이터들은 HDD, SSD와 같은 저장 장치에 살고 있습니다. 파일을 저장한다는 행위는 여러분들도 익숙하실 것이라고 믿습니다. 하지만, 여러분들이 데이터를 이용해서 어떤 계산을 하고 싶다면, 그 계산은 저장 장치가 아니라 ’연산장치’에서 일어납니다. CPU도 아마 많이 들어보셨을테고, 최근 인공신경망(ANN)이나, 암호화폐 채굴이 CPU 대신 GPU라는 연산장치 위에서 돌아간다는 이야기도 들어보셨을 것입니다. CPU건, GPU건, 컴퓨팅이라는 것은 결국 그 ’연산장치’들이 어떤 계산을 해 주기를 바라는 것이지요.\n문제는 저장장치에 있는 데이터를 연산장치가 바로 사용하는 것이 아니라는 것입니다. 연산장치가 계산을 하기 위해서는 중간 단계에 해당하는 메모리 위에 값이 기록되어야 합니다. 그리고 아마도 여러분들이 알고 계실 것처럼, 메모리에 기록된 데이터는 휘발합니다. 즉, 컴퓨터 전원이 꺼지면 없어지는 것이죠. 이 때문에 저장장치들이 필요합니다.\n그런데, 메모리에 대해서는 전원이 꺼지면 데이터가 휘발된다는 것 말고도꼭 알아야 하는 것이 있습니다. 메모리 위에 기록된 값은 ’이름’이 없으면 존재하지 않는 것이나 다름 없다는 사실입니다. 이게 무슨 말인지 알기 위해 다음과 같은 예를 살펴 봅시다.\n\n3+4\n\n[1] 7\n\n\n이러한 연산이 이루어지기 위해서는 3이라는 ’값’과 4라는 ’값’이 메모리에 먼저 기록되어야 합니다. 그 다음에 연산 장치가 메모리에 저장된 두 값을 더하는 ’연산’을 해 준 후, 그 결과 값이 7을 메모리 위에 기록합니다. 우리는 메모리 위에 기록된 결과를 모니터를 통해 보는 셈입니다. 그런데, 문제는 3, 4, 7이라는 모든 값에 별도의 이름을 붙이지 않았다는 것이지요. 앞서 말했듯이 ’이름’이 없는 값은 존재하지 않는 것이나 다름 없습니다. 따라서, 우리는 메모리에 쓰여진 이 값들을 다시 사용할 수 없습니다. 모니터에서 한 번 확인하고 날려보낸 것입니다.\n이는 반대로 이야기 하면, 이름을 부여한다면, 적어도 이름을 부여하는 프로그램, 즉 우리의 경우 R을 켜 놓은 동안은 재사용할 수 있다는 것입니다. 위의 프로그램을 다시 써 보죠.\n\na &lt;- 3\nb &lt;- 4\nc &lt;- a + b\nprint(c)\n\n[1] 7\n\n\n모니터에서 확인하는 결과는 같습니다. 그러나 우리는 몇 가지 작업을 더 했는데요, 3과 4를 각각 a와 b라는 이름에 할당(assign) 했습니다. 이름을 부여한 것이지요. 또 a에 해당하는 값과 b에 해당하는 값을 더한 결과 역시 c라는 이름에 할당했습니다. 이제 이 값들은 이름이 있으니 R을 켜둔 동안은 다시 불러 사용할 수 있는 것입니다.\n\na * b\n\n[1] 12\n\n\n다음 두 가지를 꼭 기억하세요. 이를 기억하고 있는 것은 앞으로 불필요한 에러를 피하는데 큰 도움이 됩니다.\n\n메모리 위에 쓰여진 값은 휘발한다 (전원이 꺼지면 없어진다)\n메모리 위에 쓰여진 값은 이름이 없으면 없는 것이나 다름 없다\n\n이제 앞으로 사용할 몇 가지 용어를 정의하도록 하죠.\n\n값(value): 데이터 그 자체\n변수(variable): 거기에 붙은 이름\n할당(assign): 값을 변수로 만드는 행위. R에서는 &lt;- 부호를 사용함. (사실은 =을 사용할 수도 있지만, 구분하겠습니다.)\n\n\n\n\n값-변수-할당의 관계\n\n\n사람의 언어에 비유해서 설명하자면, 값과 변수는 명사, 또는 목적어에 해당합니다. 많은 경우에는 이렇게 주어진 대상에 어떤 행위를 하고 싶어하지요. 우리는 그것을 연산이라고 합니다. 그리고 그러한 연산을 문법으로 표현한 것을 함수(function)라고 하지요. 인간의 언어에서라면 함수는 동사에 해당합니다.\n그림\n우리는 위의 예에서 이미 함수를 보았습니다. print()가 그것입니다. 이것은 주어진 값을 콘솔에 출력하는 동작을 의미하는 것이니 동사라고 할 수 있습니다. 그러면 동사와 명사를 구분하듯, R에서 변수와 함수를 구분할 수 있을까요? 구분할 수 있습니다. 여러 방법이 있지만, 가장 간단한 방법은 문자열 뒤에 괄호가 있는지 보는 것입니다. 변수는 괄호가 없습니다. 하지만, 함수는 print()처럼 괄호가 있지요.\n괄호는 왜 있는 것일까요? 괄호 안에 무언가를 써넣어야 하기 때문입니다. 즉, 함수가 표현하는 행위의 대상이 되는 목적어를 집어 넣어야 하기 때문이죠. 예컨대 print(c)에서 c라는 변수는 바로 그 목적어에 해당하요. 앞서 값이나 변수가 목적어의 역할을 하게 될 것이라고 했던 것을 기억할 것입니다. print(c)를 사람의 언어로 표현하면 다음과 같습니다.\n\nc를 콘솔에 print()하라.\n\n\n\n\n함수의 작동\n\n\n이렇게 값이나 변수가 함수가 하는 연산의 대상이 되면, 즉, 함수의 괄호 안에 들어가면, 이를 입력값(input), 또는 인수(argument)라고 합니다. 입력값을 받았으니 함수는 연산의 결과로 출력값(output)을 내어놓겠지요. 사실 더 정확한 표현은 다음과 같습니다.\n\nprint(x=c)\n\n[1] 7\n\n\n여기서 x는 print()라는 함수의 매개변수(parameter), c는 그 매개변수에 집어넣은 인수, 또는 입력값입니다. 매개변수는 print()라는 함수가 그 내부에서 사용하는 변수입니다. print()라는 함수는 내부에서 x라는 변수를 이용해 행위를 하지, c라는 함수 밖에 존재하는 변수에 대해서는 알지 못합니다. 그런데 x=c라고 하는 순간, 이용자는 함수에게 “네가 이용할 x가 바로 바로 c라는 변수에 들어있는 값이야”라고 연결해 주는 것입니다.\n[함수와 인수](pics/install/parameter_argument.pngㅑ{width=50%}\n그러면 print()는 자신이 이용하는 x라는 그릇에 c에 이미 연결되어 있는 값을 담고 그것을 출력하는 행위를 하게 됩니다.\n그런데 왜 첫번째 예에서는 x=을 생략하고 print(c)라고 했는데도 작동했을까요? 그것은 print() 함수 자체가 첫번째로 입력한 숫자를 x에 대응하는 인수로 자동으로 인식하도록 프로그램 되어 있기 때문입니다. 무언가를 출력하라고 하는 명령은 수없이 사용하게 될텐대, 매번 매개변수를 반복행 하면 너무 귀찮겠지요.\n그런데, 모든 함수가 인수를 필요로 하는 것은 아닙니다. 자연언어에서 동사 역시 자동사와 타동사로 구분되는 것과 같은 이치입니다. 예컨대 다음과 같은 함수는 인수 없이 실행 됩니다.\n\ngetwd()\n\ngetwd()라는 함수가 working directory 즉, 현재 R이 작업을 하고 있는 컴퓨터의 경로를 표시하는 동작을 의미하니, 인수가 따로 필요하지는 않겠지요. 어떤 경우에는 함수가 인수를 필요로 하지만 (즉, 타동사 이지만), 인수를 쓰지 않아도 작동하는 경우가 있습니다. 그런 경우에는 함수가 자신이 필요로 하는 인수에 대해 디폴트 값을 가지고 있는 경우 입니다. 즉, 사용자가 아무 인수도 주지 않으면 자동으로 인수로 가정하는 값이 있는 경우도 있다는 것입니다. 우리가 “밥 먹어”하는 대신 상대방이 알아들을만 한 상황에서는 “먹어”라고 하는 것과 비슷한 이치입니다."
  },
  {
    "objectID": "basic.html#데이터의-타입과-구조",
    "href": "basic.html#데이터의-타입과-구조",
    "title": "4  R 프로그래밍 기초",
    "section": "4.2 데이터의 타입과 구조",
    "text": "4.2 데이터의 타입과 구조\nR은 여러가지 종류의 데이터를 다룰 수 있습니다. 하지만 컴퓨터 프로그램은 인간처럼 연산을 하면서 주어진 데이터가 숫자인지, 문자인지 직관적으로 결정할 능력을 가지고 있지 않습니다. 연산이 이루어지기 전에 해당 데이터가 숫자인지, 문자인지, 미리 정해놓아야 합니다. 이렇게 정해 놓은 데이터의 종류를 데이터의 타입(Type)이라고 합니다. 그와는 달리, 타입을 가지고 있는 복수의 값을 엮어 놓는 방식도 여러가지가 있습니다. 우리는 그 다양한 방식들을 데이터의 구조(Structure)라고 부를 것입니다. 데이터의 타입과 구조는 매우 많은 종류가 있고, 심지어 이용자가 만들어낼 수도 있는데, 여기서는 일반적인 데이터 분석 및 시각화를 위해 자주 사용하게 되는 것만 짚고 넘어가려고 합니다.\n\n4.2.1 데이터 타입\n\nnumeric: 1, 1.2, -3.42와 같이, 우리가 일상생활에서 사용하는 실수의 개념에 가깝습니다.\ncharacter: 이는 문자를 의미합니다. “a”, “b”, “3-2”와 같이 따옴표로 둘러싸 문자를 표현합니다. 사람의 눈에는 숫자이더라도 “1”라고 쓰면 R은 이를 문자로 인식합니다. 따라서 \"1\"-\"2\"와 같은 명령어를 치면 에러가 발생합니다.\nlogical: 이는 TRUE 또는 FALSE 두 개의 값을 갖는 논리 연산을 위한 데이터 타입 입니다. 따옴표를 사용하지 않고, 대문자로만 표기했다는 것에 유의하세요. R은 소문자와 대문자를 구분하기 때문에, True 또는 False라고 쓰는 순간 완전히 다른 의미를 가지게 됩니다. 또 \"TRUE\", \"FALSE\"라고 쓴다면, logical 타입이 아닌 character 타입으로 인식됩니다. logical 타입은 다른 언어에서는 Boolean 타입이라고 불리기도 합니다.\n\n그 외에 특별한 데이터가 있습니다. NA는 값이 없음을, NaN은 계산 결과가 숫자로 표현될 수 없었음을 이야기 합니다. 예컨대, 0을을 0으로 나누려고 한다면, 그 결과값은 NaN이 됩니다.\n\n0/0\n\n[1] NaN\n\n\n정수를 뜻하는 integer, 복소수를 뜻하는 complex 타입도 있지만 당장 다룰 일이 별로 없을 것이므로, 건너뛰도록 하겠습니다. 또 하나 중요한 데이터 타입으로는 factor라는 것이 있는데요, 이것은 바로 이해가 어려우니, 나중에 사용할 때 설명하도록 하겠습니다.\n\n\n4.2.2 데이터 구조\nR의 특이한 점 중 하나는 한 개의 값이 따로 존재한다는 개념이 없다는 것입니다. 이상하게 들리겠지만, 일단 이해를 위해 다음과 같은 예를 보도록 하죠.\n\n2\n\n[1] 2\n\n\n콘솔에서 2라고 치고 엔터를 누르면, R은 이 값을 그대로 반복해서 보여주는데요, 그 옆에 [1]이라고 쓰여져 있는 것이 보일 것입니다. 그것은 2가 값들을 모아놓은 집합의 첫번째 요소라는 뜻입니다. 우리에게는 그냥 하나의 숫자 같지만, R은 여러개의 값을 담을 수 있는 그릇이 있는데, 그 안에 들어있는 값이 하필이면 한 개 였고, 그 한 개의 값이 첫번째 요소이니(물론 마지막 요소이기도 합니다) [1]이라고 표시한 것입니다. 이렇게 R은 항상 모든 값이 여러개의 값을 가질 수 있는 그릇에 담겨있다고 생각하고, 그릇이 없는 값 같은 것은 존재하지 않는다고 봅니다. 이렇게 값들을 담을 수 있는 그릇을 데이터 구조(structure)라고 부릅니다.\n그릇 그림\n\n4.2.2.1 (1) 벡터(vector)\nR이 사용하는 가장 간단한 데이터 구조는 벡터 입니다. 벡터는 같은 데이터 타입을 가진 값들의 순서가 있는 집합이라고 생각하면 좋습니다. 사실 위에서 본 [1] 2라는 출력 값은 “2라는 값 하나만 가지고 있는 벡터”라는 뜻입니다. 이제 여러개의 값이 담겨 있는 벡터를 보겠습니다.\n\nvecNum &lt;- c(1,2,3,4,5)\nvecNum\n\n[1] 1 2 3 4 5\n\n\n\nvecChar &lt;- c('a', 'b', 'c')\nvecChar\n\n[1] \"a\" \"b\" \"c\"\n\n\n위에서 보듯 c()라는 함수를 이용해서 여러 개의 값을 만들 수 있습니다. 또 값을 변수에 할당하는데 사용했던 &lt;- 연산자를 이용해 벡터 전체를 하나의 변수에 할당할 수도 있습니다. 위의 예에서 vecNum은 numeric 데이터 타입만을 가지고 있는 벡터이지만, vecChar의 경우에는 character 타입으로만 이루어진 벡터입니다.\n\n\n\n4.2.3 (2) 리스트(list)\n리스트는 ‘키(key)’라고 불리는 데이터의 이름과 그에 상응하는 ’값(value)’ 사이의 연결로 표현되는 데이터 구조 입니다. 이렇게 말하면 조금 난해하지만, 예를 보면 간단합니다.\n\npersons &lt;- list(id = c(1, 2, 3),\n                gender = c(\"Male\", \"Female\", \"Female\"),\n                height = c(173, 165, 170))\npersons\n\n$id\n[1] 1 2 3\n\n$gender\n[1] \"Male\"   \"Female\" \"Female\"\n\n$height\n[1] 173 165 170\n\n\n위의 예에서 c(1,2,3)과 같은 정보는 ’값’에 해당하고, id, gender, height과 같은 값들은 이 값들과 연결된 ’키’에 해당합니다. 이렇게 리스트를 만들어 놓으면 벡터보다 직관적으로 데이터의 관심있는 일부분을 불러올 수 있습니다. 예컨대 위에서 만든 리스트에 담긴 3명에 대한 정보 중, 성별만을 알고 싶다면 다음과 같이 명령하면 됩니다.\n\npersons$gender\n\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n위의 예에서 바로 알 수 있듯이 $ 연산자는 리스트에서 특정 키에 해당하는 값을 부르기 위한 역할을 합니다. 당장은 리스트 보다 벡터를 자주 사용하게 되겠지만, 곧 리스트가 유용한 경우가 자주 발생하게 됩니다.\n\n\n4.2.4 (3) 데이터프레임(Data Frame)\n데이터 프레임은 우리가 잘 알고 있는 표(table)를 의미합니다. 예컨대 위에서 사용한 리스트의 예를 데이터 프레임으로 만들어 볼까요?\n\ndf &lt;- data.frame(id = c(1, 2, 3),\n                 gender = c(\"Male\", \"Female\", \"Female\"),\n                 height = c(173, 165, 170))\ndf\n\n  id gender height\n1  1   Male    173\n2  2 Female    165\n3  3 Female    170\n\n\n우리에게 익숙한 테이블 모양으로 출력이 된다는 것을 알 수 있습니다. 예컨대 데이터로 엑셀 파일이 있어 이를 R을 이용해 분석하려 한다면, 이렇게 데이터프레임으로 인식시키는 것이 가장 직관적이겠지요. 데이터 프레임은 여러분들이 가장 자주 보게 될 데이터 구조 입니다."
  },
  {
    "objectID": "basic.html#서브세트subset",
    "href": "basic.html#서브세트subset",
    "title": "4  R 프로그래밍 기초",
    "section": "4.3 서브세트(Subset)",
    "text": "4.3 서브세트(Subset)\n앞서 리스트에 대해 이야기 하면서 $ 연산자를 통해 데이터의 일부만 보는 작업의 예를 보았습니다. 이렇게 데이터의 일부만 보는 행위를 서브세트라고 합니다. 서브세트를 분석 목적에 맞게 잘 하는 것은 데이터 과학에서 가장 중요하고, 자주 하게 되는 테크닉 입니다. 우리는 여기서 배우는 서브세트 기술 보다 조금 더 명료한 방법을 앞으로 사용하게 되겠지만, 이를 100% 피해갈 수는 없으므로, 가장 기초적인 것만 보도록 하겠습니다.\n\n4.3.1 벡터\n일단 벡터의 서브세트를 이해하기 위해 다음과 같은 예를 보겠습니다.\n\na &lt;- c(4, 5, 6, 7, 8)\na[2]\n\n[1] 5\n\n\n이렇게 벡터를 서브세트 하기 위해서는 간단하게 [] 안에 몇 번째 값을 보고 싶은지를 써 주면 됩니다. 이런 것도 가능합니다.\n\na[2:4]\n\n[1] 5 6 7\n\n\n여기서 2:4는 “2에서 4까지의 정수”라는 뜻으로 c(2,3,4)라고 쓴 것과 동일한 효과를 갖습니다. 따라서, 두번째, 세번째, 네번째 값이 서브세트 된 것이지요. 또 이런 방식으로 특정 순서에 있는 값만 제외하는 것도 가능합니다.\n\na[-2]\n\n[1] 4 6 7 8\n\n\n\n\n4.3.2 리스트\n이번엔 아까 썼던 것과 같은 리스트 예를 사용해 보겠습니다.\n\npersons &lt;- list(id = c(1, 2, 3),\n                gender = c(\"Male\", \"Female\", \"Female\"),\n                height = c(173, 165, 170))\n\n아까 persons$gender라고 써서 subset하는 방식으로 봤습니다. 똑같은 효과를 갖는 명령어로 다음과 같이 쓸 수 있습니다.\n\npersons[[\"gender\"]]\n\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n대괄호를 두번 써 주었다는 것(‘[[’)에 유의해 주세요. 정확하게 같은 결과가 나오지만, 이 때는 키(key)를 따옴표를 써서 문자열로 제시해 주어야 합니다. 사실 persons$gender는 이 코드를 조금 더 간단하게 쓰기 위한 약어라고 생각하시면 되겠습니다. 사실 gender는 persons 리스트에서 두번째 키이기 때문에 다음과 같이 써도 결과는 같습니다.\n\npersons[[2]]\n\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n대괄호를 한번 쓰는 것은 조금 다른 의미를 갖습니다.\n\npersons[2]\n\n$gender\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n결과에서 보는 것처럼, persons[[2]]는 persons라는 list의 두번째 키/값의 쌍에서 값만 되돌려달라는 의미입니다. 따라서 되돌려받는 값은 값에 해당하는 벡터, c(\"Male\", \"Female\", \"Female\")이 됩니다. 반면, persons[2]는 두 번째 키/값의 쌍 전체를 돌려달라는 돌려달라는 의미이므로, 반환값 역시 리스트인 list(gender = c(\"Male\", \"Female\", \"Female\")) 형태가 됩니다. 따라서, persons[2:3]과 같은 표현도 자연스럽게 정의가 되겠지요.\n\n\n4.3.3 데이터프레임\n사실 여러분은 데이터프레임을 서브세트 할 일이 가장 많을 것입니다. 사실 데이터프레임을 서브세트 하는 방식은 리스트와 매우 유사합니다. 아까 만든 df 데이터프레임을 생각해 보면,\n\ndf$gender\n\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n는 리스트처럼 gender열의 값에 해당하는 벡터를 돌려주고, 이는 다음과 같습니다.\n\ndf[['gender']]\n\n[1] \"Male\"   \"Female\" \"Female\"\n\n\n반면 숫자를 이용한 서브세팅도 리스트와 유사합니다.\ndf[[2]]라고 하면 두번째 열(column)에 해당하는 벡터를, df[2]라고 하면 두번째 열을 그 값에 해당하는 벡터값만이 아니라, 열의 이름인 gender가 더해진 열 한 개짜리 데이터프레임을 돌려줍니다. 그런데, 이런 방식 말고 리스트와 다른 방식의 서브세팅도 있습니다. 이는 데이터프레임을 다룰 때에는 값을 취할 행과 열을 모두 지정해 주는 경우도 많기 때문이지요. 그 방식은 다음과 같습니다.\n\ndf[2,3]\n\n[1] 165\n\n\n이 명령어는 두 번째 행, 세 번째 열에 해당하는 값을 취하라는 뜻입니다. 그렇다면 앞에서 배운 : 연산자를 이용해 다음과 같은 표현도 가능합니다.\n\ndf[1:2, 2:3]\n\n  gender height\n1   Male    173\n2 Female    165\n\n\n물론, 이는 첫번째 부터 두번째 행, 두번째부터 세번째 열에 해당하는 값을 데이터프레임 형태로 되돌려달라는 의미입니다.\n이렇게 연속된 숫자를 이용한 서브세팅 말고 첫번째와 세번째 열에 해당하는 값을 돌려달라고 할 수도 있겠지요? 이 때는 숫자로 이루어진 벡터를 이용합니다.\n\ndf[ , c(1,3)]\n\n  id height\n1  1    173\n2  2    165\n3  3    170\n\n\n그런데 이번에 행을 지정하는 부분 (쉼표 앞 부분)이 비어 있습니다. 이는 행 전체에 해당하는 정보를 달라는 것을 뜻합니다.\n이것 말고도 서브세팅에 이용할 수 있는 기술은 몇 가지 더 있는데요, 우리는 사실 이 방식을 사용하지 않을 예정입니다. 왜냐하면, 이렇게 R이 기본적으로 제공하는 방식은 가독성이 그리 좋지 않아, 몇 일만 지나도 내가 무엇을 하려고 했던 것인지 잊어버리는 경우가 많습니다. 예컨대, 위의 예에서 첫번째, 세번째 열이 무엇이었는지 기억하는 사람은 별로 없겠지요. 또 내가 스스로 쓴 코드를 이해하기 어렵다는 것은 다른 사람이 이해하기는 더 어렵다는 뜻입니다. 이는 협업을 자주 해야 하는 데이터 저널리즘에서는 치명적인 문제라고 할 수 있습니다. 따라서 우리는 다음 장에서 가독성과 협업 효율성이 높은 다른 방식을 이용할 것입니다."
  },
  {
    "objectID": "basic.html#조건predicate",
    "href": "basic.html#조건predicate",
    "title": "4  R 프로그래밍 기초",
    "section": "4.4 조건(Predicate)",
    "text": "4.4 조건(Predicate)\n여기서 말하는 조건은 쉽게 말하면 질문 입니다. 코딩을 하다보면 질문을 할 일이 정말 많은데요, 특히 우리가 자주 사용하는 조건(Predicate)을 이용한 질문들은 그 대답이 logical 값, 즉, TRUE 또는 FALSE가 됩니다. R에게 참, 거짓을 물어보는 방식은 아주 많은데요, 그 중 아주 많이 사용하는 것들로는 다음과 같은 것들이 있습니다.\n\n==, !=, %in%, is.na(), &gt;, &gt;=, &lt;, &lt;=\n\n==는 “두 값이 같은지”를 물어보는 것입니다. 예컨대,\n\n2 == 2\n\n[1] TRUE\n\n\n\n2 == 3\n\n[1] FALSE\n\n\n\na &lt;- 2\na == 2\n\n[1] TRUE\n\n\n등이 가능합니다. 마지막 예에서 알 수 있듯이, == 앞 뒤에는 값이 와도, 변수명이 와도 좋습니다. 여기서 등호가 2개라는 것에 유의하세요. R에서 =와 ==는 전혀 다른 것입니다. =는 &lt;-와 유사하게 할당의 의미로, ==는 질문의 의미로 사용합니다.\n반면, !=는 “구 값이 다른지”를 물어보는 것이겠지요. 예컨대,\n\n2 != 3\n\n[1] TRUE\n\n\n두 값이 다르기 때문에 이에 대한 대답은 TRUE 입니다. 반면 2!=2의 답은 FALSE겠지요. !=은 등호 앞에 !를 붙여서 만드는데, !는 R에서 not을 의미합니다.\n%in%은 해당 연산자 앞의 값이 연산자 뒤에 나오는 벡터에 속하는지를 물어보는 조건 입니다. 예컨대 다음과 같은 방식입니다.\n\n2 %in% c(2,3,4,5)\n\n[1] TRUE\n\n\n\n6 %in% c(2,3,4,5)\n\n[1] FALSE\n\n\n마지막으로 in.na()는 결측값이 있는 곳에 TRUE를 되돌려주는 조건입니다.\n\nis.na(c(2,3,NA,5))\n\n[1] FALSE FALSE  TRUE FALSE\n\n\nis.na()는 앞에서 다룬 조건들과 몇 가지 점에서 조금 다릅니다. 먼저, 질문을 하는 방식에 두개의 다른 값을 이용하는 것이 아니라 하나의 값(위의 예에서는 벡터 c(2,3,NA,5))만을 사용합니다. 둘째, 그렇기 때문에 조건의 형태가 일반 함수 형태로 되어 있고, 괄호 안에 질문의 대상이 되는 값을 써 넣도록 되어 있습니다. 셋째, 대답이 하나의 TRUE 또는 FALSE가 아니라, 벡터의 모든 요소에 대해서 주어집니다. 세번째 요소만 결측값이니, 답이 c(FALSE, FALSE, TRUE, FALSE)가 되는 것이지요. 만약 반대로 “결측값이 아닌 곳”을 찾으려 한다면, !이 부정을 의미한다고 하였으니 다음과 같이 쓰면 되겠지요.\n\n!is.na(c(2,3,NA,5))\n\n[1]  TRUE  TRUE FALSE  TRUE"
  },
  {
    "objectID": "quarto.html#프로젝트",
    "href": "quarto.html#프로젝트",
    "title": "5  프로젝트와 노트북: 기사작성과 코딩을 동시에!",
    "section": "5.1 프로젝트",
    "text": "5.1 프로젝트\n프로젝트가 어떤 기능인지를 이해하기 위해서는 working directory, 즉 작업경로라는 개념을 이해해야 합니다. 작업경로는 현재 R이 자신이 위치하고 있다고 생각하는 저장장치 안의 폴더를 의미합니다. 보통은 지금 작성하고 있는 코드가 저장되어 있는 곳이 작업폴더가 되지만, 이는 경우에 따라 다릅니다. 현재 작업 폴더가 어디인지를 알기 위해서는 다음과 같은 명령어를 콘솔에서 실행해 보세요.\n\ngetwd()\n\n작업폴더가 중요한 이유는, 저장장치로부터 R이 데이터를 불러올 때, 특별한 이야기가 없으면 작업폴더로부터 불러와야 한다고 생각하기 때문입니다. 하지만, R이 현재 작업폴더로 이용하고 있는 장소와 이용자가 작업폴더라고 믿고 있는 장소 사이에 차이가 있는 경우가 종종 있습니다. 프로그래밍을 처음 해 보시는 분들이 처음에 제일 많이 겪는 에러의 원인입니다.\n작업폴더의 문제를 해결하는 방법은 여러가지가 있지만, 하나의 보도 프로젝트를 위한 코드와 데이터, 즉 모든 파일은 항상 하나의 폴더 안에 저장해 놓도록 ’약속’하는 것입니다. 그 약속을 R에서는 프로젝트라고 부릅니다. Rstudio에서 프로젝트라고 부르는 것의 개념은 정말 단순합니다. 프로젝트는 특정한 작업을 할 때는 항상 사용하기로 미리 정해놓은 폴더 그 이상도 이하도 아닙니다. 예컨대, 지금 저는 이 교재를 쓰기 위해 Rstudio를 사용하고 있는데요, 이 교과서를 쓸 때는 Book이라는 프로젝트를 만들고, 해당 폴더 안에 책의 원고, 코드, 데이터 등을 모두 저장해 둡니다. 교과서를 쓰기 위해 필요한 모든 자료를 하나의 폴더 안에 모두 저장해 두고, Rstudio에게 “난 이 교재를 쓸 때는 Book 폴더만 사용할거야”, 라고 미리 말해두기만 하면, Rstudio에게 “나 이제부터 교재 쓴다”라고 알려주면 Rstudio는 알아서 작업경로를 바꿔줍니다.\n물론 저는 이 교재를 쓸 때 말고도, 다양한 이유로 Rstudio를 사용합니다. 예컨대 어떤 연구를 위해 Research라는 프로젝트를 만들어 두었다고 해 보죠. 그러면 Rstudio에게 “나 이제부터 연구한다” 라고 말해주면 Rstudio는 Research 폴더로 작업 경로를 바꿔줍니다. 그러면 교과서를 쓰다가 연구를 하다가 반복한다고 하더라도 작업경로 때문에 골치아픈 에러를 겪을 일이 없어지겠지요. 여러 개의 기획 기사를 동시에 쓰는 상황이라면, 기사1, 기사2, 기사3에 대한 프로젝트를 따로 만들어 두고 해당 기사를 작성할 때는 해당 프로젝트 안에서 활동하면 헷갈릴 일이 없습니다.\n이렇게만 이야기하면, 프로젝트가 큰 쓸모가 없어보이지만, 동시에 하는 작업의 종류가 늘어날 수록 경로로 인해 발생하는 에러의 빈도는 그야말로 ’기하급수’적으로 늘어납니다. Rstudio의 기능 중에 프로젝트 보다 에러를 줄여주는 기능은 없다고 감히 단언할 수 있으니, R을 처음 배우는 지금부터 꼭 프로젝트를 사용하는 버릇을 들이길 바랍니다.\n그러면, 프로젝트를 어떻게 만들고, 어떻게 프로젝트 사이를 이동하는지를 살펴보겠습니다.\n\n5.1.0.1 새 프로젝트 만들기\n새 프로젝트를 만드는 방법은 간단합니다. Rstudio의 File 메뉴를 선택해보세요. 그러면 드롭다운 메뉴에서 New Proejct라는 기능을 찾을 수 있습니다. 이를 누르면, 다음과 같은 화면이 등장할 것입니다.\n\n\n\n새 프로젝트\n\n\n여기서 프로젝트 명은 새로 만들어질 폴더의 이름이고, 경로는 그 폴더가 만들어질 상위 폴더라고 생각하시면 됩니다. 예컨대 위의 예에서, 저는 Spring2023 폴더 아래 Book이라는 새로운 폴더를 만들어 바로 그 폴더를 프로젝트 폴더로 사용하려는 것이지요.\nOK를 누르고 나면, 몇 초에 걸쳐 프로젝터(=폴더)가 만들어집니다. 프로젝트가 폴더에 불과하다는 것을 확인하기 위해서 해당 폴더를 찾아보지요. 저는 지금 윈도우를 이용하고 있기 때문에 탐색기를 이용하겠습니다.\n\n\n\n폴더에서 프로젝트 찾기\n\n\n새로 폴더가 하나 만들어져 있지요? 그 안에는 Book.Rproj라는 파일도 자동으로 만들어져 있는데, 이 파일은 단지 이 폴더가 그냥 폴더가 아니고 R을 이용한 프로젝트를 수행하기 위한 폴더임을 표시하는 것입니다. 이것은 조금 있다가 서로 다른 폴더 사이를 이동할 때 이용할 것입니다. 자, 이제 우리는 이제 책을 쓰기 위해서는 이 폴더만 사용하게 될 것입니다. 새로 작성한 코드도, 사용할 데이터도 이 폴더 안에 모두 저장하는 것이지요.\n\n\n5.1.0.2 프로젝트 바꾸기\n그런데 이미 복수의 프로젝트를 가지고 있었다면, 프로젝트 사이는 어떻게 왔다갔다 할 수 있을까요? 간단합니다. 다시 File 메뉴를 선택해 보세요. 그러면 Open Project라는 기능이 있을 것입니다. 이것을 선택하면, 일반 탐색기처럼 폴더를 선택할 수 있습니다. 만약 Research라는 프로젝트로 이동하고 싶다고 해당 프로젝트 폴더를 찾아가면 됩니다. Research 프로젝트가 이미 만들어져 있었다면 해당 폴더에는 Research.Rproj라는 파일이 저장되어 있겠지요. 그 파일을 선택한 후, OK를 누르면 이제 Rstudio는 Research 프로젝트로 이동합니다. 이제 저는 연구를 하는 것입니다.\n\n\n\n새로운 프로젝트로 이동\n\n\n그런데, 사실 이렇게 복잡한 방식으로 프로젝트 사이를 이동하는 경우는 많지 않습니다. 더 간단한 방법이 있거든요. 아까 이용한 Open Project 메뉴 아래에는 Recent Projects라는 메뉴도 있습니다. 그 위에 마우스 포인트를 올리면 최근에 이용한 프로젝트의 목록이 나타납니다. 그 목록 중 내가 이동하고 싶은 프로젝트를 클릭하면, 아주 간단하게 프로젝트 사이를 이동할 수 있습니다.\n이제 여러분이 Rstudio를 켜고 작업을 하려고 할 때 처음으로 해야 할 일은 적절한 프로젝트를 이용하는 것입니다. 새로운 작업을 시작한다면? 프로젝트를 만드세요. 만약 프로젝트를 이미 만들어 놓은 작업을 계속하고 싶다면? 지금 Rstudio가 그 작업에 해당하는 프로젝트를 이용하고 있는지 확인하세요. 만약 그렇지 않다면 Recent Projects나 Open Project를 이용해 해당 프로젝트로 이동하면 됩니다. 항상 작업은 그 이후에 시작합니다."
  },
  {
    "objectID": "quarto.html#quarto-노트북",
    "href": "quarto.html#quarto-노트북",
    "title": "5  프로젝트와 노트북: 기사작성과 코딩을 동시에!",
    "section": "5.2 Quarto 노트북",
    "text": "5.2 Quarto 노트북\n우리는 지금까지 R의 기초적인 기능을 살펴보면서, 콘솔이라고 하는 창을 이용해 왔습니다. 이 콘솔이라고 하는 창은 R의 엔진, 실제로 프로그램이 돌아가는 곳이라고 볼 수 있습니다. 하지만 콘솔에서는 코드를 작성하고 엔터키를 누르는 순간, 프로그램이 실행되고 맙니다. 지금까지 작성해 온 간단한 코드라면, 이런 방식으로 충분하겠지만, 만약 수십줄, 많게는 수백줄의 코드를 작성하고, 작성한 코드가 한 번에 실행되기를 바란다면, 이것은 그다지 효율적인 방법이 아니겠지요. 따라서, 대부분 프로그래머들은 컴퓨터 메모장에 글을 쓰듯, 먼저 긴 코드를 작성한 후, 이것이 차례차례 콘솔에서 작동되도록 합니다. 이를 위해 작성한 코드로 이루어진 텍스트 파일을 흔히 ’스크립트’라고 부릅니다. 하지만 이런 스크립트 방식의코드 작성법은 콘솔을 이용한 방법과는 반대로 작성한 코드의 부분부분이 의도한대로 잘 작동하는지 확인하는 것을 어렵게 만듭니다.\n따라서, 우리는 그 중간쯤 되는 ’노트북’이라는 방법을 사용하려고 합니다. 노트북 방법을 사용하면, 코드를 작성하면서 중간중간 결과를 확인할 수도 있고, 프로그램을 모두 작성한 후에는 전체 프로그램을 한 번에 실행할 수도 있습니다. 그리고 그보다 더 좋은 점은 코드와 코드 사이 원하는대로 문서를 작성할 수도 있고, 그 결과를 그대로 문서 파일, 프리젠테이션 파일, 심지어 웹페이지 형태로 바로 추출할 수 있다는 점입니다. 온라인 기사를 작성한다고 생각해 보면, 데이터 분석, 시각화, 기사 작성을 한 문서 안에서 별도의 작업 없이 할 수 있다는 뜻입니다! 따라서, 이 교재에서는 내내 노트북 환경을 사용하도록 하하겠습니다."
  },
  {
    "objectID": "quarto.html#노트북-생성하기",
    "href": "quarto.html#노트북-생성하기",
    "title": "5  프로젝트와 노트북: 기사작성과 코딩을 동시에!",
    "section": "5.3 노트북 생성하기",
    "text": "5.3 노트북 생성하기\n노트북 환경을 이용하는 방법은 여러가지가 있지만, 우리는 “Quarto Document”라는 가장 표준적인 방법을 사용할 것입니다. “Quarto Document”를 사용하려면 새로운 “Quarto Document” 파일을 하나 만들어주면 됩니다. Rstudio 상단의 File 메뉴에서 New File이라고 되어 있는 곳에 마우스 커서를 올려보세요, 그러면 오른쪽에 떠오르는 메뉴에 “Quarto Document”라는 항목이 있을 것입니다. 이를 클릭하면 다음과 같은 창이 떠오릅니다.\n\n\n\nQuarto Document 만들기\n\n\n여기서 지시하는대로 문서의 제목, 작성자(Author)의 이름 등을 입력하세요. 그러면, 파일 하나가 생성됩니다.\n그 다음 Visual이라고 되어 있는 모드를 Source로 바꿔주세요. (Visual 모드를 사용해도 되지만, 우리는 Source 모드를 이용하겠습니다.)\n\n\n\nSource 모드로 전환\n\n\n마지막으로 해당 파일을 저장해 주세요. ‘File’ 메뉴에서 ’Save’를 클릭한 후, 파일명을 정해주면 됩니다. 확장자는 qmd가 됩니다.\n이제 여러분은 노트북 환경을 이용하기 위한 준비가 되었습니다."
  },
  {
    "objectID": "quarto.html#노트북-이용하기",
    "href": "quarto.html#노트북-이용하기",
    "title": "5  프로젝트와 노트북: 기사작성과 코딩을 동시에!",
    "section": "5.4 노트북 이용하기",
    "text": "5.4 노트북 이용하기\n노트북 환경은 구체적으로는 다음과 같습니다.\n\n\n\n노트북 환경\n\n\n이 노트북 환경은 크게 세 부분으로 이루어집니다. 첫번째, ---로 둘러싸여 저자, 제목 등의 정보를 제공하는 부분입니다. 이는 YAML header라고 부르는데요, 꼭 있어야 하는 부분은 아닙니다. 하지만 조금 후에 굉장히 유용해 질 것이므로, 그대로 이용하실 것을 권장합니다. 제목(title)이나, 저자(author)의 내용에 해당하는 부분은 원하는대로 바꾸어도 좋습니다.\n두번째 부분은 코드가 쓰여지는 chunk라고 부르는 부분입니다. chunk는 세 개의 “backtick”, 즉 “역따옴표”로 코드를 둘러싸서 표현합니다. 역따옴표에 익숙지 않다면, 키도드 숫자 1 왼쪽에 있는 키가 역따옴표를 사용하기 위한 키 입니다. 여러분들은 주로 shift 키와 함께 물결 표시를 사용하기 위해 더 자주 사용했을 것입니다. Rstudio는 세 개의 역따옴표 있는 문자를 모두 프로그래밍 코드라고 인식합니다.\n특히, 시작하는 세 개의 역따옴표 옆에 {r}이라고 쓰게되면, 이제 Rstudio는 해당 chunk 안의 모든 문자를 다른 프로그램도 아닌 R 문법으로 작성한 코드라고 생각합니다. 만약, chunk 안에서 R 문법에 어긋나는 문자가 있다면 에러가 발생하게 될 것입니다.\n역따옴표와 사용할 프로그램을 표시하여 (예컨대, ```{r}이라고 표시하여) R 코드임이 명확해지면, Rstudio는 chunk가 시작하는 줄 오른쪽에 작은 플레이 버튼 같은 것을 표시합니다. 이 버튼을 클릭해 보세요. 그러면 해당 chunk에 쓴 R 코드가 실행되고, 그 결과는 해당 코드 바로 밑에 표시됩니다. 이런 식으로 스크립트를 작성하면서, 즉시 콘솔에서처럼 결과도 확인할 수 있게 되는 것이지요.\n마지막 부분은 앞의 두 요소 밖에 있는 모든 문자들 입니다. 이는 물론 일반 텍스트를 뜻합니다. 이 부분은 글을 쓰듯 자유롭게 작성하면 됩니다. 사실 아무 것도 아닌 것 같지만, 이렇게 내가 쓰고 싶은 글과 R 코드, 그리고 R 코드의 결과물까지 하나의 텍스트 파일 위에서 표현할 수 있게 됩니다. 마치 다음 그림 처럼요.\n\n\n\n노트북 환경\n\n\n마치 하나의 웹페이지 화면처럼 보이지 않나요? 실제로 텍스트 파일 상단에 있는 Render 버튼을 누르기만 하면 바로 웹페이지를 만들어냅니다. 더 정확하게는 해당 qmd파일을 일종의 스크립트 삼아, 텍스트 부분은 텍스트로 표현하고, chunk에 해당하는 부분은 코드를 실행시킨 다음, 그 결과까지 모두 포함하여 하나의 HTML 파일을 만들어 냅니다. 여러분이 사용하고 있는 프로젝트 폴더에 들어가보세요. 방금 Render한 qmd파일과 같은 파일명을 가진 HTML 파일이 생성되어 있을 것입니다. 그 파일을 더블클릭하면, 여러분이 사용하는 브라우저를 통해 마치 웹페이지처럼 정돈된 결과물을 볼 수 있습니다.\n방금 Render한 qmd 파일에서 일반 텍스트가 여러분이 작성한 기사 내용, 그리고 chunk가 여러분이 독자들에게 보이고자 하는 데이터 시각화를 시행하는 코드라고 생각해 보세요! 그러면 여러분은 이미 인터넷으로 배포할 수 있는 기사 웹페이지 하나를 만든 셈입니다!"
  },
  {
    "objectID": "quarto.html#마크다운-문법",
    "href": "quarto.html#마크다운-문법",
    "title": "5  프로젝트와 노트북: 기사작성과 코딩을 동시에!",
    "section": "5.5 마크다운 문법",
    "text": "5.5 마크다운 문법\nRstudio가 우리가 작성한 qmd 파일에서 코드에 해당하는 부분, 일반 텍스트에 해당하는 부분을 자동으로 구분하고 다양한 기능을 사용할 수 있게 해줄 뿐만 아니라, 심지어 웹페이지로까지 만들어 주는 것은 우리가 Rstudio가 이해할 수 있는 특정 문법을 따르기 때문입니다. 이 문법을 ’마크다운(markdown)’이라고 부릅니다. 사실 확장자명 qmd에서 “md”가 마크다운(markdown)을 뜻하지요. 앞서 사용한 “—” “```{r}” 이런 것들이 마크다운 문법 중 일부입니다. 마크다운의 문법은 물론 이것 말고도 다양합니다.\n우리는 앞서 Rstudio가 chunk 안에 있는 문자는 코드로 인식해 실행하고, 그 밖의 문자는 텍스트 그대로 표현한다고 했습니다. 사실 이는 정확한 이야기가 아닙니다. 왜냐하면 Rstudio가 chunk 밖의 문자를 일반 텍스트로 인식하는 것은 맞지만, 일반 텍스트에 여러 효과를 부여하기 위한 몇 가지 간단한 문법이 있기 때문이지요. 이러한 문법들은 써도 그만, 안 써도 그만이지만 시각적으로 더 효율적인 웹페이지를 생성하기 위해 유용합니다. 예컨대 다음과 같은 것들이 그 문법에 해당합니다.\n\n5.5.1 글씨체\n*기울임 *\n**굵게**\n~~취소선~~\n`코드`\n# 최상위 제목\n## 2단계 제목\n### 3단계 제목\n5.5.2 나열하기\n- 아이템1\n- 아이템2\n- 아이템 2a\n- 아이템 2b\n\nNumbered list item 1\nItem 2. The numbers are incremented automatically in the output.\n\n5.5.3 링크와 그림\n&lt;http://example.com&gt;\n[linked phrase](http://example.com)\n5.5.4 테이블\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell |\n| Content Cell | Content Cell |\n\n이러한 문법들은 Render 버튼을 누르면 웹페이지를 위한 적절한 시각 요소로 번역됩니다. 위의 문법 말고도 정말 다양하면서도 간단한 문법들이 있는데요, 여기서 모두 설명할 수는 없으니, Rstudio 노트북을 가능하게 해 주는 기반 기술인 Quarto 홈페이지에서 마크다운 문법을 자세히 설명한 웹사이트를 참조하는 것을 가장 권장합니다. 대신 이곳의 설명이 영어로 되어 있기 때문에, 이를 꺼리시는 분들은 검색창에서 ’Quarto 마크다운 문법’이라고 치시면 많은 한글 자료를 보실 수 있을 것입니다.\n이제 간단한 마크다운 문법을 알면 이용자는 HTML 같이 복잡한 마크업 문법을 몰라도 웹페이지를 간단하게 만들 수 있습니다. Rstudio가 내장하고 있는 프로그램이 마크다운 문서를 HTML로 다시 재번역해 주거든요(그것이 여러분이 Rstudio에서 이용하는 Render 버튼의 의미입니다). 여러분들이 매일 이용하는 웹브라우저는 이렇게 번역된 HTML을 이해할 수 있으니 여러분은 뉴스 작성을 위해 HTML을 따로 공부할 필요가 없습니다.\n그림: 마크업 -&gt; pandoc -&gt; HTML -&gt; 웹브라우저\n명심하세요! 여러분들은 이 책을 통해 연습을 하는 동안 항상 qmd 파일을 하나 만들어 마크다운 문법을 이요해 코드와 텍스트를 동시에 작성하고 이를 HTML로 렌더하는 작업을 반복할 것입니다. 그 외에도 R을 사용하는 여러 방법이 있지만, 일단 가장 쉽고 기사 작성을 위해 유용한 이 방법을 반복해서 사용하세요!"
  },
  {
    "objectID": "tidy.html#패키지-개념-이해하기",
    "href": "tidy.html#패키지-개념-이해하기",
    "title": "6  Tidyverse의 이해",
    "section": "6.1 패키지 개념 이해하기",
    "text": "6.1 패키지 개념 이해하기\nR뿐만 아니라, 많은 다른 언어에서 ’패키지’라고 하는 것은 쉽게 말하자면 유용한 함수들의 묶음을 의미합니다. 기본 R을 설계한 사람들이 R에 내장해두지는 않았지만, 특정 목적을 위해서는 유용함 도구들이 묶여서 ’패키지’로 제공된다고 생각하면 되겠습니다. 비유하자면, 여러분들이 매일 사용하는 ’카카오톡’이 R이라고 해 보죠. 카카오톡 안에는 기본적인 채팅 기능 안에도 수많은 다른 기능들이 있지요? 선물을 주고 받을 수도 있고, 음식을 주문할 수도 있고, 쇼핑을 할 수도 있습니다. 물론 모든 이용자들이 이 기능들을 모두 사용하지는 않지요. 하지만, 어떤 사람들은 자주 사용합니다. 이러한 세부 기능에 해당 하는 일종의 카카오톡 안의 ’미니 프로그램’을 R에서는 패키지라고 부른다고 생각하면 되겠습니다.\n\n\n\n카카오 미니프로그램\n\n\nR에서 패키지를 부르는 방법은 다음과 같습니다.\n\nlibrary(stats)\n\nlibrary()는 괄호가 있으니, 패키지를 부르는 ’함수’일 것이고, 괄호 안에는 부르고 싶은 패키지의 이름을 따옴표 없이 쓰면 됩니다. 여기서는 R을 설치할 때 같이 설치되는 stats라는 패키지를 불렀습니다.\n\n\n\n패키지 종류\n\n\n그런데 R이 설치될 때 모든 패키지가 함께 설치되는 것은 아닙니다. 사실 그렇지 않은 패키지가 훨씬 많지요. 심지어 패키지는 여러분도 만들 수 있습니다. 그렇게 개인이 여러 목적으로 만든 비공식 패키지까지 포함한다면, 세상에는 무한히 많은 R 패키지들이 있습니다. 하지만, 우리가 자주 사용하게될 패키지는 R개발진들의 관리 감독 아래 있는 ‘공식’ 패키지들입니다. 공식 패키지이지만, R과 함께 설치되지 않는 패키지를 설치하기 위해서는 다음과 같은 함수를 실행시키면 됩니다 (여기서는 따옴표가 필요합니다!).\n\ninstall.packages(\"tidyverse\")\n\n예, 우리가 사용한다고 했던 바로 그 tidyverse 입니다. tidyverse 문법을 이용하기 위해서 몇 가지 추가적인 함수가 필요하다고 했지요? 이렇게 설치된 tidyverse 패키지 안에 우리가 사용하고자 하는 바로 그 함수들이 포함되어 있습니다.\n물론, 설치만 한다고 해서 바로 이 패키지를 사용할 수 있는 것은 아닙니다. 아까 stats 패키지의 예에서처럼, tidyverse 패키지도 다음과 같이 불러주어야 합니다.\n\nlibrary(tidyverse)\n\n이 함수를 실행시키면 tidyverse 문법을 사용할 준비가 된 것입니다.\n\n6.1.1 패키지 사용시 주의사항: 설치? 로드?\n방금 tidyverse 패키지를 설치하고 불러왔는데요, 여기서 패키지를 ’설치’한다는 것과 ’불러온다’는 것의 의미에 대해 잠깐 생각해볼 필요가 있습니다.\n여러분이 일상적으로 윈도우 또는 맥OS 상에서 어떤 소프트웨어를 ‘설치’하면 그것은 어디에 저장되었다는 것을 의미하나요? 당연히 HDD, SSD와 같은 ’저장장치’ 입니다. 그래야, 컴퓨터를 껐다 다시 키더라도, 다시 ’설치’할 필요가 없을테니까요. tidyverse 패키지를 설치했다는 것도 비슷한 의미입니다. 설치한 패키지는 저장장치 어디엔가 저장되어 있습니다.\n\n따라서, 설치는 한 번 했다면 다시 할 필요가 없습니다.\n\n그런데 여러분 설치한 소프트웨어가 항상 켜져있나요? 물론 아닙니다. 그 소프트웨어를 실행시켜야지요. 실행시킨다는 것은 뭘까요? 여러 의미가 있지만, 가장 기본적으로는 저장장치에 설치되어 있는 해당 프로그램을 컴퓨터 메모리 상에 ’불러온다’는 것입니다. 가끔 여러분들 너무 많은 소프트웨어를 동시에 열어두면 컴퓨터가 느려져서 몇몇 사용하지 않는 프로그램을 꺼야했던 경험이 있을 것입니다. 프로그램을 껐다는 것은 반대로 메모리에서 지운다는 것을 의미하겠지요. 따라서 메모리에 여유 공간을 조금 확보하려고 프로그램을 끄는 것입니다. 이렇게 프로그램을 켠다는 것은 R 패키지로 치면 패키지를 로드하는 과정과 유사합니다.\n아까의 예에서처럼 library(tidyverse)라는 함수를 실행시키면, 저장장치에 저장되어 있던 tidyverse 패키지가 메모리로 불러와집니다. 그런데 메모리는 어떤 특성을 가지고 있었나요? 컴퓨터를 꺼도, 해당 정보에 할당된 이름이 사라져도, 메모리에서 언제든 사라질 수 있습니다. 이것은 무슨 이야기일까요? 여러분들이 Rstudio를 끄는 순간, 또는 Rstudio 안에서 다른 프로젝트로 이동하는 순간, 불러왔던 패키지는 메모리에 존재하지 않는 것이 됩니다. 그러니,\n\n패키지를 불러오는 것은 Rstudio를 새로 켤 때마다, 또는 새로운 프로젝트로 이동할 때마다, 매번 다시 해야 합니다!\n\n또 한 가지, 여러분들에게 당장 자주 일어나지는 않을 일이지만, 여러 개의 패키지를 로드해서 사용하다보면 간혹 생기는 문제가 있습니다. 바로 다른 두 개의 패키지가 하나의 함수명을 공유하고 있는 경우 입니다. 예컨대, MASS라는 패키지에도 select()라는 함수가 있고, tidyverse 패키지에도 select() 함수가 있습니다. 기능도, 문법도 완전히 다르지요. 따라서, 후자를 생각하고 select() 함수를 썼다가 에러가 발생하는 경우가 있습니다. 여러 방법이 있지만, 이럴 때에는 tidyverse::select()라고 써 주세요. 그러면, tidyverse 패키지에 속하는 select() 함수를 사용하게 됩니다."
  },
  {
    "objectID": "tidy.html#tidyverse-처음-사용하기",
    "href": "tidy.html#tidyverse-처음-사용하기",
    "title": "6  Tidyverse의 이해",
    "section": "6.2 Tidyverse 처음 사용하기",
    "text": "6.2 Tidyverse 처음 사용하기\n이제 겨우 tidyverse 문법을 사용할 준비가 되었습니다. 물론 tidyverse 패키지의 설치와 불러오기를 잊지 마세요! 사실 tidyverse는 많은 다양한 코딩 방식, 시각화 방식, 데이터 타입과 구조에 대한 재정의 등을 포함한 광범위한 코딩 패러다임인데요, 우리는 학습 목적상 다음 두 가지에만 주목하려고 합니다.\n\n서브세트\n파이프(pipe)\n\n그 외에 tidyverse의 다른 요소들은 학습이 심화되면서 차차 마주하게 될 것입니다.\n첫번째, 서브세트는 우리가 앞장에서 이미 보았던 서브세트, 즉, 데이터의 일부만을 취하는 방법입니다. R은 이미 좋은 서브세트 기능을 제공하지만, 앞서 말했듯 해당 문법이 가독성이 아주 좋지는 않다고 했습니다. 따라서 tidyverse에서 제공하는 방식의 서브세트를 이용할 것입니다. 두번째 ’파이프’는 긴 코드를 연결해서 간결하게 작성하는데 필요한 일종의 코드 작성법 입니다. 차례차례 살펴보지요.\n\n6.2.1 서브세트\ntidyverse의 서브세트는 기본적으로 R 데이터구조 중 데이터프레임에 적용되는 것입니다. 벡터나 리스트를 사용할 때에는 기본 R 문법을 사용하면 됩니다. 데이터프레임을 서브세트 하는 방법에는 행을 취하는 방법과 열을 취하는 방법이 있었습니다. 다음을 기억해 두세요. tidyverse에서는:\n\n열을 취할 때에는 항상 select()함수와 열의 ’이름’을 사용합니다.\n행을 취할 때에는 항상 filter()함수와 행을 취하는 ’조건’을 사용합니다.\n\n이것만 이해하면 거의 모든 것을 이해한 것과 다름 없습니다. 일단, tidyverse 서브세트는 데이터프레임에 관한 것이라고 했으니, 일단 앞서 이미 이용했던 것고 같은 데이터 프레임을 다시 만들어 예제 데이터로 이용해 보지요.\n\ndf &lt;- data.frame(id = c(1, 2, 3),\n                 gender = c(\"Male\", \"Female\", \"Female\"),\n                 height = c(173, 165, 170))\ndf\n\n  id gender height\n1  1   Male    173\n2  2 Female    165\n3  3 Female    170\n\n\n열을 취할 때는 select() 함수와 열의 이름을 사용한다고 했으므로, 다음과 같이 씁니다.\n\nselect(df, gender)\n\n  gender\n1   Male\n2 Female\n3 Female\n\n\n즉, select() 함수의 첫번째 인수는 서브세트의 대상이 될 데이터프레임(df), 두번째 인수는 거기서 선택할 열의 이름(gender)입니다. 그런데, 사실 복수의 열을 선택할 수도 있습니다.\n\nselect(df, gender, height)\n\n  gender height\n1   Male    173\n2 Female    165\n3 Female    170\n\n\n즉, 인수로 열의 이름을 그냥 나열하면 된다는 것입니다.\n행을 취할 때는 filter() 함수와 행을 취할 조건을 사용한다고 했습니다. ’조건’이라는 말을 앞장에서 보았지요? 바로 TRUE, FALSE를 뱉어내는 R에게 질문하는 방식이라고 설명했던 바로 그 조건 입니다. 따라서, 키가 170이 넘는 사람에 관한 행만을 취하고 싶다면, 다음과 같이 쓰면 됩니다.\n\nfilter(df, height &gt;= 170)\n\n  id gender height\n1  1   Male    173\n2  3 Female    170\n\n\nfilter() 함수의 첫 인수 역시 데이터프레임이고, 그 인수로는 조건이 옵니다. 그렇다면 두 개의 조건을 사용할 때는요? 그 때는 두 개의 조건이 AND 관계인지, OR 관계인지를 밝혀야 합니다. 그 관계를 밝히는 기호는 다음고 같습니다.\n\nAND: 조건1 & 조건2\nOR: 조건1 | 조건2\n\n이제 다음과 같은 예를 보세요.\n\nfilter(df, height &gt;= 170 & gender==\"Female\")\n\n  id gender height\n1  3 Female    170\n\n\n이것은 여성’이고(AND)’ 키가 170 이상인 사람에 해당하는 행을 돌려달라는 것이겠지요? 반면,\n\nfilter(df, height &gt;= 170 | gender==\"Female\")\n\n  id gender height\n1  1   Male    173\n2  2 Female    165\n3  3 Female    170\n\n\n이것은 여성’이거나(OR)’ 키가 170 이상인 사람에 해당하는 행을 돌려달라는 것이겠지요? 이는 데이터 전체에 해당하네요.\n\n\n6.2.2 파이프\n파이프는 코드를 길게 써야 할 때 필요한 사용하는 코딩 스타일 입니다. 파이프를 위해서는 ’파이프’로 불리는 기호가 하나 필요합니다. 바로 다음 기호 입니다.\n\n\n\n파이프\n\n\n이 간단한 기호가 어떻게 긴 코드를 작성하는데 도움을 준다는 것일까요?\n위의 그림에서 볼 수 있는 것처럼, 파이프는 함수의 첫 번째 인수를 함수의 왼쪽에 쓸 수 있게 해줍니다. 이제 데이터에 함수를 두 번 연속적으로 적용해야 하는 경우를 생각해 볼까요? 일반적인 문법에서는 우리가 중학교 수학 시간에 배운 것과 같이 다음과 같이 쓰면 됩니다.\n\ndo_this_next(do_this_first(data))\n\n이를 조금 풀어서 설명하면, 원 데이터(data)에 do_this_first() 함수를 먼저 적용하고, 그 결과에 do_this_next() 함수를 적용하는 것이지요. 물론 이렇게 써도 아무 문제가 없습니다. 하지만, 이런 방법에는 큰 문제가 있습니다. 바로 코드를 오른쪽에서 왼쪽으로 읽어야 한다는 것이지요. 이는 우리가 자연스럽게 글을 읽는 방식과 반대입니다. 사실, 이렇게 함수가 두 개 뿐이라면 큰 문제가 아니겠지만, 함수가 더 많아지면 가독성이 더욱 떨어집니다.\n\nfinally_do_this(then_do_this(do_this_next(do_this_first(data))))\n\n현실적으로는 함수를 십수개 차례대로 적용해야 하는 경우도 많으니, 이러한 방식의 코드는 나중에 스스로가 리뷰하기도 어려울 뿐더러, 협업 상황이라면 상황은 더욱 악화됩니다. 그래서 전통적으로는 이런 방식의 코드를 많이 사용해 왔습니다.\n\ndata2 &lt;- do_this_first(data)\ndata3 &lt;- do_this_next(data2)\ndata4 &lt;- then_do_this(data3)\nfinally_do_this(data4)\n\n즉, 함수를 실행하고 그 결과를 변수로 저장한 다음, 다음 함수에 해당 변수를 인수로 사용하는 방식이지요. 읽기 조금 수월한가요? 어느 정도는 괜찮습니다. 하지만, 이것도 결코 읽기 쉬운 코드라고 할 수는 없습니다. 또 그 내용을 알기 어려운 data2, data3, data4 등의 불필요한 데이터들이 계속해서 생성됩니다. 이 역시 가독성을 낮출 뿐더러, 불필요하게 메모리를 차지하게 됩니다. 데이터의 이름을 조금 더 이해하기 쉽게 만들면 좋겠지만, 이렇게 데이터 처리 와중에 생긴 데이터에 모두 이름을 붙일만한 의미가 있는 것도 아니고, 데이터 이름을 자꾸 만들다보면, 더 이상 이름을 만들 아이디어도 떠오르지 않게 됩니다(이건 농담이지만, 진담이기도 합니다!).\n우리가 파이프를 쓴다면 다음과 같이 쓸 수 있습니다.\n\ndata |&gt;\n    do_this_first() |&gt;\n    do_this_next() |&gt;\n    then_do_this() |&gt;\n    finally_do_this()\n\n이 코드를 잘 보면 항상 파이프 왼쪽에서 발생한 결과가 다음 함수의 투입값(input)이 됩니다. 이 코드는 우리가 글을 읽는 방식과 동일한 순서에 따라 쓰여졌기 때문에 읽기 쉬울 뿐더러, 필요 없는 중간 단계의 데이터(data2, data3 따위)도 만들지 않았습니다. 우리는 앞으로 연속해서 함수를 적용해야 할 때, 위의 예와 같이 파이프를 사용할 것입니다. 여러분도 가능한 위의 코딩 스타일을 사용하도록 노력해 보세요!\n\n\n6.2.3 (3) 서브세트와 파이프를 동시에!\n이제 tidyverse 문법의 주요 구성 요소라고 말한 서스세트와 파이프를 결합해 보겠습니다. 이제 앞서 사용했던 예에서 특정 열을 선택하고, 또 어떤 조건에 따라 행도 선택한다고 해 보지요. 그러면 다음과 같이 쓸 수 있을 것입니다.\n\ndf |&gt;\n    filter(height &gt;= 170 & gender==\"Female\") |&gt;\n    select(gender, height)\n\n  gender height\n1 Female    170\n\n\n코드를 잘 살펴보면 그 의미는 다음과 같습니다.\n\n\n원데이터 df에서 키가 170이 넘고, 여성인 행의 데이터를 취하라.\n그런 다음, gender, height 칼럼만 표시하라.\n\n\n파이프를 썼기 때문에, filter() 함수와 select() 함수 안에는 데이터가 인수로 들어가지 않는다는 것에 주목하세요! 파이프를 사용하면 서브세트 할 데이터는 두 함수 앞에 사용한 파이프의 왼쪽에 있게 됩니다!\n다음 내용으로 넘어가기 앞서, 위의 코드를 꼭 이해해야 합니다! 여러분은 이 책을 모두 읽을 때까지 비슷한 코드를 수십번 보고, 사용하게 될테니까요."
  },
  {
    "objectID": "manipulate.html#tidyverse를-이용해-크라우드펀딩-빅데이터-로드하기",
    "href": "manipulate.html#tidyverse를-이용해-크라우드펀딩-빅데이터-로드하기",
    "title": "7  빅데이터를 분석 가능하게",
    "section": "7.1 Tidyverse를 이용해 크라우드펀딩 빅데이터 로드하기",
    "text": "7.1 Tidyverse를 이용해 크라우드펀딩 빅데이터 로드하기\n마지막으로, tidyverse에 내장된 패키지를 이용해 외부의 데이터를 불러오는 방법에 대해 알아보겠습니다. R은 애초에 데이터를 다루기 위해 만들어진 언어이므로, 당연히 외부 데이터를 불러오는 함수가 내장되어 있습니다. 그러나 예전에 만들어진 기능이기도 하고, 몇 가지 직관적이지 않은 동작 때문에 여러가지 에러가 발생하는 경우가 많습니다. 또 데이터에 로마 알파벳과 숫자 이외에 다른 정보가 들어 있으면 이를 처리하기 위한 작업을 추가적으로 해야 하는 경우도 있습니다. 엑셀, SPSS, Stata 등 다른 소프트웨어에서 사용하는 포멧에 취약하기도 하고요. 따라서, 앞으로 우리는 R이 원래 제공하는 함수가 아닌, tidyverse에 내장된 함수를 사용해서 외부 데이터를 불러올 것입니다.\n이 책은 데이터 저널리스트가 되고자 하는 여러분들을 위한 것이므로, 나중에는 여러분만의 데이터를 얻는 방법을 배울 것입니다. 하지만, 그것은 조금 후의 일이니, 일단은 제가 생각하기에 연습에 사용하기 좋다고 생각하는 데이터를 사용하겠습니다.\n\n7.1.1 donorschoose.org 데이터 소개\n우리가 당분간 사용할 데이터는 donorschoose.org라는 미국 크라우드펀딩 웹사이트의 로그 데이터 입니다. 여러분들도 크라우드펀딩 이라는 용어는 자주 들어봤을 것이라고 생각합니다. 못 들어보셨을 분들을 위해 짧게 설명하자면, 크라우드 펀딩은 돈을 달라고 요구하는 웹사이트 입니다. 물론 그냥 돈을 달라는 것은 아니고, 돈이 필요한 기발한 아이디어를 일종의 ‘프로젝트’ 형태로 올리는 경우가 많습니다. 웹사이트에 들른 잠재적 기부자들은 만약 그 아이디어가 마음에 들면 5달러, 10달러 정도의 작은 돈을 ‘기부’하는 것이지요. 미국에서는 ’Indiegogo’, ‘Kickstarter’, 한국에서는 ‘와디즈’, ‘텀블벅’ 등이 유명합니다.\n크라우드펀딩은 많은 경우 소규모 사업 아이디어에 작은 규모의 투자를 받기 위한 플랫폼입니다. 하지만, 우리가 사용할 donorschoose.org는 그 성격이 조금 다릅니다. 여기에 올라오는 프로젝트들은 신기한 아이디어를 가지고 있는 창업자가 아니라, 교육에 필요한 기자재가 부족한 공립학교 선생님들이 올립니다. 그래서 프로젝트 소개에는 하고자 하는 교육의 목적과 학생들에 대한 소개, 필요한 기자재 목록 등과 함께 필요한 자금의 총액이 있습니다. 이 사연을 읽고 기부자들은 몇 달러의 돈을 기부하는 것이지요.\n다른 크라우드펀딩 웹사이트들처럼 donorschoose.org도 몇 가지 룰이 있는데요, 그 중 가장 중요한 것은 다음 두가지 입니다. 첫째, 정해진 시간(보통 90일) 안에 프로젝트를 올린 선생님이 정해놓은 목표액을 모두 채우면, 해당 프로젝트는 완료되고 선생님은 돈을 받습니다(목표액). 둘째, 정해진 시간 안에 목표액을 채우지 못하면 기부된 돈은 원 기부자에게 모두 환불 됩니다(환불 정책).\n이 데이터를 이용하는 이유는 현실의 온라인 환경에서 발생한 ‘로그 데이터’이기 때문입니다. 우리가 전통적인 기사에서 흔히 보는 통계 데이터들은 상당히 정제되고 있고, 목적에 따른 디자인에 따라 생성된 데이터이지만, 이러한 로글 데이터는 그렇지 않지요. 많은 경우, ’데이터 저널리스트’들은 그런 데이터를 분석하고 싶어합니다 (첫장에서 이야기한 데이터 저널리즘의 ’새로움(novelty)’ 전략을 기억하시나요?) 그러니 처음부터 조금 어렵더라도 ’리얼’한 데이터를 만지는 것이 좋지 않을까 합니다.\n이 데이터는 어디서 얻을까요? kaggle이라고 하는 일종의 데이터 경진대회 웹사이트에서 얻을 것입니다. ’kaggle’에 대해서 길게 설명할 수는 없지만, 데이터 사이언스에 종사하는 사람들 또는 학생들이 자신이 만들어낸 알고리즘을 뽐내기 위해 경쟁하는 웹사이트라고 생각하시면 되겠습니다. 이렇게 발표된 알고리즘 중 유용한 것들이 있으니 기업들도 자신의 비즈니스에서 생성된 데이터를 ’kaggle’을 통해 공개하기도 합니다. donorschoose.org 데이터도 그런 이유로 ’kaggle’에 공개되어 있습니다. 다음 링크를 따라가세요.\n\n캐글 링크\n\nkaggle에 가입을 완료하고, 약관 승인 절차들을 거치고 나면, 데이터탭 오른쪽 아래 ‘Download All’ 버튼을 눌러 모든 파일을 zip 압축 형태로 받을 수 있습니다. 압축된 파일이 1기가 가까이 되니, 아마 여러분 대부분들이 지금까지 다루어본 어떤 데이터보다 ’빅’데이터에 가까울 가능성이 크겠네요.\n\n\n\n캐글\n\n\n압축을 해제해 압축 파일 안에 있는 6개의 csv 파일을 여러분이 앞으로 사용할 프로젝트(잊지 않으셨죠?) 폴더 안에 data라는 폴더를 하나 만들고 그 안에 옮겨놓습니다. 다음 그림처럼요.\n\n\n\n데이터 저장\n\n\n이제 데이터를 부를 준비가 되었습니다.\n\n\n7.1.2 데이터 불러오기\n데이터를 부르기 전에 다음을 했는지 확인 합시다.\n\n이 책의 내용을 학습하면서 사용할 R 프로젝트를 만들었다.\n해당 프로젝트로 이동하였다.\ntidyverse 패키지를 설치하였다.\n프로젝트 안에서 donorschoose.org를 분석하는데 사용할 노트북 파일(qmd파일)을 만들었다.\n해당 노트북에서 tidyverse 패키지를 로드하였다.\n\n위의 체크리스트에 대한 대답이 모두 ’네’라면, 이제 다음과 같은 코드를 실행해 봅시다.\n\nlibrary(tidyverse)\n\n\nprojects &lt;- read_csv(\"data/projects.csv\")\n\n이 코드를 조금 뜯어보도록 합시다. 첫째, read_csv()는 csv 포맷으로 존재하는 데이터 파일을 부르는 함수로 tidyverse 패키지에 속해있습니다. 둘째, 우리가 사용하고 있는 프로젝트 폴더 안에 data 폴더를 하나 만들고 그 안에 projects.csv 파일을 저장했으니, 파일 경로는 상대경로를 이용해 “data/projects.csv”가 됩니다. 셋째, 이렇게 데이터를 부르면 데이터는 저장장치에서 메모리로 불러와집니다. 하지만, 거기까지만 한다면, 문제가 발생합니다. 앞서 이야기한 바와 같이 이름이 없으니 존재하지 않는 것이나 마찬가지가 됩니다. 즉, 한 번 불러와진 다음, 그냥 날아가버린다고 생각하시면 됩니다. 따라서 우리는 이 데이터에 이름을 붙여주어야 합니다. 이름을 붙이기 위한 표현이 바로 projects &lt;- 이 부분입니다. 벡터에 이름을 붙일 때, 리스트에 이름을 붙일 때와 똑같지요? R에서는 몇 백 메가 크기의 데이터나 숫자 한개로 이루어진 벡터나 똑같이 하나의 변수로 취급될 뿐입니다.\n\n7.1.2.1 csv와 여러 테이블 데이터 포맷\n자, 이제 데이터를 분석할 준비가 끝났습니다. 그런데, 다음으로 넘어가기 전에에 csv 포멧을 이용해보지 않은 분들도 있지요? 그런 분들을 위해 잠깐 csv에 대해 설명해 보겠습니다.\ncsv는 “comma separated values”의 약자입니다. 간단히 말해서 “쉼표”를 이용해서 값들을 구분해 놓은 테이블 형태의 데이터라는 뜻입니다. 이게 무슨 뜻인지는 아래의 그림을 보면 쉽게 이해 되실 겁니다.\nhttps://www.exceldemy.com/convert-excel-to-csv-comma-delimited/\n아래의 예에서 컬럼을 구분하기 위해 아주 간단하게 쉼표를 써 주었습니다. 행을 구분해 주기 위해서는 엔터를 쳐서 줄을 바꿔주었다고 할 수 있죠. csv 파일은 사실 이러한 규칙을 따르는 텍스트 파일에 불과합니다. 이를 R이나 마이크로소프트 엑셀, 구글 시트 등에서 부를 때 테이블로 여러분에게 ’표현’해 줄 뿐입니다. 사실 이러한 csv 파일은 테이블 데이터를 표현하는 가장 간단한 방법이지요.\n여러분은 아마도 마이크로소프트 엑셀이 사용하는 xlsx나 xls 등의 파일 포멧에 더욱 익술할 것입니다. 그런데 사실 생각해 보면 이러한 포멧의 파일들은 테이블 형태의 데이터 말고도 다양한 정보를 포함하고 있습니다. 글꼴이나, 테이블의 폭, 테두리, 수식 등의 정보들이 그것이지요. 이러한 추가 정보들을 이용하면 여러 편리한 점들이 있지만, 무엇보다 여러분들은 엑셀에 의존할 수밖에 없고, 데이터의 크기도 커지게 됩니다. 즉, 편의성을 위해 범용성을 희생한 것이지요.\n따라서, 대규모의 데이터를 다양한 플랫폼에서 다루어야 하는 데이터 사이언스를 위해서는 테이블 데이터를 주고 받을 때 안전하고, 범용적이고, 가벼운 csv 형식을 사용하는 경우가 많습니다.\n그렇다면, 테이블 형태의 데이터가 아니라면요? 그것은 나중에 살펴보도록 하겠습니다.\ncsv가 데이터 저널리즘을 위해 제일 유용하고 흔하다고 하더라도, 여러분들이 항상 테이블 형태의 데이터로 csv 파일을 다루게 되리라는 보장은 없습니다. 그건 데이터를 주는 사람 마음이지요. 그러면 다른 포멧의 데이터들은 어떻게 R로 불러들여야 할까요? 다행이 tidyverse에는 이 문제를 해결하기 위한 다양한 함수들이 포함되어 있습니다. 이 교재에서는 csv 파일 이외의 테이블 형식을 다룰 일이 없겠지만, 앞으로를 위해 다음 표를 참조하세요.\n\n\n\n데이터 포맷\n함수\n\n\n\n\ncsv\nread_csv()\n\n\nxls, xlsx\nread_excel()\n\n\nsas7bdat, sas7cat (SAS)\nread_xpt()\n\n\nsav (SPSS)\nread_sav()\n\n\ndta (Stata)\nread_dta()"
  },
  {
    "objectID": "manipulate.html#데이터-조작하기",
    "href": "manipulate.html#데이터-조작하기",
    "title": "7  빅데이터를 분석 가능하게",
    "section": "7.2 데이터 조작하기",
    "text": "7.2 데이터 조작하기\n데이터를 불러온 다음 바로 분석을 시작하면 좋겠지만, 그럴 수 있는 경우는 많지 않습니다. 내가 분석하고자 하는 데이터가 바로 분석 가능하지 않는 타입인 경우도 있고, 기존 데이터에 특정 연산을 가해 분석하고자 하는 데이터를 도출해야 하는 경우도 있습니다. 어떤 경우에는 내가 분석하고자 하는 데이터가 여러 테이블에 흩어져 있어서, 이를 결합해야 하는 경우도 있을 것입니다.\n이 중 가장 흔하게 나타나는 시나리오와 이를 수행하기 위한 tidyverse 스타일의 코딩 사례를 살펴보도록 하겠습니다. 이를 위해 먼저 donorschoose.org 데이터 중 두 개의 테이블을 R로 불러오도록 하겠습니다.\n\nprojects &lt;- read_csv(\"data/projects.csv\")\ndonations &lt;- read_csv(\"data/donations.csv\")\n\n\n7.2.1 데이터 탐색\n먼저 projects 데이터프레임을 한 번 훑어보겠습니다.\n\nprojects\n\n# A tibble: 664,098 x 35\n   projectid               teacher_acctid schoolid school_ncesid school_latitude\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;\n 1 316ed8fb3b81402ff6ac8f~ 42d43fa6f3731~ c0e6ce8~ 063627006187             36.6\n 2 90de744e368a7e4883223c~ 864eb466462bf~ d711e47~ 483702008193             32.9\n 3 32943bb1063267de6ed19f~ 37f85135259ec~ 665c361~ 410327000109             45.2\n 4 bb18f409abda2f264d5acd~ 2133fc46f951f~ 4f12c3f~ 360015302507             40.6\n 5 24761b686e18e5eace6346~ 867ff478a63f5~ 10179fd~ 062271003157             34.0\n 6 eac7d156205f1333de3887~ ff064802c18e6~ 929336e~ 040187001058             33.3\n 7 5a3bfdf2e05781ccd0654d~ 085794a9e315b~ dc34b02~ 010060000256             32.8\n 8 afda16eb54d8992db7bb42~ 1d94a31c2dc38~ 86fff7c~ 130129000571             33.9\n 9 2ab3efb23acc84017cd789~ 5a497c425e05b~ ed170a1~ 261200001297             42.4\n10 3118962680bb062323c356~ eb0855cc6ea55~ 71b4dee~ 340264001386             40.0\n# i 664,088 more rows\n# i 30 more variables: school_longitude &lt;dbl&gt;, school_city &lt;chr&gt;,\n#   school_state &lt;chr&gt;, school_zip &lt;chr&gt;, school_metro &lt;chr&gt;,\n#   school_district &lt;chr&gt;, school_county &lt;chr&gt;, school_charter &lt;lgl&gt;,\n#   school_magnet &lt;lgl&gt;, school_year_round &lt;lgl&gt;, school_nlns &lt;lgl&gt;,\n#   school_kipp &lt;lgl&gt;, school_charter_ready_promise &lt;lgl&gt;,\n#   teacher_prefix &lt;chr&gt;, teacher_teach_for_america &lt;lgl&gt;, ...\n\n\n이렇게 데이터프레임의 변수명을 그대로 실행시키면, Rstudio 노트북 환경에서는 명령어 아래 일부가 출력 됩니다. 여기서 오른쪽 화살표는 화면에 표시된 것 말고도 다른 열이 더 있다는 것을 의미합니다. 그 화살표를 클릭하면 화면이 오른쪽으로 넘어가게 됩니다. 그리고 표 아래에는 인터넷 게시판처럼, 페이지를 선택할 수 있습니다. 이는 화면에 출력된 것 말고도 행이 더 남아 있다는 것을 의미하지요. 그곳에 있는 숫자를 클릭하면 다음 페이지를 볼 수 있습니다.\n\n\n\n노트북 환경에서 데이터 프레임 확인\n\n\n그것 말고도 데이터프레임을 탐색하기 위한 방법은 여러가지가 있습니다. 어떤 식으로든 변수가 생성되고 나면, Rstudio의 기본 설정상 오른쪽 상단에 있는 Environment 창에 지금 메모리에 저장되어 있는 변수들이 표시됩니다.\n\n\n\nEnvironment에서 변수 확인\n\n\n지금 보면, 아까 우리가 불러온 donations 데이터 프레임과 projects 데이터프레임이 저장되어 있네요. projects를 클릭해 보겠습니다.\n\n\n\nEnvironment에서 데이터프레임 확인\n\n\n그러면 우리가 엑셀에서 보는 것과 유사하게 스크롤 할 수 있는 테이블 화면이 떠오릅니다. 여기서는 조금 더 익숙한 방식으로 여러 데이터를 살펴보실 수 있을 것입니다.\n데이터가 많은 경우에 별로 권장되지는 않지만 콘솔에서 탐색하는 방법도 있습니다. 콘솔에서 다음과 같은 코드를 실행시켜보세요.\n\nhead(projects)\n\n그러면 다음과 같은 화면이 등장할 것입니다. 콘솔은 노트북과 달리 사람이 조작할 수 있는 환경을 제공하지 못하기 때문에, 한 번에 표현할 수 있는 것 이상의 데이터는 생략이 되어 표시된다는 것을 알 수 있습니다.\n\n\n\nhead()함수를 이용한 데이터프레임 확인\n\n\n콘솔에서는 다음과 같은 명령어가 더욱 유용합니다.\n\nstr(projects)\n\nspc_tbl_ [664,098 x 35] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ projectid                             : chr [1:664098] \"316ed8fb3b81402ff6ac8f721bb31192\" \"90de744e368a7e4883223ca49318ae30\" \"32943bb1063267de6ed19fc0ceb4b9a7\" \"bb18f409abda2f264d5acda8cab577a9\" ...\n $ teacher_acctid                        : chr [1:664098] \"42d43fa6f37314365d08692e08680973\" \"864eb466462bf704bf7a16a585ef296a\" \"37f85135259ece793213aca9d8765542\" \"2133fc46f951f1e7d60645b0f9e48a6c\" ...\n $ schoolid                              : chr [1:664098] \"c0e6ce89b244764085691a1b8e28cb81\" \"d711e47810900c96f26a5d0be30c446d\" \"665c3613013ba0a66e3a2a26b89f1b68\" \"4f12c3fa0c1cce823c7ba1df57e90ccb\" ...\n $ school_ncesid                         : chr [1:664098] \"063627006187\" \"483702008193\" \"410327000109\" \"360015302507\" ...\n $ school_latitude                       : num [1:664098] 36.6 32.9 45.2 40.6 34 ...\n $ school_longitude                      : num [1:664098] -119.6 -96.7 -122.4 -74 -118.3 ...\n $ school_city                           : chr [1:664098] \"Selma\" \"Dallas\" \"Colton\" \"Brooklyn\" ...\n $ school_state                          : chr [1:664098] \"CA\" \"TX\" \"OR\" \"NY\" ...\n $ school_zip                            : chr [1:664098] \"93662\" \"75243\" \"97017\" \"11226\" ...\n $ school_metro                          : chr [1:664098] NA \"urban\" \"rural\" \"urban\" ...\n $ school_district                       : chr [1:664098] \"Selma Unified Sch District\" \"Richardson Ind School District\" \"Colton School District 53\" \"New York City Dept Of Ed\" ...\n $ school_county                         : chr [1:664098] \"Fresno\" \"Dallas\" \"Clackamas\" \"Kings (Brooklyn)\" ...\n $ school_charter                        : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ school_magnet                         : logi [1:664098] FALSE FALSE FALSE TRUE FALSE FALSE ...\n $ school_year_round                     : logi [1:664098] FALSE FALSE FALSE FALSE FALSE TRUE ...\n $ school_nlns                           : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ school_kipp                           : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ school_charter_ready_promise          : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ teacher_prefix                        : chr [1:664098] \"Mrs.\" \"Mrs.\" \"Mr.\" \"Mr.\" ...\n $ teacher_teach_for_america             : logi [1:664098] FALSE FALSE FALSE TRUE FALSE FALSE ...\n $ teacher_ny_teaching_fellow            : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ primary_focus_subject                 : chr [1:664098] \"Literature & Writing\" \"Literacy\" \"Literacy\" \"Social Sciences\" ...\n $ primary_focus_area                    : chr [1:664098] \"Literacy & Language\" \"Literacy & Language\" \"Literacy & Language\" \"History & Civics\" ...\n $ secondary_focus_subject               : chr [1:664098] \"College & Career Prep\" \"ESL\" \"Mathematics\" \"Special Needs\" ...\n $ secondary_focus_area                  : chr [1:664098] \"Applied Learning\" \"Literacy & Language\" \"Math & Science\" \"Special Needs\" ...\n $ resource_type                         : chr [1:664098] \"Books\" \"Books\" \"Technology\" \"Books\" ...\n $ poverty_level                         : chr [1:664098] \"highest poverty\" \"highest poverty\" \"high poverty\" \"highest poverty\" ...\n $ grade_level                           : chr [1:664098] \"Grades 6-8\" \"Grades PreK-2\" \"Grades PreK-2\" \"Grades 3-5\" ...\n $ fulfillment_labor_materials           : num [1:664098] 30 30 30 30 30 30 30 30 30 30 ...\n $ total_price_excluding_optional_support: num [1:664098] 556 296 431 576 408 ...\n $ total_price_including_optional_support: num [1:664098] 654 349 507 678 480 ...\n $ students_reached                      : num [1:664098] 32 22 17 12 24 20 320 18 25 28 ...\n $ eligible_double_your_impact_match     : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ eligible_almost_home_match            : logi [1:664098] FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ date_posted                           : Date[1:664098], format: \"2014-05-12\" \"2014-05-12\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   projectid = col_character(),\n  ..   teacher_acctid = col_character(),\n  ..   schoolid = col_character(),\n  ..   school_ncesid = col_character(),\n  ..   school_latitude = col_double(),\n  ..   school_longitude = col_double(),\n  ..   school_city = col_character(),\n  ..   school_state = col_character(),\n  ..   school_zip = col_character(),\n  ..   school_metro = col_character(),\n  ..   school_district = col_character(),\n  ..   school_county = col_character(),\n  ..   school_charter = col_logical(),\n  ..   school_magnet = col_logical(),\n  ..   school_year_round = col_logical(),\n  ..   school_nlns = col_logical(),\n  ..   school_kipp = col_logical(),\n  ..   school_charter_ready_promise = col_logical(),\n  ..   teacher_prefix = col_character(),\n  ..   teacher_teach_for_america = col_logical(),\n  ..   teacher_ny_teaching_fellow = col_logical(),\n  ..   primary_focus_subject = col_character(),\n  ..   primary_focus_area = col_character(),\n  ..   secondary_focus_subject = col_character(),\n  ..   secondary_focus_area = col_character(),\n  ..   resource_type = col_character(),\n  ..   poverty_level = col_character(),\n  ..   grade_level = col_character(),\n  ..   fulfillment_labor_materials = col_double(),\n  ..   total_price_excluding_optional_support = col_double(),\n  ..   total_price_including_optional_support = col_double(),\n  ..   students_reached = col_double(),\n  ..   eligible_double_your_impact_match = col_logical(),\n  ..   eligible_almost_home_match = col_logical(),\n  ..   date_posted = col_date(format = \"\")\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nstr()은 structure라는 뜻으로, 각 컬럼 이름과 각 컬럼의 데이터 타입, 데이터의 갯수, 그리고 가장 상위에 있는 몇가지 값을 보여줍니다. 많은 경우 str()은 각 열의 데이터 타입을 확인하기 위해 사용합니다. 그런데, 만약 str()이 과도하게 많은 정보를 준다고 생각하신다면 다음 명령어도 유용합니다.\n\nnames(projects)\n\n [1] \"projectid\"                             \n [2] \"teacher_acctid\"                        \n [3] \"schoolid\"                              \n [4] \"school_ncesid\"                         \n [5] \"school_latitude\"                       \n [6] \"school_longitude\"                      \n [7] \"school_city\"                           \n [8] \"school_state\"                          \n [9] \"school_zip\"                            \n[10] \"school_metro\"                          \n[11] \"school_district\"                       \n[12] \"school_county\"                         \n[13] \"school_charter\"                        \n[14] \"school_magnet\"                         \n[15] \"school_year_round\"                     \n[16] \"school_nlns\"                           \n[17] \"school_kipp\"                           \n[18] \"school_charter_ready_promise\"          \n[19] \"teacher_prefix\"                        \n[20] \"teacher_teach_for_america\"             \n[21] \"teacher_ny_teaching_fellow\"            \n[22] \"primary_focus_subject\"                 \n[23] \"primary_focus_area\"                    \n[24] \"secondary_focus_subject\"               \n[25] \"secondary_focus_area\"                  \n[26] \"resource_type\"                         \n[27] \"poverty_level\"                         \n[28] \"grade_level\"                           \n[29] \"fulfillment_labor_materials\"           \n[30] \"total_price_excluding_optional_support\"\n[31] \"total_price_including_optional_support\"\n[32] \"students_reached\"                      \n[33] \"eligible_double_your_impact_match\"     \n[34] \"eligible_almost_home_match\"            \n[35] \"date_posted\"                           \n\n\n이 함수는 데이터프레임 각 열의 이름만을 보여줍니다.\n\n\n7.2.2 데이터 필터링 (= 서브세팅)\n위의 방법으로 데이터를 탐색하다보면, school_ncesid열에 결측값이 다수 존재한다는 것을 알 수 있습니다. NCES가 미국 국가교육통계센터(National Center for Education Statistics)를 의미하니, 공식 통계 상의 학교 ID라는 것을 알 수 있습니다. 그런데, 이 ID가 없다는 것은 뭔가 좀 이상하네요. 만약, 우리가 ID에 결측치가 있는 것은 정상적이지 않으므로 분석에서 제외하기로 결정했고 해 보죠. 그렇다면 지금까지 배운 것을 이용해 어떻게 제외하면 될까요?\n물론 답은 세브세트 입니다. 그 중에서도 결측치가 있는 행을 삭제하는 것이니, filter() 함수를 사용해야 하겠네요. 그리고 school_ncesid의 값이 결측되지 않은 경우 만을 취하고자 하니 filter() 함수 안에 들어갈 조건은 !is.na(school_ncesid)가 되겠네요. 따라서 다음과 같습니다.\n\nprojects_no_na &lt;- projects |&gt;\n    filter(!is.na(school_ncesid))\n\n이번엔 학교의 위도와 경도 정보는 사용하지 않을 것이라고 해 볼까요? 다시 말해, school_latitude 열과 school_longitude 열을 제외하겠다는 뜻이겠군요. 그 때는 이렇게 해 볼 수 있습니다.\n\nprojects_cleaned &lt;- projects_no_na |&gt;\n    select(!c(school_latitude, school_longitude))\n\n여기서도 !은 not의 의미이므로, “해당 컬럼 두 개 빼고” 라는 뜻이 됩니다. 두개 컬럼 이름을 하나의 벡터로 묶기 위해 c()를 사용했다는 것에 주목해주세요.\n물론 행과 열의 서브세팅을 파이프로 결합할 수도 있습니다 (이 방법이 더 좋습니다.).\n\nprojects_cleaned &lt;- projects |&gt;\n    filter(!is.na(school_ncesid)) |&gt;\n    select(!c(school_latitude, school_longitude))\n\n\n\n7.2.3 새로운 변수 만들기\n주어진 데이터를 분석에 그대로 사용하는 경우는 많지 않습니다. 주어진 변수, 또는 변수들을 바탕으로 분석에 적합한 새로운 변수를 만들어 주어야 합니다. 예컨대, 야구에서 타수와 안타 수가 주어져 있을 때, 타자의 타격 능력을 분석하기 위해서 두 변수를 조합해 타율을 계산하는 경우가 그런 경우에 해당할 것입니다.\n이렇게 새로운 변수를 만들기 위한 tidyverse 문법은 mutate() 함수를 사용하는 것입니다. 그 형식은 대략 다음과 같습니다.\n\n원래 데이터프레임 |&gt; mutate(새 변수 이름 = 함수(원래 변수))\n\n이렇게 원래의 데이터프레임에 mutate()을 적용하고 나면, 그 결과물은 새로 생산된 변수가 아닙니다! mutate()의 결과물은 원래의 데이터프레임에 새로운 변수(열)이 추가된 새로운 데이터프레임 입니다.\n앞서 불러온 donorschoose.org 데이터의 projects 테이블에서 각 프로젝트의 목표액이 달러로 포함되어 있는데요, 보도하는 사람이 이 목표액을 원화로 표시하고 싶었다고 해 보지요. 원달러 환율이 대략 1,200이라고 치면, 원화로 표현된 목표액은 원래 변수에 1,200을 곱한 것이 되겠네요. 사실 목표액에 해당하는 변수는 projects 테이블에 두 개 있는데, 그 중 일단 total_price_excluding_optional_support를 이용하겠습니다. 그러면, 새 변수를 만들기 위해서는 다음과 같이 써 주면 됩니다.\n\nprojects |&gt;\n    mutate(size_kw = total_price_excluding_optional_support * 1200)\n\n# A tibble: 664,098 x 36\n   projectid               teacher_acctid schoolid school_ncesid school_latitude\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;\n 1 316ed8fb3b81402ff6ac8f~ 42d43fa6f3731~ c0e6ce8~ 063627006187             36.6\n 2 90de744e368a7e4883223c~ 864eb466462bf~ d711e47~ 483702008193             32.9\n 3 32943bb1063267de6ed19f~ 37f85135259ec~ 665c361~ 410327000109             45.2\n 4 bb18f409abda2f264d5acd~ 2133fc46f951f~ 4f12c3f~ 360015302507             40.6\n 5 24761b686e18e5eace6346~ 867ff478a63f5~ 10179fd~ 062271003157             34.0\n 6 eac7d156205f1333de3887~ ff064802c18e6~ 929336e~ 040187001058             33.3\n 7 5a3bfdf2e05781ccd0654d~ 085794a9e315b~ dc34b02~ 010060000256             32.8\n 8 afda16eb54d8992db7bb42~ 1d94a31c2dc38~ 86fff7c~ 130129000571             33.9\n 9 2ab3efb23acc84017cd789~ 5a497c425e05b~ ed170a1~ 261200001297             42.4\n10 3118962680bb062323c356~ eb0855cc6ea55~ 71b4dee~ 340264001386             40.0\n# i 664,088 more rows\n# i 31 more variables: school_longitude &lt;dbl&gt;, school_city &lt;chr&gt;,\n#   school_state &lt;chr&gt;, school_zip &lt;chr&gt;, school_metro &lt;chr&gt;,\n#   school_district &lt;chr&gt;, school_county &lt;chr&gt;, school_charter &lt;lgl&gt;,\n#   school_magnet &lt;lgl&gt;, school_year_round &lt;lgl&gt;, school_nlns &lt;lgl&gt;,\n#   school_kipp &lt;lgl&gt;, school_charter_ready_promise &lt;lgl&gt;,\n#   teacher_prefix &lt;chr&gt;, teacher_teach_for_america &lt;lgl&gt;, ...\n\n\n보시다시피, 위의 코드를 실행시키면, 원래 projects 테이블에 새로 만들어진 변수가 추가된 커다란 테이블이 출력됩니다. 하지만 이러한 코드에는 문제가 있습니다. 여러번 반복해서 말하기 때문에 눈치채신 분도 있겠지만, 이렇게 새로 만들어진 테이블은 원래의 테이블과는 다른 새로운 테이블이고, 이 새로운 테이블에는 이름이 없습니다! 이름이 없는 데이터는 존재하지 않는 데이터나 마찬가지라고 했지요? 따라서, 기껏 새로운 변수를 만들고 모니터로 한 번 확인하고는 이를 그냥 버린 것과 다름 없습니다.\n그렇다면, projects 테이블에 새 변수(열)을 추가 하려면 어떻게 해야 할까요? 다음과 같이 하면 됩니다.\n\nprojects &lt;- projects |&gt;\n    mutate(size_kw = total_price_excluding_optional_support * 1200)\n\n앞의 예와 유일한 차이는 projects &lt;- 이 부분 뿐입니다. 즉, mutate()을 통해 새로운 테이블을 만든 후, 그 테이블의 이름을 원래의 테이블 이름인 projects에 할당해 버린 것이지요. 엄밀히 말하면, 이제 변수를 새로 만들기 전 원래 테이블은 사라져 버리고, 새로운 테이블이 원래의 테이블을 대신해서 projects라는 이름을 대체하고 있는 것이지요.\n만약, size_kw라는 새로운 변수를 만들지 않고, 원화로 표시된 숫자가 원래 total_price_excluding_optional_support 열에 기록된 숫자를 대체하기를 바란다면 어떻게 할까요? 위의 예와 비슷한 논리로 다음과 같이 하면 됩니다.\n\nprojects |&gt;\n    mutate(total_price_excluding_optional_support = total_price_excluding_optional_support * 1200)\n\n# A tibble: 664,098 x 36\n   projectid               teacher_acctid schoolid school_ncesid school_latitude\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;\n 1 316ed8fb3b81402ff6ac8f~ 42d43fa6f3731~ c0e6ce8~ 063627006187             36.6\n 2 90de744e368a7e4883223c~ 864eb466462bf~ d711e47~ 483702008193             32.9\n 3 32943bb1063267de6ed19f~ 37f85135259ec~ 665c361~ 410327000109             45.2\n 4 bb18f409abda2f264d5acd~ 2133fc46f951f~ 4f12c3f~ 360015302507             40.6\n 5 24761b686e18e5eace6346~ 867ff478a63f5~ 10179fd~ 062271003157             34.0\n 6 eac7d156205f1333de3887~ ff064802c18e6~ 929336e~ 040187001058             33.3\n 7 5a3bfdf2e05781ccd0654d~ 085794a9e315b~ dc34b02~ 010060000256             32.8\n 8 afda16eb54d8992db7bb42~ 1d94a31c2dc38~ 86fff7c~ 130129000571             33.9\n 9 2ab3efb23acc84017cd789~ 5a497c425e05b~ ed170a1~ 261200001297             42.4\n10 3118962680bb062323c356~ eb0855cc6ea55~ 71b4dee~ 340264001386             40.0\n# i 664,088 more rows\n# i 31 more variables: school_longitude &lt;dbl&gt;, school_city &lt;chr&gt;,\n#   school_state &lt;chr&gt;, school_zip &lt;chr&gt;, school_metro &lt;chr&gt;,\n#   school_district &lt;chr&gt;, school_county &lt;chr&gt;, school_charter &lt;lgl&gt;,\n#   school_magnet &lt;lgl&gt;, school_year_round &lt;lgl&gt;, school_nlns &lt;lgl&gt;,\n#   school_kipp &lt;lgl&gt;, school_charter_ready_promise &lt;lgl&gt;,\n#   teacher_prefix &lt;chr&gt;, teacher_teach_for_america &lt;lgl&gt;, ...\n\n\n즉, 원래의 값에 1200을 곱한 값에 원래의 이름을 할당함으로써, 새로운 값이 원래의 값을 대체하도록 하는 것입니다.\n앞서 projects 테이블에 프로젝트 목표액에 해당하는 열이 두 개라고 했지요? 앞에서 사용한 것과 다른 하나는 total_price_including_optional_support 입니다. 앞에서 사용한 변수가 “optional_support”라는 것을 제외한(excluding) 금액이었다면, 두번째 변수는 “optional_support”를 포함한다(including)는 차이가 있습니다. 사실 “optional support”는 해당 프로젝트에 지원되는 금액이 아니라, ’donorschoose.org’에 지원되는 금액을 의미합니다. ’donorschoose.org’도 서비스를 유지하기 위해 직원 월급, 홈페이지 유지비 등 다양한 비용을 지불해야 할테니까요.\n이제 기자가 이 “optional_support”가 전체 프로젝트 목표액에서 차지하는 비율(%)에 관심을 가지게 되었다고 합시다. 그러면 두 개의 목표액 수치를 조합해서 이 비율을 계산해야 하겠네요. 이 역시 mutate()을 이용해 쉽게 할 수 있습니다.\n\nprojects |&gt;\n    mutate(ratio = (total_price_including_optional_support - total_price_including_optional_support) / total_price_excluding_optional_support)\n\n# A tibble: 664,098 x 37\n   projectid               teacher_acctid schoolid school_ncesid school_latitude\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;\n 1 316ed8fb3b81402ff6ac8f~ 42d43fa6f3731~ c0e6ce8~ 063627006187             36.6\n 2 90de744e368a7e4883223c~ 864eb466462bf~ d711e47~ 483702008193             32.9\n 3 32943bb1063267de6ed19f~ 37f85135259ec~ 665c361~ 410327000109             45.2\n 4 bb18f409abda2f264d5acd~ 2133fc46f951f~ 4f12c3f~ 360015302507             40.6\n 5 24761b686e18e5eace6346~ 867ff478a63f5~ 10179fd~ 062271003157             34.0\n 6 eac7d156205f1333de3887~ ff064802c18e6~ 929336e~ 040187001058             33.3\n 7 5a3bfdf2e05781ccd0654d~ 085794a9e315b~ dc34b02~ 010060000256             32.8\n 8 afda16eb54d8992db7bb42~ 1d94a31c2dc38~ 86fff7c~ 130129000571             33.9\n 9 2ab3efb23acc84017cd789~ 5a497c425e05b~ ed170a1~ 261200001297             42.4\n10 3118962680bb062323c356~ eb0855cc6ea55~ 71b4dee~ 340264001386             40.0\n# i 664,088 more rows\n# i 32 more variables: school_longitude &lt;dbl&gt;, school_city &lt;chr&gt;,\n#   school_state &lt;chr&gt;, school_zip &lt;chr&gt;, school_metro &lt;chr&gt;,\n#   school_district &lt;chr&gt;, school_county &lt;chr&gt;, school_charter &lt;lgl&gt;,\n#   school_magnet &lt;lgl&gt;, school_year_round &lt;lgl&gt;, school_nlns &lt;lgl&gt;,\n#   school_kipp &lt;lgl&gt;, school_charter_ready_promise &lt;lgl&gt;,\n#   teacher_prefix &lt;chr&gt;, teacher_teach_for_america &lt;lgl&gt;, ...\n\n\n두 목표액의 차이가 “optional support” 금액에 해당할 것이고, 이를 optional support를 포함한 목표액으로 나눈 것이 전체 목표액에서 “optional support”가 차지하는 비율이 되겠지요.\n이번에는 변수의 데이터 타입을 바꾸기 위해 mutate()을 사용하는 경우를 살펴보겠습니다. projects 테이블에는 school_zip이라는 변수가 있는데요, 이는 학교 우편번호를 뜻합니다. 그런데 데이터를 로드한 결과 이 우편번호가 문자(character)로 인식되어 있습니다. 이를 숫자로 다시 인식시켜주고 싶다고 하죠. 이에 해당하는 코드는 다음과 같습니다.\n\nprojects &lt;- projects |&gt;\n    mutate(school_zip = as.numeric(school_zip))\n\nas.numeric() 이라는 함수가 데이터의 타입을 숫자로 바꾸라는 뜻이니, school_zip의 데이터 타입을 숫자로 바꾼다음, 그 결과물을 원래 변수명인 school_zip에 대체해 버린 것입니다. 이렇게 새로운 데이터 타입을 가지게 된 컬럼을 포함한 새 테이블을 원래 테이블 이름인 projects에 할당해 버렸습니다(projects &lt;- 부분). 따라서 이제 projects 테이블의 school_zip 열은 문자가 아닌 숫자 입니다.\n\n\n7.2.4 join\n두 테이블을 연결하고 싶은 경우도 있습니다. 앞서 본 projects와 donations의 관계가 바로 그렇습니다. donations 테이블에 기록된 것은 각각의 기부들인데, 각 기부는 특정 프로젝트를 위한 것일테니, 기부에 대한 정보와 프로젝트에 대한 정보는 연결될 수 있겠지요. donations 테이블에는 projectid라는 열이 있는데, 이것이 바로 어떤 프로젝트에 대한 기부인지를 표현해 주는 정보입니다. 그리고 똑같은 이름의 열이 projects 테이블에도 존재합니다. 이 테이블에서 projectid는 각 프로젝트의 고유번호겠지요. 따라서, donations 테이블에 있는 projectid가 일치하는 프로젝트를 projects 테이블에서 찾으면 해당 프로젝트에 대한 정보를 찾을 수 있겠지요.\n\n\n\nJoin 가능한 테이블의 예\n\n\n더 나아가, projectid를 이용해 두 테이블을 연결하는 것도 가능합니다. 이를 데이터베이스 용어로 ’join’이라고 합니다.\ndonorschoose.org의 큰 테이블을 join하기에 앞서, 아주 간단한 예로 연습을 해 보도록 하지요. 먼저 가상의 두 테이블을 만들겠습니다.\n\nleft &lt;- data.frame(Key=c(1,2,3),\n                   ColA=c(\"R1\",\"R2\",\"R3\"))\n\nright &lt;- data.frame(Key=c(1,2,4),\n                   ColB=c(\"F1\",\"F2\",\"F4\"))\n\n각 테이블은 출력해보면 알겠지만, 두 테이블은 다음과 같이 생겼습니다.\n\n\n\nLeft-Right 테이블\n\n\n테이블 이름이 left, right인 이유는 앞으로 작성할 코드에서 left 테이블을 먼저, 즉, 왼쪽에 써주고, right 테이블을 나중에, 즉, 오른쪽에 써 줄 것이기 때문입니다.\n이 두 테이블이 Key열을 이용해 연결 가능하다는 것은 바로 아시겠지요? 다만, 문제가 있습니다. left 테이블에는 Key의 값으로 1,2,3이 있고, 오른쪽 테이블에는 1,2,4가 있습니다. 즉, 연결이 안 되는 값이 있습니다. 이 때 왼쪽, 오른쪽 중 어느 테이블을 기준으로 두 테이블을 붙여줄 것인가에 따라, ’left join’과 ’right join’이 구분됩니다.\n먼저 left join 입니다.\n\nleft_join(left, right, by=\"Key\")\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n3   3   R3 &lt;NA&gt;\n\n\nleft 테이블을 기준으로 했으니, left 테이블에 있는 모든 값에, Key에 의해 매칭이 되는 right 테이블의 정보가 연결되었습니다. Key 3에 해당하는 right 테이블의 행은 없으니 ColB는 결측값으로 남아있고요. right 테이블에서 매칭이 되지 못한 Key 4에 해당하는 값은 버려졌습니다.\n위의 코드는 다음과 같이 써도 무방합니다.\n\nleft_join(left, right, by=c(\"Key\"=\"Key\"))\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n3   3   R3 &lt;NA&gt;\n\n\nby=c(\"Key\"=\"Key\")는 왼쪽 테이블의 Key열과 오른쪽 테이블의 Key열을 매칭하라는 의미입니다. 지금은 이러한 문법이 중요하지 않지만, 경우에 따라서는 매칭할 열임에도 불구하고 왼쪽 테이블과 오른쪽 테이블에서 다른 이름을 사용하고 있는 경우가 있습니다.\n또 다음과 같은 코드도 같은 의미입니다.\n\nleft |&gt; left_join(right, by=c(\"Key\"=\"Key\"))\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n3   3   R3 &lt;NA&gt;\n\n\n이는 left_join() 함수의 첫번째 인수가 파이프에 의해 함수 바깥 왼쪽으로 나간 것이니 지금까지 해온 파이핑과 같은 경우 입니다. 이렇게 하면 앞서와 마찬가지로 가독성 있게 코드를 길게 늘여 쓰는데 도움이 됩니다.\n이제 ’right join’을 해 보지요.\n\nleft |&gt; right_join(right, by=\"Key\")\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n3   4 &lt;NA&gt;   F4\n\n\n이번엔 반대로 오른쪽 테이블 기준으로 연결된 것을 알 수 있지요?\n사실 join에는 몇 가지가 더 있습니다. 그 중 자주 쓰는 것으로 ’full join’이 있습니다. 이것은 매칭이 안 되더라도 한 쪽 테이블에라도 있으면 일단 연결해주는 방식입니다. 즉, 어떤 정보도 버리지 않는 것이지요.\n\nleft |&gt; full_join(right, by=\"Key\")\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n3   3   R3 &lt;NA&gt;\n4   4 &lt;NA&gt;   F4\n\n\n반대로 양쪽 테이블에 모두 정보가 있어야만 연결을 해 주는 ’inner join’도 있습니다.\n\nleft |&gt; inner_join(right, by=\"Key\")\n\n  Key ColA ColB\n1   1   R1   F1\n2   2   R2   F2\n\n\n이제 donorschoose.org의 두 테이블을 연결해 보도록 하지요.\n일단, donations 테이블이 projects 테이블보다 훨씬 더 큰 테이블일 수밖에 없다는 것을 확인합시다. 왜냐하면, 하나의 프로젝트에 대해서 여러개의 기부가 이루어졌을 수 있기 때문이지요. 만약 프로젝트 A에 대해서 기부가 세번 이루어졌다면 ’A’라는 프로젝트의 고유값은 donations 테이블에 세번 등장할 것입니다. 따라서, donations 테이블을 기준으로 projects 테이블을 연결하는 것이 자연스럽겠지요.\n대신 projects 테이블에는 21개의 열이, donations 테이블에는 35개의 열이 있으니, 연결 후 정보를 확인하기 너무 어렵습니다. 각 테이블에서 일부 관심있는 열만 뽑아서 연결한 후, 이를 connected라는 테이블로 메모리에 저장하겠습니다..\n\nconnected &lt;- donations |&gt;\n    select(projectid, donation_to_project, donation_optional_support, donation_timestamp) |&gt;\n    left_join(projects |&gt;\n                  select(projectid, total_price_including_optional_support), \n              by = c(\"projectid\"=\"projectid\"))\nconnected\n\n# A tibble: 3,097,989 x 5\n   projectid      donation_to_project donation_optional_su~1 donation_timestamp \n   &lt;chr&gt;                        &lt;dbl&gt;                  &lt;dbl&gt; &lt;dttm&gt;             \n 1 ffffac55ee02a~               42.5                    7.5  2011-08-25 14:27:34\n 2 ffffac55ee02a~               26.8                    4.73 2011-11-04 07:54:21\n 3 ffffac55ee02a~               55.4                    0    2011-11-02 22:53:53\n 4 ffffac55ee02a~                8.5                    1.5  2011-11-03 23:54:01\n 5 ffffac55ee02a~               20                      0    2011-11-02 23:21:00\n 6 ffffac55ee02a~                4.25                   0.75 2011-10-16 20:59:09\n 7 ffffac55ee02a~               50                      0    2011-08-31 08:13:55\n 8 ffff97ed93720~              212.                    37.5  2010-11-12 16:11:46\n 9 ffff97ed93720~              185.                    32.6  2010-12-01 14:52:17\n10 ffff97ed93720~               21.2                    3.75 2010-11-23 09:09:10\n# i 3,097,979 more rows\n# i abbreviated name: 1: donation_optional_support\n# i 1 more variable: total_price_including_optional_support &lt;dbl&gt;\n\n\n조금 길어졌지만, 잘 뜯어보면 donations 테이블에서 4개의 열을 뽑아서 그것을 왼쪽 테이블로, projects 테이블에서 2개의 열을 뽑아 오른쪽 테이블로 삼은 다음, prjectid열을 이용해 left_join() 한 것에 불과합니다. 어렵지 않지요?\n단, 여기서 자주 나오는 실수중 하나는 각 테이블에서 일부 열을 select()할 때 매칭할 열을 뽑지 않는 것입니다. 즉, 위의 경우라면, 양쪽 테이블에서 projectid 테이블을 각각 select() 해 두어야 연결이 가능하겠지요.\n\n\n7.2.5 피벗\n데이터를 분석하다보면, 같은 정보를 그대로 유지하되, 테이블의 형태만 바꾸어야 하는 경우가 있습니다. 이게 무슨 말인가 하는 분도 있겠지만, 일단 다음 두 개의 테이블을 비교해 보도록 하지요.\n\ncountries_longer &lt;- data.frame(country = c(\"x\",\"x\",\"x\",\"y\",\"y\",\"y\",\"z\",\"z\",\"z\"),\n                        year = rep(c(1960, 1970, 2010), 3),\n                        ranking = c(10,13,15,20,23,25,30,33,35))\ncountries_longer\n\n  country year ranking\n1       x 1960      10\n2       x 1970      13\n3       x 2010      15\n4       y 1960      20\n5       y 1970      23\n6       y 2010      25\n7       z 1960      30\n8       z 1970      33\n9       z 2010      35\n\n\n\ncountries_wider &lt;- countries_longer |&gt; \n    pivot_wider(names_from=\"year\", names_prefix=\"yr\", values_from=\"ranking\")\ncountries_wider\n\n# A tibble: 3 x 4\n  country yr1960 yr1970 yr2010\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 x           10     13     15\n2 y           20     23     25\n3 z           30     33     35\n\n\n잘 보면 아시겠지만, 두 개의 테이블은 완벽하게 같은 정보를 담고 있습니다. countries_wider 테이블에 countries_longer 테이블과 다른 점이라고는 단지 year 칼럼에 들어갔던 연도 데이터가 칼럼 이름으로 바뀌었다는 점 뿐입니다. 그 차이 때문에 첫번째 테이블은 길쭉한(long) 모양새를 하고 있고, 두번째 테이블은 넓은(wide) 형태를 하고 있습니다. 따라서 첫번째 테이블 형태를 ‘long 포맷’, 두번째 형태를 ’wide 포맷’이라고 부릅니다.\n두 번째 테이블을 만들 때에는 직접 데이터를 집어 넣어서 만든 것이 아니라, 첫 번째 테이블을 변형해서 만들었습니다. 이렇게 두 개의 ‘포맷’ 사이를 왔다 갔다 하며 테이블의 형태를 바꾸는 것을 ’피벗’이라고 합니다. 그리고 long 포맷을 wide 포맷으로 바꾸는 함수가 바로 pivot_wider() 입니다. 위의 사용 예에서 pivot_wider() 함수의 인수는 4개 입니다. 하나는 형태를 바꿀 데이터 그 자체(위에서는 countries_wider 테이블 입니다), 두번째는 names_from에 들어갈 칼럼 이름, 즉, 피벗이 되고 나면, 칼럼 이름으로 바뀔 부분 입니다. 세번째는 names_prefix에 들어갈 문자 입니다. 위의 예에서는 “yr” 이라고 정해주었기 때문에 새로운 테이블에서 칼럼 이름이 “yr”로 시작하게 된 것입니다. 이 인수는 사실 꼭 사용해야 하는 것은 아니지만, 사용하지 않을 경우, 위의 예에서는 칼럼 이름이, 1960, 1970, 2010 이렇게 숫자로만 어루어져 있었겠지요? 이는 나중에 에러의 원인이 될 수 있습니다. 그래서 편의상 “yr”이라는 문자를 앞에 붙여주도록 지정해 준 것이지요. 마지막으로 사용한 인수는 values_from 입니다. 이것은 wide 포맷에서 (칼럼 이름이 아닌) 테이블 안의 값들이 long 포맷의 어느 칼럼에서 와야 하는지를 정해주는 것입니다. long 포맷의 ranking 컬럼에 속한 수들이 wide 포맷에서는 yr1960, yr1970, yr2010 칼럼의 값으로 들어간 것이 보이시지요?\n물론 반대로 wide 포맷을 long 포맷으로 바꿀 수도 있습니다 (사실은 이쪽이 훨씬 더 자주 사용합니다!).\n\ncountries_wider |&gt; \n    pivot_longer(cols=!country, names_to=\"year\", names_prefix=\"yr\", values_to=\"ranking\")\n\n# A tibble: 9 x 3\n  country year  ranking\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 x       1960       10\n2 x       1970       13\n3 x       2010       15\n4 y       1960       20\n5 y       1970       23\n6 y       2010       25\n7 z       1960       30\n8 z       1970       33\n9 z       2010       35\n\n\npivot_wider() 함수의 인수와 pivot_longer() 함수의 인수가 미묘하게 다르다는 점을 잘 봐두세요. pivot_longer() 함수의 인수는 names_from, values_from이 아니라 names_to, values_to 입니다. 해당 인수들이 무엇을 의미하는지는 pivot_wider()를 잘 이해 했다면 이 역시 잘 이해할 수 있을 것입니다. 더 중요한 차이는 cols라는 인수입니다. 이는 내가 ‘길게’만들어 주고 싶은 칼럼을 정해주는 것입니다. 위의 예에서 !country라고 한 것은 country 칼럼 말고 ’나머지’(not) 부분을 길게 만들어달라는 뜻입니다.\n지금까지의 이야기를 요약하면 다음 그림과 같습니다.\n\n\n\n피벗 개념\n\n\n그런데, 이런 피봇은 왜 하게 될까요? 여러 이유가 있겠지만, 가장 중요한 이유는 내가 분석이나 시각화를 위해 사용하고 싶은 함수가 특정 포맷으로 되어 있는 데이터를 요구하기 때문입니다. 단적으로, 앞으로 이용할 시각화 툴들은 long 포맷을 요구합니다. 하지만, 만약 여러분이 wide 포맷의 데이트를 입수했다면 피봇을 해야 하는 것이지요."
  },
  {
    "objectID": "summarise.html#summarise",
    "href": "summarise.html#summarise",
    "title": "8  데이터 요약하기 (= 분석하기)",
    "section": "8.1 summarise",
    "text": "8.1 summarise\ntidyverse 문법에서 데이터를 요약할 때에는 그게 어떤 방식의 요약이든간에, 요약을 한다고 선언해 주어야 합니다. 그 선언은 간단하게 summarise()라는 함수를 사용하면 됩니다. 그리고 그 함수 안에 ‘어느 변수를’ ‘어떤 방식으로’ 요약할 것인지만 써주면 됩니다.\n바로 다음과 같이 말이지요.\n\nprojects |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support),\n              avg_opt = mean(total_price_including_optional_support - \n                                 total_price_excluding_optional_support))\n\n# A tibble: 1 x 2\n  avg_size avg_opt\n     &lt;dbl&gt;   &lt;dbl&gt;\n1     542.    103.\n\n\n첫번째 줄의 의미는, total_price_excluding_optional_support 칼럼의 평균(mean())을 낸 다음 이를 avg_size라고 부르자는 의미 입니다. 두번째는 total_price_including_optional_support에서 total_price_excluding_optional_support을 뺀 값들의 평균을 낸 다음 이를 avg_opt라고 부르자는 의미입니다. 이렇게, 여러개의 요약을 한 번에 할 수 있습니다.\n어떻게 요약을 할 것인지에 해당하는 함수로 이번에는 평균, mean()을 사용했지만 그 외에도 여러가지가 있습니다.\n\n\n\n함수\n기능\n\n\n\n\nmean()\n평균\n\n\nmedian()\n중앙값\n\n\nsd()\n표준편차\n\n\nn()\n갯수\n\n\nmax()\n최대값\n\n\nmin()\n최소값"
  },
  {
    "objectID": "summarise.html#그룹별-요약",
    "href": "summarise.html#그룹별-요약",
    "title": "8  데이터 요약하기 (= 분석하기)",
    "section": "8.2 그룹별 요약",
    "text": "8.2 그룹별 요약\n전체 데이터를 요약하는 것이 유용할 때도 많지만, 사실 데이터 분석에서 훨씬 더 자주 사용하는 것은 그룹별 요약 입니다. 예컨대, 대한민국 1인당 국민소득이 관심사일 수도 있지만, 지역별 1인당 국민소득에 관심을 가질 때도 있는 것이지요.\n특히, 의미 있는 분석 결과를 도출하기 위해서는 특정 그룹 사이를 비교하는 것이 효과적이기 때문에, 이러한 그룹별 비교는 더욱 자주 사용하게 됩니다. 앞서의 예에서라면, 전라남도와 경상남도의 1인당 국민소득을 비교하는 것도 그룹별 비교이지만, 연도를 하나의 그룹이라고 생각한다면, 연도별 1인당 국민소득을 비교하는 것 역시 그룹별 비교라고 할 수 있습니다.\ntidyverse 문법에서 그룹별 요약을 하기 위해서는 summarise() 함수 앞에 group_by() 함수를 사용해 주면 됩니다. 단, group_by() 함수의 인수로 요약에 사용하고 싶은 그룹 정보가 담긴 컬럼명을 표시해주면 됩니다.\n\nprojects |&gt;\n    group_by(school_state) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support))\n\n# A tibble: 52 x 2\n   school_state avg_size\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 AK               516.\n 2 AL               507.\n 3 AR               524.\n 4 AZ               500.\n 5 CA               599.\n 6 CO               505.\n 7 CT               480.\n 8 DC               511.\n 9 DE               411.\n10 FL               488.\n# i 42 more rows\n\n\n이렇게 하면, donorschoose.org에 생성된 프로젝트들의 주별 평균 목표액 크기가 구해진 것입니다.\n이렇게 group_by()를 이용한 요약에서 두 가지를 이해하면 좋습니다.\n첫째, group_by()까지 실행했을 때는 것으로 보기에 아무 일도 일어나지 않습니다. 이를 확인하기 위해서 위의 코드에서 일부만을 실행해 보겠습니다.\n\nprojects |&gt;\n    group_by(school_state)\n\n# A tibble: 664,098 x 35\n# Groups:   school_state [52]\n   projectid               teacher_acctid schoolid school_ncesid school_latitude\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt;\n 1 316ed8fb3b81402ff6ac8f~ 42d43fa6f3731~ c0e6ce8~ 063627006187             36.6\n 2 90de744e368a7e4883223c~ 864eb466462bf~ d711e47~ 483702008193             32.9\n 3 32943bb1063267de6ed19f~ 37f85135259ec~ 665c361~ 410327000109             45.2\n 4 bb18f409abda2f264d5acd~ 2133fc46f951f~ 4f12c3f~ 360015302507             40.6\n 5 24761b686e18e5eace6346~ 867ff478a63f5~ 10179fd~ 062271003157             34.0\n 6 eac7d156205f1333de3887~ ff064802c18e6~ 929336e~ 040187001058             33.3\n 7 5a3bfdf2e05781ccd0654d~ 085794a9e315b~ dc34b02~ 010060000256             32.8\n 8 afda16eb54d8992db7bb42~ 1d94a31c2dc38~ 86fff7c~ 130129000571             33.9\n 9 2ab3efb23acc84017cd789~ 5a497c425e05b~ ed170a1~ 261200001297             42.4\n10 3118962680bb062323c356~ eb0855cc6ea55~ 71b4dee~ 340264001386             40.0\n# i 664,088 more rows\n# i 30 more variables: school_longitude &lt;dbl&gt;, school_city &lt;chr&gt;,\n#   school_state &lt;chr&gt;, school_zip &lt;chr&gt;, school_metro &lt;chr&gt;,\n#   school_district &lt;chr&gt;, school_county &lt;chr&gt;, school_charter &lt;lgl&gt;,\n#   school_magnet &lt;lgl&gt;, school_year_round &lt;lgl&gt;, school_nlns &lt;lgl&gt;,\n#   school_kipp &lt;lgl&gt;, school_charter_ready_promise &lt;lgl&gt;,\n#   teacher_prefix &lt;chr&gt;, teacher_teach_for_america &lt;lgl&gt;, ...\n\n\n이는 전체 projects 테이블을 출력하는 것과 동일합니다. 다만, 좌측 상단에 보면 ’Groups: school_state [52]’라는 표시가 있습니다. 즉, group_by() 함수를 실시하면 이용자가 지정한대로 그룹만 만들어둔 상태가 되는 것입니다. 실제로 효과가 나타나는 것은 summarise() 함수나 다른 함수를 이용해서 그룹별 연산을 한 다음이지요.\n한 가지만 더 이야기 하자면, 코드의 일부분만을 실행시키기 위해서는 위와 같이 부분을 새로 작성해서 실행해 주어도 되지만, 실행시키고 싶은 부분만으로 블록 설정한 다음 ’Alt+Enter’를 눌러주어도 됩니다. 이는 사실 여러분들의 코드에서 에러가 발생했을 때 버그가 있는 부분을 찾는 좋은 방법이기도 합니다.\n둘째, summarise() 함수를 이용해 요약한 결과 그 자체도 테이블 입니다. 따라서 그 결과물에도 서브세트, 요약, 피봇 등의 작업을 다시 적용할 있습니다. 바로 다음과 같은 경우가 그렇습니다.\n\nprojects |&gt;\n    group_by(school_state) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support),\n              count = n()) |&gt;\n    filter(avg_size &gt; 600)\n\n# A tibble: 3 x 3\n  school_state avg_size count\n  &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n1 HI               703.  2586\n2 La               654.     3\n3 NY               705. 73182\n\n\n이렇게 하면, 평균 프로젝트 목표액이 600달러를 초과하는 주만 결과를 확인할 수 있네요."
  },
  {
    "objectID": "summarise.html#날짜-정보를-이용한-그룹별-요약",
    "href": "summarise.html#날짜-정보를-이용한-그룹별-요약",
    "title": "8  데이터 요약하기 (= 분석하기)",
    "section": "8.3 날짜 정보를 이용한 그룹별 요약",
    "text": "8.3 날짜 정보를 이용한 그룹별 요약\n모든 프로그램 언어에서 날짜는 에러를 자주 발생시키는 골치덩어리 입니다. 하지만, 날짜 정보는 데이터 분석에서 빠질 수 없는 요소이기도 하지요. 제일 흔하게 하는 분석 중 하나가 ‘연도별 추이’ 따위를 계산하는 것인데, 이는 앞서도 언급했던 것처럼 연도에 따라 그룹별 평균을 내는 것에 지나지 않습니다.\n다행히 R에는 날짜 정보를 쉽게 다루기 위한 패키지 lubridate이 있습니다. 해당 패키지는 다른 패키지들과 유사하게 다음과 같이 설치합니다.\n\ninstall.packages(\"lubridate\")\n\n설치가 완료되면, 패키지를 불러옵니다.\n\nlibrary(lubridate)\n\n우리가 지금까지 사용해 온 projects 테이블에서 날짜 정보, 즉, 프로젝트가 언제 만들어졌는가는 date_posted 컬럼에 포함되어 있습니다. 먼저, 이 칼럼의 데이터 타입을 확인해 볼까요?\n\nstr(projects$date_posted)\n\n Date[1:664098], format: \"2014-05-12\" \"2014-05-12\" \"2014-05-11\" \"2014-05-11\" \"2014-05-11\" ...\n\n\nDate라는 데이터 타입을 가지고 있네요. 즉, R이 이미 이 컬럼에 담겨있는 값들을 날짜로 인식하고 있다는 것입니다. 하지만, 이는 운이 좋은 경우입니다. 많은 경우, R은 사람이 보기에는 날짜가 분명한 값들은 일반 문자라고 인식하는 경우가 많습니다. 이러한 “운이 덜 좋은” 경우를 가정하기 위해 다음과 같이 데이터 타입을 바꾸어 줍시다.\n\nprojects &lt;- projects |&gt;\n    mutate(date_posted = as.character(date_posted))\nstr(projects$date_posted)\n\n chr [1:664098] \"2014-05-12\" \"2014-05-12\" \"2014-05-11\" \"2014-05-11\" ...\n\n\n이제 데이터 타입이 문자(chr)로 바뀐 것이 보이지요? 이렇게 되면, 날짜 사이의 간격을 계산할 수도, 날짜에서 연도만 추출할 수도 없을것입니다. 하지만, lubridate의 기능을 이용하면 언제든지 이를 다시 날짜 타입으로 바꾸어 줄 수 있습니다.\n문자를 날짜로 인식시켜주기 위한 함수는 여러개가 있는데, 이는 날짜를 표현하는 포맷에 따라 달라집니다. 위의 경우에는 “년(year)-월(month)-일(day)”의 순서대로 표시하는 방식이니 해당 함수의 이름은 ymd() 입니다.\n\nprojects &lt;- projects |&gt;\n    mutate(date_posted = ymd(date_posted))\nstr(projects$date_posted)\n\n Date[1:664098], format: \"2014-05-12\" \"2014-05-12\" \"2014-05-11\" \"2014-05-11\" \"2014-05-11\" ...\n\n\n이제 다시 데이터 타입이 Date으로 돌아왔습니다. 만약 날짜를 표시하는 방식이 “2014-05-11”이 아니고, “May 11, 2014” 였다면, 해당 함수는 mdy()겠지요. 영국식으로 “11/5/2014” 였다면, dmy()였을 테고요.\nR이 date_posted를 날짜로 인식하고 있기 때문에, 여기서 연도를 추출하는 것도 어렵지 않습니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    select(year, date_posted)\n\n# A tibble: 664,098 x 2\n    year date_posted\n   &lt;dbl&gt; &lt;date&gt;     \n 1  2014 2014-05-12 \n 2  2014 2014-05-12 \n 3  2014 2014-05-11 \n 4  2014 2014-05-11 \n 5  2014 2014-05-11 \n 6  2014 2014-05-11 \n 7  2014 2014-05-11 \n 8  2014 2014-05-11 \n 9  2014 2014-05-11 \n10  2014 2014-05-11 \n# i 664,088 more rows\n\n\n이제 year 칼럼을 이용해 연도별 평균 프로젝트 목표액을 구해보도록 하죠.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support))\n\n# A tibble: 13 x 2\n    year avg_size\n   &lt;dbl&gt;    &lt;dbl&gt;\n 1  2002     609.\n 2  2003     952.\n 3  2004     435.\n 4  2005     641.\n 5  2006     693.\n 6  2007     547.\n 7  2008     443.\n 8  2009     625.\n 9  2010     484.\n10  2011     478.\n11  2012     516.\n12  2013     587.\n13  2014     626.\n\n\n연도별 평균을 주(state)에 따라 따로 계산할 수도 있을까요? 물론입니다. group_by()를 두 변수에 대해서 해 주면 되지요.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support))\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 455 x 3\n# Groups:   school_state [52]\n   school_state  year avg_size\n   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 AK            2007     380.\n 2 AK            2008     414.\n 3 AK            2009     412.\n 4 AK            2010     419.\n 5 AK            2011     442.\n 6 AK            2012     462.\n 7 AK            2013     577.\n 8 AK            2014     522.\n 9 AL            2003     339.\n10 AL            2004     546.\n# i 445 more rows\n\n\n이렇게 다양한 방식으로 요약한 결과를 그래프로 표현하면, 그것이 바로 시각화 입니다. 드디어 시각화를 배울 준비가 되었습니다."
  },
  {
    "objectID": "visualize.html#ggplot2의-기초-계층layer-개념-이해하기",
    "href": "visualize.html#ggplot2의-기초-계층layer-개념-이해하기",
    "title": "9  데이터 시각화",
    "section": "9.1 ggplot2의 기초: 계층(layer) 개념 이해하기",
    "text": "9.1 ggplot2의 기초: 계층(layer) 개념 이해하기\nggplot2는 상당히 독특한 문법 체계를 가지고 있습니다. 일단, ggplot2만의 독특한 계층(layer)체계를 이해해야 합니다. ggplot2는 시각화를 데이터로부터 최종 시각 표현까지 도달하기 위해 순서대로 계층을 쌓는 과정으로 이해합니다. 그 계층들은 다음과 같습니다.\n\nData\nAesthetic\nGeometries\nFacets\nStatistics\nCoordinates\nTheme\n\n다음 그림은 이를 표현하고 있습니다.\n\n\n\nggplot2의 계층 개념\n\n\n\nData 계층은 ggplot2로 시각화하고 싶은 테이블 형태의 데이터를 의미합니다. 해당 데이터에 포함된 각 컬럼은 ’변수’를 나타내는데, 시각화에 대해 이야기 할 때는 데이터에 포함된 변수를 외부변수라고 부르겠습니다.\n그 위에 Aesthetics 계층이 얹혀집니다. Aesthetics 계층은 Data계층에 포함된 외부변수와 ggplot2가 스스로 이해할 수 있는 내부변수 간의 연결을 만들어 줍니다. 그러한 내부변수들로는 다음과 같은 것들이 있습니다.\n\nx: x축 값으로 표현하는 변수\ny: y축 값으로 표현하는 변수\ncolor: 선 색깔로 표현하는 변수\nfill: 면적의 색깔로 표현하는 변수\nsize: 크기로 표현하는 변수\nlinetype: 선의 모양으로 표현하는 변수\ngroup: 그룹을 정의하는 변수 Aestheics 계층에서 이용자는 데이터에 포함된 컬럼, 즉, 외부 변수 중 어느 것들이 이들 내부 변수에 해당할 것인지를 지정해 주어야 합니다.\n\n그림: 외부변수-내부변수\nGeometries 계층은 그래프 타입이라고 생각하면 됩니다. 선 그래프, 바 그래프, 파이 차트 등이 대표적인 그래프 타입들입니다.\nFacets계층은 여러개의 그래프를 동시에 표현하는 것을 의미합니다. 예컨대, 한국과 미국에 대해 비교를 같은 종류의 그래프를 나란히 그려주는 것 입니다.\n그림: facets\nStatistics 계층은, 시각화 전에 ggplot2가 자체적으로 특정 계산을 해 주는 것을 의미합니다.\nCoordinates 계층은 말 그대로 좌표계를 선택하는 것입니다. 우리가 일반적으로 알고 있는 유클리디안 좌표계 말고도, 극 좌표계와 같이 특수한 좌표계를 이용할 수도 있고, 일반 좌표계에서도 x축의 간격과 y축의 간격을 다르게 하거나, x축과 y축을 바꾸어버릴 수도 있습니다.\n마지막으로 Theme 계층은 그 외 시각화의 미적 부분을 정의합니다.\n\n여기서 coordinates과 theme 계층은 기초적인 시각화를 위해 반드시 필요하기 보다는 시각화된 결과를 조금 더 (스토리텔링 관점에서) 보기 좋게 하기 위한 목적이 크기 때문에, 스토리텔링에 관한 변도의 장에서 따로 다루기로하고 여기서는 나머지 계층에 대해 설명해보겠습니다."
  },
  {
    "objectID": "visualize.html#ggplot2-사용해보기",
    "href": "visualize.html#ggplot2-사용해보기",
    "title": "9  데이터 시각화",
    "section": "9.2 ggplot2 사용해보기",
    "text": "9.2 ggplot2 사용해보기\n이제 바로 gglot2를 사용해 앞서 만들어낸 그룹별 요약을 바로 시각화 해 보겠습니다.\n\nlibrary(tidyverse)\noptions(scipen=999)\nprojects &lt;- read_csv(\"data/projects.csv\")\n\n\nprojects |&gt;\n    group_by(school_state) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support),\n              count = n()) |&gt;\n    filter(avg_size &gt; 600) |&gt;\n    ggplot() +\n    aes(x=school_state, y=avg_size, fill=school_state) +\n    geom_bar(stat=\"identity\") \n\n\n\n\nggplot()으로 시작하는 코드가 나오기 전까지의 코드는 이전 챕터에서 만들어낸 그룹별 요약 + 서브세트와 정확하게 동일합니다. 즉, 앞서 만들어낸 그룹별 요약는데 이어서, ggplot2의 계층을 규칙대로 쌓아주기만 하면, 시각화 자료가 만들어집니다. 그러면 ggplot2 문법 부분을 차례대로 설명해 볼까요? 1. ggplot(): 이제부터 ggplot2를 이용해 시각화를 시작한다는 의미입니다. 이 앞의 코드를 통해 만들어 낸 그룹별 요약의 결과 역시 데이터 프레임이라고 했고, 이를 파이프를 통해 ggplot() 함수와 연결 시켰기 때문에, 앞서 만든 요약 결과가 ggplot2를 통한 시각화의 ‘Data’ 계층에 해당한다는 것을 알 수 있습니다. 2. aes(x=school_state, y=avg_size, fill=school_state): aes()는 Aesthetics 계층을 의미합니다. 즉, 여기서는 ’내부변수’인 x, y, fill을 ’외부변수’인 school_state, avg_size, school_state와 연결시키고 있는 것입니다. 물론 이들 외부 변수 이름은 Data 계층에 존재하지 않는다면 에러가 발생할 것입니다. x와 fill 모두에 school_state이 연결되어 있다는 것에도 주목해보세요. x와 school_state이 연결되었기 때문에, x축의 한 자리마다 하나의 주에 해당하는 바 그래프가 그려진 것이지만, 또, fill과 school_state도 연결되었기 때문에, 각 주는 다른 색깔의 바 그래프를 가지게 된 것입니다. 내부변수 fill을 사용하지 않으면 어떻게 되는지 확인하고 싶다면, fill=school_state 부분을 지우고 다시 실행시켜보세요. 3. geom_bar(stat=\"identity\"): 먼저 geom_bar()는 Geometries 계층으로 바 그래프를 선택했다는 것을 의미합니다. 그런데 그 안에 stat=\"identity\"라는 인수가 있지요? 이는 Statistics 계층에 대한 조작입니다. geom_bar() 함수는 우리가 아무런 지시도 하지 않으면 기본 동작으로 Data 계층에서 숫자를 센다음 이를 내부 변수 y로 삼으려는 계산 즉, Statistics 계층에서의 행동을 기본 값으로 가지고 있습니다. 다른 geometries 함수들은 대개 그렇지 않은데, 이는 geom_bar() 함수의 특성입니다. 그런데, 우리는 우리가 원하는 y 값으로 avg_size를 미리 계산해 두었지요? 따라서, stat=\"identity\"라는 옵션을 줌으로써 이용자가 Data 계층을 통해 공급한 외부 변수와, Aestheics 계층에서 만든 내부변수 y와의 연결을 “시키는 그대로(=identity)” 받아들이라고 명령하는 것입니다.\n여기까지 해서 우리는 위의 코드를 통해 Statistics 계층까지를 지정해준 것입니다. 그 외의 계층은 별도로 건드리지 않으면 기본값에 따라 시각화 표현을 만들어 줍니다.\n또 하나 유의해야 할 것은 ggplot()이라고 시각화 코드가 시작하면, 거기서부터는 |&gt;라는 지금까지 써왔던 파이프 대신 +를 파이프로 사용한다는 것입니다. 이를 잊어버리는 것도 에러를 발생시키는 흔한 원인이 되니 유의하기 바랍니다.\n경우에 따라서는 막대 그래프를 세로가 아니라 가로로 그리고 싶을 때도 있습니다. 그럴 때는 어떻게 하면 좋을까요? 내부변수 x에 대응하는 외부변수와 y에 대응하는 외부변수를 바꿔지기만 하면 됩니다. 즉, Aesthetics 계층만 살짝 수정해부면 되는 것이지요. 이제 왜 ggplot2의 계층 구조가 편리한 것인지 조금 감이 오실 것입니다. 다음 코드가 앞의 코드와 다른 점을 잘 찾아보세요.\n\nprojects |&gt;\n    group_by(school_state) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support),\n              count = n()) |&gt;\n    filter(avg_size &gt; 600) |&gt;\n    ggplot() +\n    aes(x=avg_size, y=school_state, fill=school_state) +\n    geom_bar(stat=\"identity\")"
  },
  {
    "objectID": "visualize.html#선그래프와-시간-데이터의-표현",
    "href": "visualize.html#선그래프와-시간-데이터의-표현",
    "title": "9  데이터 시각화",
    "section": "9.3 선그래프와 시간 데이터의 표현",
    "text": "9.3 선그래프와 시간 데이터의 표현\n이번에는 선 그래프를 그려보도록 하겠습니다. 선 그래프를 그리기 위해서는 Geometries 계층만 선그래프에 해당하는 것으로 바꿔주면 됩니다. geom_bar()를 geom_line()으로 대체해주는 것이지요.\n\nprojects |&gt;\n    group_by(school_state) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support),\n              count = n()) |&gt;\n    filter(avg_size &gt; 600) |&gt;\n    ggplot() +\n    aes(x=school_state, y=avg_size) +\n    geom_line(aes(group=1)) + \n    geom_point()\n\n\n\n\n이 그래프 역시 맨 처음의 막대 그래프와 거의 아무런 차이가 없습니다. 단, Geometries를 변경하기 위해 geom_bar() 대신 geom_line()을 사용해 주었지요. 그리고, geom_line() 안에도 Aesthetics, 즉, aes() 함수가 있습니다. 이 역시 내부 변수와 외부 변수를 연결하는 역할을 합니다. group 역시 ggplot2가 사용하는 내부변수라고 위에서 설명했지요? 그런데, 왜 geom_line() 안에 있을까요? 해당 연결은 그래프 전체를 그릴 때가 아니라, 선을 그릴 때만 유효했으면 하기 때문입니다. ‘선을 그릴 때만’ 이라니, 다른 것도 그린다는 이야기인가요? 그렇습니다. 위의 코드에서 geom_line() 뒤에 바로 geom_point()를 덧붙였지요? 이렇게 여러게의 Geometries 계층을 덧붙일 수 있다는 것을 잘 알아두세요! 선 뿐만 아니라 점도 함께 그린 것입니다(만약 이해가 잘 안 된다면, + geom_point() 부분만 지우고 실행시켜보세요). 그런데, 위의 코드는 (선을 그릴 때가 아니라) 점을 그릴 때에는 group이라는 내부 변수에 무언가를 연결한 것이 유효하지 않다는 것을 의미합니다.\n그런데 group=1은 무엇을 의미하는 것일까요? 사실 여기에서 설명하기엔 조금 복잡한 세부사항이 숨어있지만, ’그래프에 존재하는 모든 점이 하나의 그룹이라고 생각해라’라는 것을 의미한다고 일단 이해하시면 좋겠습니다. geom_line()은 ’선을 그린다’는 행위만을 알고 있을 뿐이지, (많은 경우) 어떤 점들을 이어서 선을 그어야 하는지는 모르거든요. 그래서 여기서는 모든 점을 다 이어서 선을 그리라는 의미로 group=1이라고 한 것입니다.\n또 하나 첫번째 코드와의 차이점은 stat=\"identity\"라는 표현이 이번에는 없다는 것입니다. geom_bar()를 사용할 때 stat=\"identity\"라는 옵션은 데이터의 숫자를 세는 geom_bar()가 기본값으로 가지는 행동을 억누르고, 주는 데이터를 있는 그대로 받아들이라는 뜻이라고 했지요? 그런데, geom_line()은 원래부터, 주는 데이터를 그대로 받아들입니다. 즉, geom_line()에게 stat=\"identity\"는 기본 옵션인 것이지요. 따라서, stat=\"identity\"라는 표현은 이 경우 써도 그만, 안 써도 그만 입니다.\n그런데, 여러분은 새로 그린 선 그래프가 막대 그래프보다 마음에 드나요? 저라면 이 경우에는 선 그래프를 추천하지 않을 것 같습니다. 나중에 데이터 스토리텔링을 이야기 하면서 좀 더 자세히 배우겠지만, 이렇게 선으로 연결된 점들을 보면, 인간의 뇌는 이 세 점 사이에 어떠한 연속성, 순서가 있는 것으로 자연스럽게 여기는 경향이 있습니다. 하지만, 위의 선 그래프에 표현된 세 개의 주 사이에는 어떠한 연속성도, 순서도 없지요. 이를, ‘범주형(categorical) 자료’ 또는 ’명목(nominal) 변수’라고 합니다. 즉, x축에 범주형 자료가 와야 할 때는 선 그래프가 잘 어울리지 않는 것이지요.\n그렇다면, 언제 선 그래프가 잘 어울릴까요? 여러분도 익숙하다시피, x축에 시간이 올 때 입니다. 그러면 시간 데이터를 이용한 선 그래프를 그려볼까요? 시간 데이터는 &lt;데이터 요약하기&gt; 장에서 한 번 다룬 바가 있습니다. 연도별 프로젝트 크기를 구하는 코드를 그대로 가져와 보도록 하지요.\n\nlibrary(lubridate)\n\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support))\n\n# A tibble: 13 x 2\n    year avg_size\n   &lt;dbl&gt;    &lt;dbl&gt;\n 1  2002     609.\n 2  2003     952.\n 3  2004     435.\n 4  2005     641.\n 5  2006     693.\n 6  2007     547.\n 7  2008     443.\n 8  2009     625.\n 9  2010     484.\n10  2011     478.\n11  2012     516.\n12  2013     587.\n13  2014     626.\n\n\n이제 자연스러운 ‘순서를 갖는’ year 변수가 있으니, 선그래프가 적합해 보입니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size) +\n    geom_line() +\n    geom_point()\n\n\n\n\nx축에 시간이 있으니, 조금 더 익숙한 모양의 그래프가 되지요? 우리는 자연스럽게 시간에 따른 ’경향(trend)’를 파악할 수 있습니다.\n물론 지금까지 배운 것들을 결합하면 여러개의 경향을 한 번에 표현할 수도 있습니다. &lt;데이터 요약하기&gt; 장에서 다룬 코드를 다시 한 번 가져와 보도록 하지요.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support))\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 455 x 3\n# Groups:   school_state [52]\n   school_state  year avg_size\n   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 AK            2007     380.\n 2 AK            2008     414.\n 3 AK            2009     412.\n 4 AK            2010     419.\n 5 AK            2011     442.\n 6 AK            2012     462.\n 7 AK            2013     577.\n 8 AK            2014     522.\n 9 AL            2003     339.\n10 AL            2004     546.\n# i 445 more rows\n\n\n보다시피, 연도 뿐만이 아니라, 각 주에 대해서도 프로젝트 목표액 평균이 구해졌습니다. 모든 주에 대해 그래프를 그리려면 너무 많을 테니, 앞서 분석한 세 개의 주 중, 하와이(HI)와 뉴욕(NY)에 대한 데이터만 filter()를 이용해 서브세팅 하기로 하지요.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\"))\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 21 x 3\n# Groups:   school_state [2]\n   school_state  year avg_size\n   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 HI            2007     438.\n 2 HI            2008     588.\n 3 HI            2009     445.\n 4 HI            2010     564.\n 5 HI            2011     455.\n 6 HI            2012     466.\n 7 HI            2013     896.\n 8 HI            2014     730.\n 9 NY            2002     611.\n10 NY            2003     971.\n# i 11 more rows\n\n\n%in%을 이용한 서브세팅에 주목해 보세요. 이제 Aesthetics 계층에서 x축과 연결할 데이터와 y축에 연결할 변수 뿐만 아니라, 다른 선에 연결할 변수, school_state도 구해졌습니다. 앞서 보았던 group 변수를 이용해서 다음과 같이 표현해 봅시다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size) +\n    geom_line(aes(group=school_state)) +\n    geom_point()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\ngroup=school_state라고 써 줌으로써, geom_line()에게 뉴욕주는 뉴욕주끼리, 하와이주는 하와주끼리 연결하라고 한 것입니다. 하지만, 이렇게 하면 문제가 하나 있습니다. 어느 선이 어느 주인지 알 수가 없다는 것이죠. 그래서 이번에는 group 변수 대신에 color 변수를 사용해 보겠습니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size) +\n    geom_line(aes(color=school_state)) +\n    geom_point()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n좀 더 명확하지요? 단, 점은 검은 색이라서 어색하긴 합니다. 왜냐하면 앞서 이야기 한 것처럼 color변수에 대한 설정을 geom_line()에만 적용하고, geom_point()에는 적용되지 않았기 때문입니다. 이럴 때에는 color=school_state를 ggplot 전체에 적용되는 Aesthetics 계층으로 옮겨주면 됩니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n요즘에는 그럴 일이 별로 없지만, 만약 흑백 매체라면, 이렇게 그룹별로 색깔만 달리한 그래프는 차이를 표현해 주지 못하겠지요? 그럴 때는 linetype, shape과 같은 변수를 이용하면 됩니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, linetype=school_state, shape=school_state) +\n    geom_line() +\n    geom_point()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "visualize.html#산포도와-상관관계-표현.",
    "href": "visualize.html#산포도와-상관관계-표현.",
    "title": "9  데이터 시각화",
    "section": "9.4 산포도와 상관관계 표현.",
    "text": "9.4 산포도와 상관관계 표현.\n막대 그래프는 하나의 축이 범주형 자료를 표현할 때, 선 그래프는 하나의 축이 시간을 표현할 때 사용하는 것이 좋다고 하였습니다. 두 경우 모두 나머지 하나의 축은 연속적인 숫자, 즉, 금액을 나타내었지요. 그런데, 만약 두 변수 모두 연속적인 변수라면 어떤 그래프를 사용할까요? 여러 방법이 있지만, 산포도(scatters plot)을 이용해서 두 연속형 변수 간의 상관관계(correlation)을 찾아내는 것이 일반적입니다. 산포도란, 데이터에 포함된 두 개의 변수를 x축 y축 상의 점으로 모두 표현해준 것을 의미합니다. 사실 ggplot2의 관점에서는 이미 사용해본 geom_point()를 활용한다는 것 이상의 의미를 가지지 않습니다.\n이번에는 크라우드펀딩 프로젝트를 통해 수혜를 얻는 학생의 수(students_reached)와 프로젝트 목표액 간에 상관관계가 있는지 알아보도록 하지요.\n\nprojects |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(500) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support) +\n    geom_point(alpha=0.3, stroke=NA)\n\n\n\n\n간단하지요? 편의상 포함한 filter() 부분과 sample_n() 부분을 제외하면, x와 y만 정해준 후, geom_point()를 이용하면 됩니다. filter()를 이용해 서브세팅을 한 이유는 크라우드펀딩 프로젝트 치고는 너무 큰 (목표액이 너무 크거나, 수혜를 입는 학생들이 너무 많은) 예외적인 경우를 제외해주기 위해서입니다. sample_n(500)은 전체 데이터에서 500개 행만 무작위로 뽑아달라는 의미입니다. 둘 다 꼭 해야 한다기 보다는 보기 좋은 그래프를 그리기 위한 편의상의 선택입니다.\n마찬가지 이유로 geom_point() 안에 옵션도 추가했습니다. alpha=0.3이라는 옵션은 산포도에 찍히는 점들을 투명하게 만들어주기 위한 것입니다. 숫자가 작을수록 투명해지는 것이고, alpha=1이 되면 완전히 불투명해 지는 것이지요. stroke=NA는 각 점의 테두리를 없애주기 위한 옵션입니다.\n자 두 변수 간에 상관 관계가 있는 것처럼 보이나요? 제 눈에는 별로 그렇게 보이지 않는데요, 이 상관관계 역시 시각적으로 표현할 수 있습니다. 위의 그래프에 하나의 계층만 추가하면 됩니다.\n\nprojects |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(500) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support) +\n    geom_point(alpha=0.3, stroke=NA) +\n    geom_smooth(method = lm, se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n여기서는 geom_smooth()라는 하나의 Geometries 계층만을 추가했습니다. 간단하게 상관관계를 직선으로 표현하고 있는데요, 우리 눈에 명확하지는 않지만, 양의 기울기를 갖는 것을 수혜를 입는 학생 수가 늘 수록, 프로젝트 목표액이 조금 느는 경향이 있는 것 같네요.\ngeom_smooth()에도 옵션을 사용했는데요, method=lm은 상관관계를 곡선이 아닌 직선으로(Linear Model) 표현해달라는 것이고, se=FALSE는 상관관계를 나타내는 해당 직선의 불확실성을 시각화하지 말라는 옵션입니다. 불확실성을 표현한다는 것이 무엇인지 확인하고 싶으시다면, 이 옵션을 TRUE로 바꿔서 다시 한 번 시각화 해 보세요."
  },
  {
    "objectID": "visualize.html#차원-이상의-데이터-시각화",
    "href": "visualize.html#차원-이상의-데이터-시각화",
    "title": "9  데이터 시각화",
    "section": "9.5 2차원 이상의 데이터 시각화",
    "text": "9.5 2차원 이상의 데이터 시각화\n지금까지 살펴본 시각화는 2차원 표현에 한정되었습니다. 이 말이 무슨 말이냐 하면, x축으로 표현되는 하나의 변수, 그리고 y축으로 표현되는 또 다른 변수, 이렇게 두개의 변수만을 시각화 하였다는 것입니다. 바로 위에서 살펴본 산포도를 보세요. 수혜를 받는 학생수(students_reached)라는 변수가 x축에, 프로젝트의 크기(total_price_excluding_optional_support)라는 두 개의 변수가 표현되어 있지요.\n그럼, 그 이상의 변수를 하나의 시각화에서 표현하고 싶다면 어떻게 해야 할까요? 물론 가장 쉽게 생각해볼 수 있는 방법은 3차원 그래프를 그리는 것입니다.\n3차원 그래프 그림\n하지만, 이는 불행이도 권장되지 않습니다. 3차원 그래프라고 해보았자, 결국에는 종이나 화면이라는 2차원 상에 표현한 3차원을 모방한 그림에 불과하죠. 인간의 뇌는 이러한 정보를 이해하는데 그다지 능숙하지 못합니다. 하지만 다른 방법이 있습니다. x축, y축 말고 다른 표현방식을 동원하는 것이지요. 대표적인 것이, 색깔, 크기, 모양 등등 입니다. 이게 무슨 뜻인지를 이해하기 위해서 바로 위에서 이용한 산포도를 조금 변형해보기로 하죠.\n예컨대 위에서 x축, y축으로 표현한 두 개 변수 이외에 세번째 변수로 donorschoose.org를 지원하기 위한 기부액, 즉, optional support를 시각화하고 싶다고 해 볼까요? x, y축은 이미 다른 변수가 차지하고 있으니, 저는 산포도에서 각 점의 크기로 이 세번째 변수를 표현해보겠습니다.\n\nprojects |&gt;\n    mutate(optional = total_price_including_optional_support - total_price_excluding_optional_support) |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(500) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support, \n        size=optional) +\n    geom_point(alpha=0.3, stroke=NA)\n\n\n\n\n위의 코드에서 두 번째 줄과 aes() 함수의 인수에 주목해주세요. 두 번째 줄에서는 optional support가 데이터에 포함되어 있지 않으므로, 이를 optional support를 포함한 프로젝트 크기와 포함하지 않은 프로젝트 크기의 차이로 계산한 새로운 변수 optional을 만들어주었습니다. aes() 함수는 이전과 유사하지만, size=optional이라는 인수가 추가되었습니다. 즉, size라는 내부 변수와 방금 계산한 optional이라는 외부 변수를 연결함으로써, ggplot2에게 optional이라는 변수는 점의 크기로 표현해달라고 말한 것이지요. 시각화 결과에서 점의 크기가 제각각인 것은 그때문입니다.\n그런데, 추가로 표현하고 싶은 세번째 변수가 optional support 같은 숫자가 아니라, 순서가 없는 카테고리라면 어떨까요? 예컨대, project데이터 안에는 프로젝트를 만든 해당 선생님이 재직하고 있는 학교의 빈곤율에 대한 데이터가 포함되어 있습니다. 이 빈곤률 변수의 이름은 poverty_level인데요, 여기에 어떤 값들이 포함되어 있는지 확인해 봅시다.\n\nunique(projects$poverty_level)\n\n[1] \"highest poverty\"  \"high poverty\"     \"moderate poverty\" \"low poverty\"     \n\n\n직관적으로 알 수 있듯이 4개의 카테고리가 있네요. 이를 점의 크기로 표현하는 것은 조금 부자연스러운 것 같습니다. 대신 색깔로 표현해 볼까요?\n\nprojects |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(500) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support, \n        color=poverty_level) +\n    geom_point(alpha=0.7, stroke=NA)\n\n\n\n\n여기서 바뀐 것은 aes() 함수 안에 있는 color=porverty_level 부분 뿐입니다.\n앞서 두가지 방식을 합하여 4개의 변수를 표현하는 것도 가능합니다.\n\nprojects |&gt;\n    mutate(optional = total_price_including_optional_support - total_price_excluding_optional_support) |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(500) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support, \n        size=optional,\n        color=poverty_level) +\n    geom_point(alpha=0.3, stroke=NA)"
  },
  {
    "objectID": "visualize.html#더-많은-정보를-표현하기-위한-facet-계층-이용",
    "href": "visualize.html#더-많은-정보를-표현하기-위한-facet-계층-이용",
    "title": "9  데이터 시각화",
    "section": "9.6 더 많은 정보를 표현하기 위한 Facet 계층 이용",
    "text": "9.6 더 많은 정보를 표현하기 위한 Facet 계층 이용\n그런데 바로 위의 예와 같이 4개의 변수를 동시에 표현하는 것은 역시 독자들에게 조금 부담스러울 수 있습니다. 이를 여러개의 그래프를 동시에 그리는 방식으로 해결하기 위한 것이 facet 계층입니다. facet 계층을 더해주기 위한 함수로는 facet_wrap()과 facet_grid()이 있는데요, 여기서는 전자만 살펴보겠습니다.\n다음의 예는 빈곤률을 색깔로 표현하는 대신, 빈곤률별로 산포도를 나누어서 그리기 위한 예시입니다.\n\nprojects |&gt;\n    mutate(optional = total_price_including_optional_support - total_price_excluding_optional_support) |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(2000) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support, \n        size=optional) +\n    geom_point(alpha=0.3, stroke=NA) +\n    facet_wrap(vars(poverty_level))\n\n\n\n\n여기서 추가된 것은 마지막줄 뿐입니다. 즉, facet_wrap()함수를 이용해 facet 계층을 더해주고 그 안에 vars()라는 함수의 인수로 그래프를 구분해서 그리는데 사용할 변수의 이름을 넣어주면 되는 것입니다.\n그런데, 모든 산포도가 흑백이니 조금 단조롭네요. 그래프를 빈곤율별로 나누었지만, 여전히 점의 색깔을 다르게 해 볼까요? 다음과 같이 하면 됩니다.\n\nprojects |&gt;\n    mutate(optional = total_price_including_optional_support - total_price_excluding_optional_support) |&gt;\n    filter(total_price_excluding_optional_support &lt; 1000 & students_reached &lt; 500) |&gt;\n    sample_n(2000) |&gt;\n    ggplot() +\n    aes(x=students_reached, y=total_price_excluding_optional_support, \n        size=optional,\n        color=poverty_level) +\n    geom_point(alpha=0.3, stroke=NA) +\n    facet_wrap(vars(poverty_level))\n\n\n\n\n네, aes() 함수 안에 원래대로 color=poverty_level이라는 인수를 다시 넣어주었을 뿐입니다. 이제 ggplot2는 계층을 계속해서 쌓아나가는 방식으로 시각화 정보를 조금씩 더 정교하게 만들 수 있다는 말이 조금 실감이 가시나요?"
  },
  {
    "objectID": "visualize.html#시각화를-위한-데이터-처리-워크플로우",
    "href": "visualize.html#시각화를-위한-데이터-처리-워크플로우",
    "title": "9  데이터 시각화",
    "section": "9.7 시각화를 위한 데이터 처리 워크플로우",
    "text": "9.7 시각화를 위한 데이터 처리 워크플로우\n일단 원하는 시각화를 만들어내고 나면, 필요한 분석이 모두 끝난 것입니다. 더 세련된 분석을 할 수도 있지만, 보통 기사를 쓸 때 위에서 보는 것과 같은 그래프를 효과적으로 만드는 것이 현실적으로 최종 목표이기 마련이지요.\n그런데, 지금까지 보여드린 시각화는 조금 간단한 경우입니다. 일단 project라는 하나의 데이터셋만을 이용했지요. 그리고 그 안에 우리가 시각화하고 싶은 변수들이 어지간히 이미 존재했고요. 이제 조금 더 현실적인, 즉, 조금 더 복잡한 경우를 생각해봅시다.\n이번에는 프로젝트의 목표액과 실제 기부되는 금액의 연도별 총액에 관심이 있다고 해 볼까요? 프로젝트 목표액은 projects 테이블에, 기부 금액은 donations 테이블에 있으니, 두 데이터를 모두 사용해야겠네요.\n먼저 연도별 프로젝트 총 목표액을 계산해보도록 하겠습니다. 앞서 이용해 본 lubridate 패키지의 year() 함수를 이용하는 것에 주목해 주세요.\n\nyearly_goals &lt;-projects |&gt;\n    mutate(year_posted = year(date_posted)) |&gt;\n    group_by(year_posted) |&gt;\n    summarise(total_goal = sum(total_price_excluding_optional_support))\nyearly_goals\n\n# A tibble: 13 x 2\n   year_posted total_goal\n         &lt;dbl&gt;      &lt;dbl&gt;\n 1        2002    312861.\n 2        2003   1872573.\n 3        2004   1985522.\n 4        2005   5908231.\n 5        2006  14054710.\n 6        2007  17289711.\n 7        2008  21292919.\n 8        2009  39746659.\n 9        2010  41829562.\n10        2011  49825420.\n11        2012  60714684.\n12        2013  77114580.\n13        2014  28021255.\n\n\n마찬가지로 donations 테이블로부터 연도별 총 기부액을 계산해보도록 하겠습니다.\n\ndonations &lt;- read_csv(\"data/donations.csv\")\n\nRows: 3097989 Columns: 21\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (9): donationid, projectid, donor_acctid, donor_city, donor_state, dono...\ndbl  (3): donation_to_project, donation_optional_support, donation_total\nlgl  (8): is_teacher_acct, donation_included_optional_support, payment_inclu...\ndttm (1): donation_timestamp\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nyearly_donations &lt;- donations |&gt;\n    mutate(year_donated = year(ymd_hms(donation_timestamp))) |&gt;\n    group_by(year_donated) |&gt;\n    summarise(total_donations = sum(donation_to_project))\nyearly_donations\n\n# A tibble: 15 x 2\n   year_donated total_donations\n          &lt;dbl&gt;           &lt;dbl&gt;\n 1         2000            100 \n 2         2001          66404.\n 3         2002         132464.\n 4         2003         880914.\n 5         2004        1453859.\n 6         2005        2531063.\n 7         2006        5495615.\n 8         2007        8867026.\n 9         2008       10959050.\n10         2009       17621316.\n11         2010       27524141.\n12         2011       31614936.\n13         2012       41838311.\n14         2013       52338678.\n15         2014        2975804.\n\n\n이 예에서 사용한 ymd_hms() 함수 역시 lubridate 패키지의 일부로 앞서 사용한 ymd() 함수처럼 해당 변수가 시간 정보임을 R에게 인식시켜주는 기능을 합니다. 다만, donation_timestamp 변수는 연-월-일 뿐 아니라, 시-분-초까지 기록되어 있기 때문에 ymd()함수가 아니라 ymd_hms() 함수를 사용한 것이지요.\n이 두 가지 결과를 시각화하기 위해서는 먼저 두 개의 결과를 하나의 데이터 프레임으로 합쳐야 합니다. 연도를 기준으로 두 테이블을 붙이는 것이니, 앞서 실습해 본 join을 이용하면 되겠네요.\n\nyearly_goals |&gt;\n    left_join(yearly_donations, by=c(\"year_posted\"=\"year_donated\"))\n\n# A tibble: 13 x 3\n   year_posted total_goal total_donations\n         &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;\n 1        2002    312861.         132464.\n 2        2003   1872573.         880914.\n 3        2004   1985522.        1453859.\n 4        2005   5908231.        2531063.\n 5        2006  14054710.        5495615.\n 6        2007  17289711.        8867026.\n 7        2008  21292919.       10959050.\n 8        2009  39746659.       17621316.\n 9        2010  41829562.       27524141.\n10        2011  49825420.       31614936.\n11        2012  60714684.       41838311.\n12        2013  77114580.       52338678.\n13        2014  28021255.        2975804.\n\n\n이는 일종의 시계열(time-seriese)이므로, 선 그래프로 표현하는 것이 자연스러워 보입니다. 특히, 목표액(goal)과 기부액(total_donations)를 다른 색깔의 선으로 보여줄 수 있다면 직관적이겠네요. 문제는 ggplot2를 이용해 해당 선그래프를 표현하기 위해서는 색깔에 해당하는 ‘내부변수’ color에 대응하는 변수, 즉, 목표액인지, 기부액인지를 표현하는 ‘변수’가 없고, total_goal과 total_donations라는 ’변수명’으로 존재한다는 것입니다. 따라서, 이 변수명을 변수값으로 만들어주어야 합니다. 이를 위해서 했던 것이 앞장에서 실습했던 데이터를 ’피벗’하여 ’넓은(wide)’한 데이터를 ’길쭉하게(long)’ 바꿔주는 것이었습니다.\n아래 그림과 유사하게 다시 그리기 https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html\n\nyearly_goals |&gt;\n    left_join(yearly_donations, by=c(\"year_posted\"=\"year_donated\")) |&gt;\n    pivot_longer(!year_posted, names_to=\"var\", values_to=\"val\")\n\n# A tibble: 26 x 3\n   year_posted var                   val\n         &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1        2002 total_goal        312861.\n 2        2002 total_donations   132464.\n 3        2003 total_goal       1872573.\n 4        2003 total_donations   880914.\n 5        2004 total_goal       1985522.\n 6        2004 total_donations  1453859.\n 7        2005 total_goal       5908231.\n 8        2005 total_donations  2531063.\n 9        2006 total_goal      14054710.\n10        2006 total_donations  5495615.\n# i 16 more rows\n\n\n이렇게 데이터를 길쭉하게 만들고 나면 새로 만들어진 var 변수를 ggplot2의 내부변수 color에 대응시켜줄 수 있습니다.\n\nyearly_goals |&gt;\n    left_join(yearly_donations, by=c(\"year_posted\"=\"year_donated\")) |&gt;\n    pivot_longer(!year_posted, names_to=\"var\", values_to=\"val\") |&gt;\n    ggplot() +\n    aes(x=year_posted, y=val, color=var) +\n    geom_line() +\n    geom_point()\n\n\n\n\n예상대로, 실제 기부액이 목표액보다는 적네요.\n이 시각화를 만들어 내는데 필요한 테크닉은 모두 앞에서 배운 것이지만, 과정이 조금 길었지요. 두 개의 데이터를 로드해서, 각각의 데이터를 분석한다음, 그 결과를 join한 후, long form 데이터로 변형해 최종적으로 ggplot2을 적용했습니다. 그런데, 이러한 긴 과정에 한 번에 바로 떠오르는 사람은 별로 없습니다. 데이터 분석의 경험이 부족하면 할수록 더욱 그렇지요.\n그러면, 실제로 데이터를 분석할 때 이 긴 과정을 어떻게 미리 설계해야 하는 것일까요? 어떻게 보면 분석에 필요한 코딩 기술보다 이 과정에 익숙해지는 것이 더 중요합니다. 분석은 다른 사람이 도와줄 수도 있는 것이니까요.\n답은 간단합니다. 앞에서 한 분석과 반대의 순서를 따르면 됩니다. 앞서의 워크 플로우를 표현하면 다음과 같습니다.\n\n\n\n시각화를 위한 워크플로우\n\n\n하지만 계획은 반대로 하는 것이지요. 이를 조금 더 자세히 설명해 보겠습니다.\n\n질문 만들기: 일단 좋은 질문이 있어야 겠지요.\n시각화 목표 그리기: 질문을 바탕으로 최종적으로 얻고 싶은 그림을 그려야 합니다. 당연히 분석 전이니 정확한 그림은 알 수 없지요. 하지만, 연도별 목표액과 기부액을 다른 색깔을 가진 두 개의 선 그래프로 표현하고 싶다는 계획은 세울 수 있지요. 이렇게 예상 가능한 시각화 결과를 일단 손으로 그려둡니다. 영화의 콘티를 만든다고 생각하면 좋을 것 같습니다.\n최종 데이터 형태 상상하기: 시각화 목표가 생겼으면, 시각화에 필요한 최종 데이터 형태가 무엇인지 알아야 합니다. 앞서 ggplot2로 색깔이 다른 두 개의 선 그래프를 그리기 위해서 ’길쭉한 형태’의 데이터가 필요하다고 하였지요? 그것이 바로 우리가 필요했던 최종 데이터의 형태입니다.\n결과 재구조화 설계하기: 그런데, 최종 형태의 데이터를 원 데이터에서 바로 얻게 되는 경우는 드뭅니다. 최종 형태는 원래 형태를 재구조화 한 결과인 경우가 더욱 많지요. 앞의 예에서 projects 테이블과 donations 테이블에 나온 두 개의 결과 테이블을 join한 다음 ’길쭉한 데이터’로 ’피벗’한 것이 바로 그러한 재구조화의 예 입니다. 이를 미리 설계해둡니다.\n데이터 분석 방법 설계하기: 결과의 재구조화 과정에 대한 계획이 끝나면, 재구조화 전에 어떠한 분석 결과를 가지고 있어야 했는지가 명확해집니다. 앞의 예에서는 projects 테이블에서 연도별 목표액이, donations 테이블에서 연도별 기부액이 계산되어야 한다는 점이 명확해지지요.\n데이터 소스 찾기 및 재구조화: 분석 방법을 설계하고 나면, 어떤 데이터가 필요한지가 분명해집니다. 앞의 예에서는 projects, donations 테이블이 바로 그것이지요. 실전에서는 막상 이렇게 필요한 원데이터가 없어 이곳저곳을 다시 뒤져야 하거나, 원 데이터를 변형하여 필요없는 데이터를 제외하거나, 기존 변수로부터 새로운 변수를 만들어야 하는 경우도 있습니다.\n\n이를 도식화하면 다음과 같습니다.\n그림: 질문하기 -&gt; 시각화 목표 그리기 -&gt; 최종 데이터 형태 -&gt; 분석 결과 재구조화 설계 -&gt; 분석 방법 설계 -&gt; 데이터 찾기/재구조화\n물론 이 과정이 꼭 한 번에 끝나는 것은 아닙니다. 어떤 경우에는 결국 필요한 원데이터를 찾지 못해 원래의 질문, 시각화 목표를 수정하는 과정을 반복해야 하는 경우도 있겠지요. 그러나 중요한 것은 이렇게 실제 시각화를 ’수행’하는 과정과 반대 방향의 ’설계’가 꼭 미리 이루어져야 한다는 것입니다. 이 과정이 이루어지면 결과적으로 시행착오가 줄여 총 분석 시간을 절약할 수 있고, 문제가 발생했을 때 쉽게 수정도 가능하며, 무엇보다 이 설계 과정을 분석을 함께 (또는 대신) 해줄 동료와 공유할 수 있습니다."
  },
  {
    "objectID": "retrieval.html#web의-구조와-웹api의-기초",
    "href": "retrieval.html#web의-구조와-웹api의-기초",
    "title": "10  데이터 수집하기",
    "section": "10.1 Web의 구조와 웹API의 기초",
    "text": "10.1 Web의 구조와 웹API의 기초\n스크래이핑과 크롤링에 대해서는 간단하게만 언급한다고 하니 실망하는 분도 있겠지만, 사실 API를 통해 공개되어 있는 데이터만 이용할 수 있어도 이전에는 접근할 수 없었던 굉장히 방대한 양의 데이터에 접근하게 되는 것입니다. 아마도 최근 굉장히 많은 사적, 공적 정보들이 웹API라는 것을 통해서 공유된다는 이야기는 들어본 분도 있을 것입니다. 웹API가 무엇인지를 이야기함에 앞서, 도대체 왜 더 많은 데이터들이 웹API를 통해 공개되는 것일까요?\n기업이나 공공기관이 자신이 보유한 데이터를 공유하는 이유는 적극적인 측면과 수동적인 측면으로 나누어 설명해 볼 수 있습니다. 적극적인 이유는 데이터를 공유함으로써 자신이 운영하고 있는 플랫폼에 더 많은 사람들을 참여시키는 것이 스스로의 이익과 부합하는 경우이지요. 투명한 정보 공개를 통해 행정에 대한 시민들의 참여를 늘리려고 하는 공공기관이 그런 경우 중 하나라고 할 수 있죠. 이렇게 투명한 행정은 정부가 스스로 원하는 경우도 있지만, 시민사회가 적극적으로 요구하는 경우가 늘어나고 있습니다. 기업의 경우에는 다른 기업이 자신이 보유한 플랫폼 위에서 플랫폼 이용자를 대상으로 다른 기업이 사업을 하도록 하고 싶은 경우가 그렇습니다. 페이스북, 유튜브와 같은 소셜 미디어를 생각해보면 알 수 있지요. 이러한 기업들은 이용자에 대해 알아낸 정보를 일부 광고주들에게 제공하면, 광고주들은 그덕분에 개별 이용자들에게 맞춤형 광고를 전달할 수 있습니다. 물론 그 댓가로 소셜미디어 기업들은 서비스의 품질을 올리고, 결과적으로 더 많은 이용자들을 끌어들일 수 있겠지요. 즉, 플랫폼 기업, 광고주, 이용자 간의 윈-윈을 통해 전체 비즈니스 생태계를 크게 만들려는 전략입니다.\n물론, 웹API를 제공하지 않아도 특정 온라인 기업이 보유한 정보가 매우 매력적이라면, 개별 이용자나 다른 기업들이 해당 서비스에서 정보를 빼가기 위해 많은 노력을 하겠지요? 아마도 웹스크레이핑, 크롤링 등의 수단을 동원할 것입니다. 만약 많은 사람들이 무질서하게 정보를 가져가기 위한 노력을 하게 된다면 어떻게 될까요? 너무 많은 접속이 발생해 서비스가 느려지거나, 심지어 멈춰버릴 수도 있겠지요. 유명 가수의 콘서트 예약을 위해 많은 사람들이 한번에 접속하는 경우를 생각해 보세요. 또, 다른 개인 또는 기업과 공유하고 싶지 않은 정보를 무질서하게 가져가려 하는 경우도 발생하겠지요. 따라서 기업들은 기왕 자신의 정보를 공유할 것이라면, 자신들이 정해놓은 통로와 규칙에 따라, 서비스 질의 저하를 피하면서 공유하고 싶은 정보만 공유하는 전략을 취할 유인이 있습니다. 이것이 웹API를 통해 정보를 공유하는 수동적인 이유입니다.\n그런데 애초에 API는 무엇일까요? 사실 여기서 이야기 하는 API는 웹API 입니다. 사실 API라 하면 소프트웨어와 다른 소프트웨어가 정보를 주고받을 수 있는 통로를 모두 포괄해서 이야기 하는 것이거든요. ’웹API’라고 하면 인터넷을 통해 서비스를 제공하는 소프트웨어(예컨대 인스타그램과 같은 소셜미디어)가 사람이 아닌 외부 소프트웨어에게 정보를 주는 규칙을 의미합니다. 사람에게 정보를 주는 화면을 UI(유저 인터페이스)라고 한다면, API는 소프트웨어에게 정보를 주는 방식이지요.\n\n\n\nUI v. API\n\n\n그런데 웹API는 너무도 자주 사용하기 때문에, 그 방식이 어느정도 표준화되어 있습니다. 때문에, 웹스크레이핑, 크롤링과 달리 그 표준을 사용하는데 필요한 몇가지 지식과 기술을 가지고 있으면 API를 통해 정보를 얻을 수 있는 것이지요. 이 표준을 이해/이용하는데 필요한 기술은 HTTP라는 통신 규약, 그리고 XML, JSON이라는 테이블과는 다른 데이터 형식이 전부입니다."
  },
  {
    "objectID": "retrieval.html#api-처음-경험하기-data.go.kr",
    "href": "retrieval.html#api-처음-경험하기-data.go.kr",
    "title": "10  데이터 수집하기",
    "section": "10.2 API 처음 경험하기: data.go.kr",
    "text": "10.2 API 처음 경험하기: data.go.kr\n이 교재에서는 대한민국 정부가 운용하는 공공데이터포털에서 제공하는 API를 사용할 것입니다. 공공데이터 포털은 관련 법령에 따라 국가행정기관에서 생성 및 관리하고 있는 데이터를 총 망라하여 파일 형태, 또는 API 형태로 제공합니다. 여기서 제공하는 데이터들은 그야말로 정책 입안을 위한 참고자료로 삼기위해 이루어진 조사 결과를 제공하는 통계청 국가통계포털과 성격이 다소 다릅니다. 통계청은 ‘한국노동패널조사’, ’사회통합실태조사’와 같은 국가 단위의 조사 결과를 공유한다면, 공공데이터포털에서 제공되는 데이터들은 실시간 대기 오염 정보, 아파트 실거래가 정보등, 조사를 위한 노력을 하지 않아도 저절로 만들어지는 데이터들 역시 포함합니다.\n앞으로의 실습을 위해 먼저 공공데이터포털에 회원가입을 하시길 바랍니다. 그래야 API를 이용하기 위한 자격을 얻을 수 있습니다. 로그인 후, 첫 화면에서 ’한국환경공단_에어코리아_대기오염정보’라는 검색어로 검색을 해 보도록 합니다.\n\n\n\n검색 결과\n\n\n여기서 오픈API 항목 가장 위에 보이는 ’한국환경공단_에어코리아_대기오염정보’를 클릭 합니다.\n\n\n\n클릭 결과\n\n\n이제 ‘활용신청’을 클릭하면 다음과 같은 화면이 나옵니다. ’활용목적’ 부분을 적당히 기입하고, 라이선스에 동의한 후, 활용신청을 해 주세요. 그러면, ’활용신청 현황’이라는 화면이 뜨면서, 지금까지 여러분이 이용 신청을 한 API 목록이 나타납니다. 이 화면은 사실 주메뉴(화면 최상단)으로부터 ’마이페이지-&gt; 데이터활용-&gt; Open API -&gt; 활용신청 현황’을 차례로 클릭해서 볼 수도 있습니다.\n\n\n\n활용신청 현황 화면\n\n\n어떤 경우에는 이용 승인에 시간이 걸리는 경우도 있지만, 많은 경우 바로 승인이 되어 API 이름 앞에 ’[승인]’이라고 표시되어 있습니다. 만약 승인이 되었다면, 방금 신청한 API를 클릭해보세요. 그러면 다음과 같은 화면이 나타납니다.\n\n\n\n계발계정 상세보기 화면\n\n\n호 여기에는 해당 API와 관련된 여러 정보들이 설명되어 있지만, 가장 중요한 것은 ‘End Point’라고 표시되어 있는 API 주소와, 비밀번호에 해당하는 ’일반 인증키’ (Encoding버전, Decoding 버전 중 무엇을 쓰든 큰 상관이 없습니다) 입니다. 이 두 정보를 메모장 같은 곳에 잘 옮겨두세요. 그 다음, ‘데이터명’ 항목 옆에 있는 ’상세설명’을 클릭합니다. 그러면 다음과 같은 화면이 나타납니다.\n\n\n\nAPI 상세설명 화면\n\n\n여기에는 API를 이용하는데 필요한 규칙이 대략적으로 기술되어 있습니다. 정확한 정보는 ‘참고문서’ 항목에서 다운받을 수 있는 메뉴얼에 자세하게 기술되어 있습니다. 시험삼아 한 번 열어 보세요. 처음에는 복잡해 보일지 몰라도, 정부에서 표준화한 형식을 따르고 있는 문서이기 때문에, 몇 번의 연습을 통해 익숙해지고 나면 다른 API를 이용할 때에도 이용법을 쉽게 이해할 수 있게 됩니다.\n자, 이제 공공데이터포털에서 제공하는 API를 통해 데이터를 다운받을 준비가 끝났습니다. 이제 다시 R로 돌아가서 실제로 데이터를 다운받아 보도록 하겠습니다."
  },
  {
    "objectID": "retrieval.html#r을-이용해-api-이용하기---다운로드",
    "href": "retrieval.html#r을-이용해-api-이용하기---다운로드",
    "title": "10  데이터 수집하기",
    "section": "10.3 R을 이용해 API 이용하기 - 다운로드",
    "text": "10.3 R을 이용해 API 이용하기 - 다운로드\n여기서는 httr, jsonlite, xml2라는 패키지를 이용하게 될 것입니다. 앞서 API를 이용하기 위해서는 HTTP라는 웹 통신 규칙, JSON, XML이라는 데이터 형식을 이해하면 된다고 했지요? 이 3개의 패키지는 각각 HTTP, JSON, XML을 R에서 다루기 위한 기능을 제공합니다. 이러한 패키지들에 대해 처음 들어보신다면, 설치가 되어있지 않을 것이므로, 다음 코드를 통해 설치를 완료해주세요.\n\ninstall.packages(c(\"httr\",\"jsonlite\",\"xml2\"))\n\nHTTP(Hyptertext Transfer Protocol)는 웹페이지에 대한 정보를 담고 있는 서버 컴퓨터와 이용자의 컴퓨터 사이에 정보를 교환하기 위한 규칙으로, 여러분들이 웹브라우저에서 ‘HTTP’ 또는 ’HTTPS’로 시작되는 웹페이지 주소를 사용할 때 늘 사용하고 있는 규칙입니다. 표준적인 웹API는 소프트웨어 사이에 정보를 주고받는데 바로 이 HTTP를 사용하기 때문에, R에서 웹API를 사용하려면 R이 브라우저 처럼 HTTP를 이용해 외부 컴퓨터와 정보를 주고 받게 해 주는 패키지, 즉, httr을 이용해야 하는 것입니다.\n여느 패키지를 이용할 때처럼, 해당 패키지를 불러오도록 합시다.\n\nlibrary(tidyverse)\nlibrary(httr)\n\nHTTP가 작동하는 방식은 간단합니다. 서버 컴퓨터에게 규칙에 따라 특정 정보를 달라고 ’요청’하면, 서버가 이용자가 해당 정보를 볼 권한이 있는지, 요청한 정보가 있는지 확인한 후 그에 ’응답’합니다. 이러한 통신을 위해서는 다음 세 가지 정보가 필요합니다.\n\n요청 메시지를 보낼 웹API의 주소\n요청 권한이 있다는 것을 나타내는 인증키\n원하는 정보를 서버가 정한 방식에 따라 요청하는 규칙\n\n이 정보들은 모두 공공데이터포털 또는 앞서 내려받았던 메뉴얼에 나와 있습니다. 차례차례 보도록 하지요.\n첫째, 요청에 필요한 주소는 내려받은 메뉴얼 문서를 참조하는 것이 좋습니다. 공공데이터포털의 오픈API 상세정보 화면에도 ‘요청주소’, ‘서비스URL’ 등 관련 주소가 있지만, 어떤 경우에는 이 주소들이 여러분이 원하는 정보를 요청할 수 있는 주소가 아닌 경우가 있습니다. 그것은 하나의 API가 여러 가지 정보를 주는 경우, 정보의 종류에 따라 조금씩 다른 주소를 사용하기도 하기 때문이죠. 우리가 이용하려는 ‘에어코리아 대기오염정보’ API가 그런 경우입니다. 메뉴얼 문서를 포함하고 있는 압축 파일을 열어보면, 이 API는 ‘대기오염정보’, ‘대기오염통계 현황’, ‘미세먼지 경보 발령 현황’ 등등 여러 종류의 정보를 제공하고 있습니다. 여기서는 그 중 ’대기오염정보’를 이용해볼 것입니다.\n‘대기오염정보’를 이용하기 위해서는 해당 메뉴얼을 읽어보아야겠지요. 그러니 압축 파일에 포함된 문서 중, ’한국환경공단_에어코리아_대기오염정보_기술문서_v1.1.docx’파일을 열어봅니다. 스크롤해 내려가다보면, ’대기오염정보 조회 서비스’ 아래 표에 ’Call Back URL’이라는 항목이 있습니다. 주소가 http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty로 되어 있네요. 이 주소가 바로 우리가 정보 요청을 위해 사용할 주소 입니다.\n\n\n\nCall Back URL\n\n\n둘째, 앞서 ‘에어코리아 대기오염정보’ 이용 승인을 받으면서 개발계정 상세정보에 인증키가 발급되어 있는 것을 확인했습니다.\n\n\n\n인증키\n\n\n곧 HTTP를 이용해 API 서버에 정보 요청을 할 때, 정보 요청에 대한 권한을 승인받기 위해 이 인증키를 함께 보낼 것입니다.\n셋째, 어떻게 정보를 요청하는데 대한 규칙을 알기 위해서는 다시 메뉴얼로 돌아가야 합니다. 앞서 확인한 ‘Call Back URL’ 바로 아래에 있는 표에 ’요청 메시지 명세’라는 표가 있는데요, 여기서 정보 요청의 규칙을 알 수 있습니다.\n\n\n\n요청 메시지 명세\n\n\n위의 예시에서 보면, 정보를 요청할 때, ‘serviceKey’라는 항목에는 나의 인증키를, ’returnType’이라는 항목에는 json과 xml 중 어떤 데이터 형식으로 정보를 받고 싶은지를, ’numOfRows’라는 항목에는 한 번 요청할 때마다 몇개의 정보를 받고 싶은지를, ’pageNo’ 항목에는 전체 정보 중 몇 번째 페이지에 해당하는 정보를 받고 싶은지를, ’stationName’에는 어느 대기오염 측정소의 정보를 얻고 싶은지를, ’dateTerm’에는 얼마나 긴 기간 동안의 대기오염 정보를 얻고 싶은지를, 마지막으로 지금 당장은 중요하지 않지만 ’ver’에는 제공하는 API의 몇가지 버전 중 어느 것을 이용하고 싶은지를 기입해서 HTTP 메시지로 보내면 된다고 합니다.\n사실 모든 항목에 대응하는 메시지를 보내야 하는 것은 아닙니다. serviceKey의 경우에는 내가 권한을 가지고 있다는 것을 밝히기 위해서 꼭 기입해야 하지만, 다른 항목들 중 ’항목구분’이 0이라고 표시되어 있는 경우, 아무 메시지도 보내지 않으면 ’샘플데이터’라는 칼럼에 나와있는 값들이 일종의 디폴트 값으로 가정됩니다. 즉, 이용자가 페이지번호를 넣지 않으면 자동으로 1페이지 정보가 돌아오는 식이지요.\n자, 이제 서버에 정보를 요청하기 위한 모든 정보를 알게되었습니다. 이제 R을 이용해 질문만 하면 됩니다. 가장 간단하게 종로구 측정소의 지난 한 달간 대기오염 정보를 원한다고 해 볼까요? 이를 httr 패키지로 요청하면 다음과 같이 됩니다.\n\nres &lt;- GET(url=\"http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty\",\n           query=list(returnType=\"json\",\n                      stationName=\"종로구\",\n                      dataTerm=\"MONTH\",\n                      serviceKey=\"LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq/ea2CQUTUuisLvxlxaGm0YTp4f+89FfhplvwiQIe0cngpybTkdDHQ==\"))\nres\n\nResponse [http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty?returnType=json&stationName=%3CU%2BC885%3E%3CU%2BB85C%3E%3CU%2BAD6C%3E&dataTerm=MONTH&serviceKey=LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq%2Fea2CQUTUuisLvxlxaGm0YTp4f%2B89FfhplvwiQIe0cngpybTkdDHQ%3D%3D]\n  Date: 2023-09-02 05:08\n  Status: 200\n  Content-Type: application/json;charset=UTF-8\n  Size: 130 B\n\n\n출력된 결과값 메시지 중 “Status: 200”이라는 표현이 있으면 일단 성공했다고 보아도 좋습니다. 웹API 서버는 종종 네트워크 상태에 따라 반응을 하지 않는 경우도 있으니, 에러 메시지가 보인다고 해서 포기하지 말고 여러 번 시도해 보세요.\n정보를 요청하는 위의 코드 그 자체는 그 동안의 설명을 이해했다면 어렵지 않게 이해할 수 있을 것입니다. 먼저 GET() 함수(모두 대문자로 써야 합니다)는 httr 패키지가 제공하는 HTTP 규칙을 이용해 정보 요청을 하기 위한 함수입니다. 앞서 알아낸 서버주소는 GET()함수의 url이라는 인수의 값으로 기입할 수 있습니다. 이제 서버에게 요청할 구체적인 질문은 query라는 인수에 값으로 기입합니다. 단, 이 때는 기입해야 하는 정보가 returnType, stationName, dataTerm, serviceKey 등 여러개 이므로, 이를 list로 묶어서 기입합니다. 아래에서부터 앞서 알아낸 인증키, 그리고 ‘종로구’ 측정소의 ‘한달’ 간 정보를 원한다는 메시지, 그리고 마지막으로 ’json’이라는 데이터 형태로 정보를 보내달라는 요청 내용까지 포함된 것입니다.\n이제 res라는 변수에 서버가 보낸 정보가 포함되어 있다는 것은 알지만, 이를 우리가 쓸 수 있는 데이터로 변환하는데에는 몇 가지 작업이 필요합니다. 효율적으로 정보를 주고 받기 위해 기계만 이해할 수 있는 형식을 이용하기 때문이죠. 따라서, 최종 분석을 위해서는 다음과 같은 변환 작업이 필요합니다.\n\n\n\nAPI로부터 받은 데이터 변환\n\n\n첫번째 변환을 제공하는 함수는 httr 패키지의 content() 함수입니다. 이 함수는 기계가 이해할 수 있느 언어를 사람도 이해할 수 있는 언어로 변환해 줍니다.\n\ndtString &lt;- content(res, \"text\", encoding=\"UTF-8\")\ndtString\n\n[1] \"{\\\"response\\\":{\\\"body\\\":{\\\"totalCount\\\":0,\\\"items\\\":[],\\\"pageNo\\\":1,\\\"numOfRows\\\":10},\\\"header\\\":{\\\"resultMsg\\\":\\\"NORMAL_CODE\\\",\\\"resultCode\\\":\\\"00\\\"}}}\"\n\n\n여기서 “text”는 사람의 언어로 바꾸어 달라는 뜻이고, encoding=\"UTF-8\"은 기계 언어와 사람 언어 사이의 번역 규칙이라고 생각하면 될 것입니다. “UTF-8”는 일반적으로 (들어본 분도 있을 것입니다) “유니코드”라고 부르는 규칙으로, 현대 인터넷의 표준 규칙쯤 됩니다.\n출력된 결과는 아직, 알듯, 모를듯 하지요? 이는 사람의 언어로 변환은 되었지만, R이 아직, 이 문자열이 json이라는 특정 형식을 갖는 데이터라는 것을 모르고, 그냥 한 줄로 된 긴 문자열이라고 생각하기 때문입니다. R이 이 문자열을 json 데이터로 이해하기 위해서는 우리가 그 사실을 알려주어야 합니다. 말하자면, ‘네가 지금 보고 있는 문자열이 json 데이터라고 생각하고 다시 한 번 잘 봐봐’ 라고 명령을 내려주는 것이지요.\n그러면 json은 어떤 형식의 파일이길래, 편한 테이블 형태의 데이터 형식을 제쳐두고 이를 사용하는 것일까요? 먼저 우리에게 익숙한 테이블 형태의 데이터를 생각해 보면, 우리는 데이터를 테이블로 표현하기 위해서는 열과 행으로 이루어진 2차원 평면 상의 한 칸 한 칸에 값을 집어 넣습니다.\n\n\n\n테이블 데이터\n\n\n반면에 json은 아주 간단한 나무(tree) 헝태의 데이터 구조 입니다. 즉, 테이블로는 표현 불가능한 값 간의 위계질서, 또는 데이터의 ’깊이’를 표현할 수 있는 것이지요. 방금 받은 데이터를 json이라고 생각하고 표현하면 다음과 같습니다.\n\n\n\nJSON 데이터\n\n\n이제 R에게 문자열을 json으로 이해해 보라고 말하기 위해서는 jsonlite 패키지의 fromJSON()이라는 함수를 사용할 것입니다.\n\nlibrary(jsonlite)\n\nWarning: package 'jsonlite' was built under R version 4.1.3\n\n\n\nAttaching package: 'jsonlite'\n\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\ndtJSON &lt;- fromJSON(dtString)\ndtJSON\n\n$response\n$response$body\n$response$body$totalCount\n[1] 0\n\n$response$body$items\nlist()\n\n$response$body$pageNo\n[1] 1\n\n$response$body$numOfRows\n[1] 10\n\n\n$response$header\n$response$header$resultMsg\n[1] \"NORMAL_CODE\"\n\n$response$header$resultCode\n[1] \"00\"\n\n\n이제 R은 dtJSON이 json 형태의 데이터였다는 것을 이해하고, 이를 스스로 다룰 수 있는 형태로 변환했습니다. 사실 json은 인터넷 통신을 위해 주로 사용하는 데이터 형식이지, R 고유의 형식은 아닙니다. 그런데, R에는 json은 아니지만, json과 같이 나무 형태의 데이터 구조를 처리할 수 있는 데이터 형식이 있습니다. 그것은 바로 list이지ㅛ. 따라서, fromJSON() 함수는 주어진 json데이터의 구조를 이해하면 이를 바로 R의 list 형식으로 변환합니다. 이제 Rstudio의 오른쪽 ‘Envrionment’ 상태창에 있는 dtJSON 항목을 클릭해보면 다음과 같은 화면이 나타날 것입니다.\n\n\n\nlist로 표현된 JSON 데이터\n\n\n\nstr(dtJSON)\n\nList of 1\n $ response:List of 2\n  ..$ body  :List of 4\n  .. ..$ totalCount: int 0\n  .. ..$ items     : list()\n  .. ..$ pageNo    : int 1\n  .. ..$ numOfRows : int 10\n  ..$ header:List of 2\n  .. ..$ resultMsg : chr \"NORMAL_CODE\"\n  .. ..$ resultCode: chr \"00\"\n\n\n여기서 보이는 데이터 구조를 그림으로 그리면, 다음과 같이 나무 가지와 같은 형태가 됩니다.\n\n\n\n가지형태의 데이터 구조\n\n\n웹API가 우리에게 익숙한 테이블 형태의 데이터를 이용하지 않고, json과 같이 생소한 데이터 타입을 이용하는 이유는 바로 이와 같은 가지치기 구조가 통신에는 더욱 편리한 경우가 많기 때문입니다.\n위의 그림에서 또 한 가지 알 수 있는 것은 우리가 정말 필요로 하는 테이블(즉 ‘data.frame’)은 ’dtJSON-response-body-items’에 숨어 있다는 것입니다. R은 json 형식의 파일을 이미 R 고유의 list 형식으로 변환했으니, 우리가 앞서 list의 서브세팅에서 배웠듯이 다음과 같은 명령문을 이용해 이 테이블에 접근할 수 있습니다.\n\ndf &lt;- dtJSON$response$body$items\ndf\n\nlist()\n\n\n드디어 우리가 원하는 테이블을 얻을 수 있었습니다!"
  },
  {
    "objectID": "retrieval.html#xml-데이터의-요청-및-처리-고급급",
    "href": "retrieval.html#xml-데이터의-요청-및-처리-고급급",
    "title": "10  데이터 수집하기",
    "section": "10.4 XML 데이터의 요청 및 처리 (고급급)",
    "text": "10.4 XML 데이터의 요청 및 처리 (고급급)\n이번에는 json이 아니라, XML 형태의 데이터를 API로부터 받았을 경우에 대해서 살펴보겠습니다. XML도 json처럼 나무 형태에 데이터를 표현하기 위한 구조이지만, 표현하는 방법이 조금 더 복잡하고, 테이블 형태로 변환하는 법도 조금 더 복잡합니다. 하지만, 어떤 API는 데이터를 XML 형태로만 제공하는 경우도 있으니, 살펴보고 넘어가도록 하지요. XML이 json과 어떻게 다른지는 곧 보게될 예를 통해 쉽게 이해할 수 있을 것입니다.\n먼저 XML데이터를 R에서 쉽게 다루기 위해서는 다음 두 패키지를 이용하는 것이 좋습니다.\n\nlibrary(xml2)\n\nWarning: package 'xml2' was built under R version 4.1.3\n\nlibrary(purrr)\n\n이제 앞서 사용한 것과 동일한 대기오염 데이터를 GET() 함수를 이용해 받아보겠습니다. 모든 것이 똑같지만, returnType에 투입된 인수가 ’json’이 아니라 ’xml’이라는 것만 다르다는 것을 알 수 있습니다. 이 때문에 이제 API는 데이터를 XML형태로 보내주게 되지요.\n\nres &lt;- GET(url=\"http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty\",\n           query=list(returnType=\"xml\",\n                      stationName=\"종로구\",\n                      dataTerm=\"MONTH\",\n                      serviceKey=\"LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq/ea2CQUTUuisLvxlxaGm0YTp4f+89FfhplvwiQIe0cngpybTkdDHQ==\"))\nres\n\nResponse [http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMsrstnAcctoRltmMesureDnsty?returnType=xml&stationName=%3CU%2BC885%3E%3CU%2BB85C%3E%3CU%2BAD6C%3E&dataTerm=MONTH&serviceKey=LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq%2Fea2CQUTUuisLvxlxaGm0YTp4f%2B89FfhplvwiQIe0cngpybTkdDHQ%3D%3D]\n  Date: 2023-09-02 05:08\n  Status: 200\n  Content-Type: application/xml;charset=UTF-8\n  Size: 272 B\n&lt;BINARY BODY&gt;\n\n\n앞서의 경우와 마찬가지로, 결과에 포함된 Status Code가 200이면 정상적으로 데이터가 도착한 것입니다. 그런 다음, 도착한 데이터를 사람이 읽을 수 있는 문자열로 변환하는 과정도 동일합니다.\n\ndtXMLstring &lt;- content(res, \"text\", encoding=\"UTF-8\")\ndtXMLstring\n\n[1] \"&lt;?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?&gt;\\r\\n&lt;response&gt;\\n  &lt;header&gt;\\n    &lt;resultCode&gt;00&lt;/resultCode&gt;\\n    &lt;resultMsg&gt;NORMAL_CODE&lt;/resultMsg&gt;\\n  &lt;/header&gt;\\n  &lt;body&gt;\\n    &lt;items/&gt;\\n    &lt;numOfRows&gt;10&lt;/numOfRows&gt;\\n    &lt;pageNo&gt;1&lt;/pageNo&gt;\\n    &lt;totalCount&gt;0&lt;/totalCount&gt;\\n  &lt;/body&gt;\\n&lt;/response&gt;\"\n\n\n그런데 결과물이 더 복잡하게 생겼지요? 아직 R은 이 문자열이 XML 데이터라는 것을 알기 전인데, 우리는 XML 데이터라는 것을 알고 있으니, 이를 미리 그림으로 표현해 보면 다음과 같습니다.\n\n\n\nXML 데이터\n\n\nXML이 복잡해 보이는 이유는 json과 달리, 변수 정보를 표현하는 형식이 값의 앞 뒤에 붙어있다는 것입니다. 이게 무슨 말인가 하면, 다음 그림과 같이 json은 값 앞에 한 번 변수 이름을 표시해 주지만, XML의 경우에는 값 뒤에도 변수 이름을 표시해 준다는 것입니다.\n\n\n\nJSON과 XML 형식 비교\n\n\n그 외에는 XML도 json처럼 나무 형식의 데이터를 표현하는 하나의 방식에 줄과합니다. 이제 json에 대해서 그랬던 것처럼, R에게 방금 본 문자열이 사실은 XML이었다고 말해줄 차례입니다. 이렇게 말해주기 위한 xml2 패키지의 함수는 read_xml 입니다.\n\ndtXML &lt;- dtXMLstring |&gt;\n    read_xml() |&gt;\n    as_list() \n\n그런데 read_xml() 뒤에 as_list()라는 다른 함수가 쓰였죠? 이는 read_xml() 함수가 jsonlite의 fromJSON() 함수와 달리 XML 데이터를 바로 R의 list 데이터로 변환하지 않기 때문입니다. list로 변환하지 않고 데이터를 다루는 방법도 있지만, 이는 다소 까다롭기 때문에 역시 xml2 패키지에 포함된 함수인 as_list() 함수를 이용해 list로 변환까지 하기로 하겠습니다.\n이제 Rstudio 화면 우측 상단에 있는 ‘Environment’ 창에서 dtXML을 클릭하여 데이터 구조를 보도록 합시다.\n\n\n\ndtXML\n\n\n우리가 원하는 대기 오염 대이터는 ‘response’ 아래 ‘body’ 아래 ‘items’ 아래 열개의 ’item’으로 표현되어 있다는 것을 알 수 있습니다. 그리고 각각의 item은 또 다시 다음과 같은 나무 형태이지요.\n\n\n\n나무형태의 XML 데이터\n\n\n우리가 이를 테이블로 변환하려면, item 하나를 테이블을 한 행(row)으로 item 안에 있는 각각의 값을 하나의 열(column)로 표현해야 합니다. 문제는 R이 반대의 경우, 즉, 각각의 item이 열이고, 그 안에 있는 요소들이 행인 상황에는 테이블로 만드는 것은 쉽게 하지만, 이 경우는 조금 에둘러가야 한다는 것입니다. 이를 해결하기 위해서는 여러 방법이 있지만, 제일 간단한 방법은 주어진 list의 구조를 반대로 먼저 만들어주는 것입니다. 즉, 다음과 같이 만들어 주는 것이지요.\n\n\n\nTranspose\n\n\n이를 위한 함수는 아까 불러온 purrr 패키지의 transpose() 함수 입니다.\n\ndtXML_transposed &lt;- dtXML$response$body$items |&gt;\n    transpose()\n\n이제 새로 만들어진 dtXML_transposed의 구조를 Environment 패널에서 확인해 보세요. 위의 그림처럼 바뀌어져 있을 것입니다. 그런다음 테이블로 바꾸어주면 됩니다.\n\ndfXML &lt;- dtXML$response$body$items |&gt;\n    transpose() |&gt;\n    as_tibble() |&gt; \n    unnest(cols=everything(), keep_empty = TRUE) \n\n그런데 transpose() 뒤에도 여전히 알쏭달쏭한 코드들이 붙어있지요? 그 이유는 ’transpose’한 후 테이블로 만들어 주어도 각각의 대기오염 측정치가 원 데이터의 구조상 단순한 값이 아니라, 값이 한 개 있는 작은 리스트로 변환되기 때문입니다. 비유해서 말하자면, 우리는 과일 하나하나가 필요한데, 과일과 과일이 메달린 가지 하나가 같이 왔다고 할 수 있습니다.\n 이런 문제를 다루기 위해 일반 데이터 프레임과 매우 비슷하지만 조금 더 유연한 기능을 가진 테이블 형식을 tidyverse가 제공하는데, 이를 tibble이라고 부릅니다. 데이터 프레임은 각 칸에 과일 하나만 넣을 수 있지만, tibble은 가지가 달린 과일로 넣을 수 있다고 생각해 보세요. 그래서 데이터 프레임으로 만들지 않고 as_tibble() 함수를 이용해 tibble로 만들었습니다. 해당 함수 역시 tidyverse 패키지에 속해있지요. 이제 이렇게 만들어진 tibble의 모든 칸에는 가지 끝에 달린 과일이 (즉, 각각의 값이 리스트 형태로) 들어있습니다.\n\n\n\nNested Tibble\n\n\n이제 모든 칸에서 가지를 떼주어야 합니다. 그래야 과일에 해당하는 값들을 사용할 수 있거든요. 이 작업은 tidyverse의 unnest() 함수를 통해 할 수 있습니다. 그 안의 인수는 다음과 같은 뜻 압니다.\n\ncols=everything(): 모든 열(column)을 unnest()할 것.\nkeep_empty=TRUE: 값이 없는 칸, 비어 있는대로 둘 것.\n\n이제 위의 코드를 실행하고, Envrionment 패널에서 dfXML을 클릭해보세요. 아까 json 데이터를 처리해서 보았던 것과 동일한 테이블을 획득했다는 것을 알 수 있습니다.\n보신 바와 같이 XML 파일은 그 후속 작업이 조금 복잡합니다. json 형태의 데이터를 받을 수 있다면 json을 선택하는 것이 아무래도 효율적이겠지요."
  },
  {
    "objectID": "retrieval.html#여러-페이지-변환-추후작성",
    "href": "retrieval.html#여러-페이지-변환-추후작성",
    "title": "10  데이터 수집하기",
    "section": "10.5 여러 페이지 변환 (추후작성)",
    "text": "10.5 여러 페이지 변환 (추후작성)\n아직 문제는 남았습니다. 앞서 API로부터 대기오염 데이터를 요청할 때 사용하지 않은 인수로 pageNO가 있었습니다. 이 인수는 데이터 전체 중 몇 페이지에 해당하는 데이터를 불러올 것인지를 확인하는 ### for 반복문 ### function ### 페이지 전환 만들기"
  },
  {
    "objectID": "retrieval.html#웹스크레이핑-기초-html-기초",
    "href": "retrieval.html#웹스크레이핑-기초-html-기초",
    "title": "10  데이터 수집하기",
    "section": "10.6 웹스크레이핑 기초: HTML 기초",
    "text": "10.6 웹스크레이핑 기초: HTML 기초\n앞서 이야기한 것처럼, 데이터를 보유한 측에서 따로 API를 제공하지 않는다면, 웹페이지로 부터 데이터를 직접 가져오는 방법을 생각해볼 수 있습니다. 물론 데이터의 양이 적다면, 브라우저에 표시된 테이블을 드레그 해서 복사-붙여넣기 하는 것도 방법이겠지만, 그렇게 손으로 작업하기에는 데이터의 양이 지나치게 많은 경우도 있지요. 이 때는 프로그래밍을 통해 복사-붙여넣기 작업을 컴퓨터가 자동으로 하도록 시키는 것을 고려해볼 수 있겠지요. 이를 웹스크레이핑이라고 합니다. 만약, 어디에 어떤 정보가 있는지를 자동으로 찾아가면서 동시에 복사-붙여넣기를 해야하는 더 고약한 작업은 웹크롤링이라고 부르지요. 스크레이핑과 크롤링은 API를 이용할 때와 달리 데이터 형태가 표준화되어 있지 않고, 해당 웹사이트가 어떻게 작동하는지를 거꾸로 역추적해야 하는 경우가 대부분이기 때문에, 여기서 다루기에는 상당히 방대한 양의 많은 지식과 기술을 필요로 합니다. 하지만, 비교적 간단한 형태의 웹사이트, 구체적으로 ’정적웹(Static Web)’이라고 부르는 웹사이트의 경우에는 R을 통해 간단한 스크레이핑 작업을 할 수 있습니다. 이 교재에서는 그러한 경우만 다루고, 그 이상을 위해서는 어떤 추가 지식이 필요한지만 짧게 언급하고 넘어가도록 하겠습니다.\nR에서 가장 간단하게 웹스크레이핑을 하는 방법은 rvest라는 패키지를 이용하는 것입니다. 먼저 패키지를 설치하도록 합시다.\n\ninstall.packages('rvest')\n\n패키지 사용을 위해서 물론 패키지를 로드해야겠지요.\n\nlibrary(rvest)\n\nWarning: package 'rvest' was built under R version 4.1.3\n\n\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\n간단한 예시를 위해 2023년 TV방영 드라마에 대한 정보를 찾는다고 해 보지요. 특히 드라마 작가, 연출자, 제작사 등의 정보 같은 경우에는 하나하나 조사를 하는 것보다 팬들이 모아놓은 정보가 상당히 충실한 경우가 많습니다(물론 정확성은 사후 검증해야 한다는 것은 두말 할 나위 없겠지요). 찾아보니 위키피디아에 2022년_대한민국의_텔레비전_드라마_목록이라는 항목이 있네요.\n\n\n\n위키피디아 페이지\n\n\n여기에 큰 테이블이 있으니, 이 정보를 복사해 오도록 R에게 지시하면 되겠습니다. 그런데, 스크레이핑을 위해서는 HTML 이라는 웹 문서 표준에 대한 기초적인 이해가 조금 필요합니다. 아마, 여러분들도 인터넷을 사용하시면서 HTML이라는 용어는 여러번 들어보셨을 것입니다. HTML은 HyperText Markup Language의 줄임말로, 웹페이지를 작성하는 문서 표준 입니다. HTML 규칙에 따라 문서를 작성하면 여러분이 사용하시는 크롬, 엣지 등의 웹브라우저가 이를 이해하고 여러분들에게 익숙한 알록달록한 웹페이지로 표현해서 보여주는 것이지요. 즉, 여러분이 웹브라우저 주소 창에 URL 주소를 치고 엔터를 누르면, 여러분의 컴퓨터(클라이언트라고도 부릅니다)와 웹사이트 서버가 정보를 주고 받는데, 이 때 서버가 보내는 정보가 바로 HTML 파일 이라고 생각하시면 되겠습니다. 그리고 여러분 컴퓨터의 브라우저가 이를 웹페이지로 번역해서 보여주는 것이고요.\n\n\n\n서버-클라이언트 구조\n\n\n위의 그림에서 보듯이 이렇게 웹서버와 클라이언트 간에 HTML을 주고 받을 때 사용하는 통신 규칙이 API를 사용하면서도 이야기했던 HTTP이고요.\n우리가 브라우저를 통해 보는 웹페이지는 화려하지만, 브라우저가 해석하기 전의 HTML 파일 자체는 특정 규칙을 따르는 문서 파일에 불과합니다. 웹스크레이핑은 이 규칙을 역이용해서 컴퓨터가 원하는 정보를 찾도록 하는 작업이라고 보아도 무방합니다. 그러면 가장 간다한 HTML 파일 형태를 볼까요?\n\n&lt;html&gt;\n    &lt;head&gt; &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt; 이것은 제목 입니다 &lt;/h1&gt;\n        &lt;p&gt; 이것은 문단 입니다 &lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n앞에서 본 xml 파일과 거의 동일한 형태를 가지고 있지요? 사실 xml과 html은 친척 관계라고 할 수 있습니다. html은 xml처럼 정보의 앞 뒤에 붙은 테그를 이용해서 텍스트에 추가적인 정보를 덧붙입니다.\n\n\n는 그 사이에 들어오는 텍스트가 문서의 본문에 해당함을,\n\n\n는 그 사이의 텍스트가 하나의 문단임을 표현하는 식이지요. HTML은 다양한 정보를 덧붙이기 위해서 여러가지 tag를 가지고 있습니다. 이를 잘 이용하면 컴퓨터에게 ‘이 HTML 문서에 있는 모든 제목을 복사해 줘’, 또는 ‘이 HTML 문서에 있는 모든 본문 문단을 복사해 줘’ 같은 요청을 할 수 있겠지요.\n드라마 목록 사례에서는 해당 문서에 있는 큰 표를 복사해 오면 되는데, HTML은 표를 나타내는\n\n\n\n테그가 있습니다. 물론 우리가 웹브라우저에서 해당 위키피디아 페이지를 보았을 때, 큰 표를 볼 수 있는 것은 브라우저가 HTML 문서의 테이블 테그를 이해하고 표로 해석해 주었기 때문이지요.\n\n\n\nHTML문서상의 테이블 부분\n\n\n그러면 우리는 R에게 ’이 HTML 문서에 있는 모든 테이블을 복사해 줘’라고 요청하면 되겠군요. rvest 패키지를 이용해 이런 요청을 할 때는 다음과 같이 하면 됩니다.\n\nurl &lt;- 'https://ko.wikipedia.org/wiki/2022%EB%85%84_%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%ED%85%94%EB%A0%88%EB%B9%84%EC%A0%84_%EB%93%9C%EB%9D%BC%EB%A7%88_%EB%AA%A9%EB%A1%9D'\n\ntables &lt;- url |&gt;\n    read_html() |&gt;\n    html_table() \n\nSys.setlocale(\"LC_ALL\", \"korean\")\n\n[1] \"LC_COLLATE=Korean_Korea.949;LC_CTYPE=Korean_Korea.949;LC_MONETARY=Korean_Korea.949;LC_NUMERIC=C;LC_TIME=Korean_Korea.949\"\n\nstr(tables)\n\nList of 3\n $ : tibble [1 x 1] (S3: tbl_df/tbl/data.frame)\n  ..$ 연도별 대한민국의 텔레비전 드라마 목록: chr \"…\\n2012\\n2013\\n2014\\n2015\\n2016\\n2017\\n20182019\\n2020\\n2021\\n2022\\n2023\\n2024\\n20252026\\n2027\\n2028\\n2029\\n2030\\n2031\\n2032\"\n $ : tibble [6 x 3] (S3: tbl_df/tbl/data.frame)\n  ..$ 구분: chr [1:6] \"면색\" \"면색\" \"면색\" \"극본 및 연출\" ...\n  ..$ 구분: chr [1:6] \"분홍색\" \"노란색\" \"회색\" \"극본 및 연출\" ...\n  ..$ 설명: chr [1:6] \"웹을 기반으로 한 텔레비전 드라마 편성 작품\" \"현재 방영중인 작품\" \"방영 예정 작품\" \"†는 전체 회차에 참여하지 않고 중간 투입이나 하차 등을 표시함.\" ...\n $ : tibble [85 x 11] (S3: tbl_df/tbl/data.frame)\n  ..$ 작품명              : chr [1:85] \"《고스트 닥터》\" \"《마녀식당으로 오세요》\" \"《트레이서》\" \"《악의 마음을 읽는 자들》\" ...\n  ..$ 극본                : chr [1:85] \"김선수\" \"이영숙\" \"김현정\" \"설이나\" ...\n  ..$ 연출                : chr [1:85] \"부성철김영환\" \"소재현이수현\" \"이승영백호민\" \"박보람김재홍\" ...\n  ..$ 방송 기간(시작/종영): chr [1:85] \"2022.01.032022.02.22\" \"2022.01.052022.01.19\" \"2022.01.072022.03.25\" \"2022.01.142022.03.12\" ...\n  ..$ 방송횟수            : chr [1:85] \"16\" \"5\" \"16 (32)\" \"16 (32)\" ...\n  ..$ 방송사(채널)        : chr [1:85] \"tvN\" \"tvN\" \"MBC\" \"SBS\" ...\n  ..$ 유형                : chr [1:85] \"월화\" \"수목\" \"금토\" \"금토\" ...\n  ..$ UHD                 : logi [1:85] NA NA NA NA NA NA ...\n  ..$ 방송여부            : chr [1:85] \"예\" \"예\" \"예\" \"예\" ...\n  ..$ 시청등급            : logi [1:85] NA NA NA NA NA NA ...\n  ..$ 비고                : chr [1:85] \"\" \"\" \"\" \"\" ...\n\n\n첫줄은 우리가 스크레이핑을 하려고 하는 URL의 주소 입니다. 실제로 저 주소를 웹브라우저 주소창에 치고 검색을 해 보면 다음과 같은 한글 주소라는 것을 알 수 있습니다.\nhttps://ko.wikipedia.org/wiki/2022년_대한민국의_텔레비전_드라마_목록\n그런데, 웹의 설계상 URL은 흔히 ASCII 부호라고 불리는 아주 기본적인 알파벳과 숫자, 아주 한정된 특수문자들로만 구성되도록 되어 있습니다. 하지만, 지금 우리가 사용하는 URL에서도 그렇듯, 최근에는 URL에 한글 또는 다른 문자를 자유롭게 활용하기도 하는데요, 이를 실제로 인터넷 통신에 활용할 때는 이를 ASCII 부호로 모두 변환해 주어야 하는 것이지요. 이를 ‘URL인코딩’ 이라고 하며, URL 인코딩은 통신에 적합한 알파벳 또는 숫자로 원래 문자를 바꾸어 주는 것이므로, 앞서 이야기 했던 문자를 컴퓨터가 저장할 수 있는 기계어로 바꾸어주는 인코딩과는 조금 다른 개념입니다. 아무튼, 위의 복잡한 URL은 그렇게 인코딩된 주소라고 생각하면 될 것입니다.\n그 다음, 해당 url을 rvest 패키지의 read_html() 함수에 집어넣으면, 해당 웹페이지를 웹브라우저가 개입하기 전에 원래 HTML 형태로 그대로 복사해 오게 됩니다. 복잡한 HTML 문서에서 테이블 부분 (즉,\n\n\n\n테그에 둘러싸인 부분)만을 가져오는 함수가 html_table()인 것입니다. 그 결과를 tables라는 변수에 저장시켰습니다.\n그 다음 Sys.setlocale(\"LC_ALL\", \"korean\")은 R의 문자 환경을 바꾸어 주는 옵션인데요, 웹에서 복사해 온 데이터가 한글로 되어 있음을 알려주는 것이라는 정도로 이해하면 좋겠습니다.\n위의 str(tables)의 결과를 보면 tables는 3개의 테이블로 구성된 리스트라는 것을 알 수 있습니다. 그것은 우리가 스크레이핑 하려고 했던 페이지에 사실은 테이블이 3개 있었기 때문입니다. 우리가 관심을 가지고 있는 큰 테이블 말고도, 아래에서 보는 것처럼, ‘일러두기’ 부분 역시 테이블로 되어 있습니다.\n\n\n\n일러두기 테이블\n\n\n우리가 스크레이핑 하려고 했던 테이블은 3번째 테이블로 저장이 되어 있으니, 다음과 같이 원하는 부분을 서브세팅 해 주면 최종 결과를 얻을 수 있습니다.\n\ndrama2023 &lt;- tables[[3]]\ndrama2023\n\n# A tibble: 85 x 11\n   작품명 극본  연출  `방송 기간(시작/종영)` 방송횟수 `방송사(채널)` 유형  UHD  \n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt; &lt;lgl&gt;\n 1 《고~  김선~ 부성~ 2022.01.032022.02.22   16       tvN            월화  NA   \n 2 《마~  이영~ 소재~ 2022.01.052022.01.19   5        tvN            수목  NA   \n 3 《트~  김현~ 이승~ 2022.01.072022.03.25   16 (32)  MBC            금토  NA   \n 4 《악~  설이~ 박보~ 2022.01.142022.03.12   16 (32)  SBS            금토  NA   \n 5 《술~  위소~ 김정~ 2022.02.032022.02.17   5        tvN            수목  NA   \n 6 《기~  선영  차영~ 2022.02.122022.04.03   16       JTBC           토일  NA   \n 7 《스~  권도~ 이희~ 2022.02.122022.04.03   16       tvN            토일  NA   \n 8 《서~  유영~ 김상~ 2022.02.162022.03.31   12       JTBC           수목  NA   \n 9 《스~  한희~ 이철  2022.02.232022.04.06   12       IHQ , MBN      수목  NA   \n10 《결~  임성~ 오상~ 2022.02.262022.05.01   16       TV조선         토일  NA   \n# i 75 more rows\n# i 3 more variables: 방송여부 &lt;chr&gt;, 시청등급 &lt;lgl&gt;, 비고 &lt;chr&gt;\n\n\n\n#Sys.setlocale(\"LC_ALL\", \"C\")\n#Sys.setlocale(\"LC_ALL\", \"english\")\n#Sys.setlocale(\"LC_ALL\", \"korean\")"
  },
  {
    "objectID": "retrieval.html#고급-스크레이핑을-위한-조언",
    "href": "retrieval.html#고급-스크레이핑을-위한-조언",
    "title": "10  데이터 수집하기",
    "section": "10.7 고급 스크레이핑을 위한 조언",
    "text": "10.7 고급 스크레이핑을 위한 조언\n사실 이렇게 간단한 작업을 위해서 스크레이핑까지 동원할 필요는 없습니다. 위의 예라면, 마우스로 원하는 표를 드래그 해서 엑셀에 붙여넣기를 할 수도 있을 테고, 최악의 경우 표에 있는 정보 하나하나를 손으로 옮겨 적는다고 해도 한 시간이 채 걸리지는 않을 것 같습니다. 하지만, 만약 위키피디아에 1960년대부터 이런 표가 한 해 당 하나씩 있고, 이를 모두 분석에 이용하고 싶다면 어떻게 해야 할까요? 각 페이지의 URL 주소만 알면 위의 작업을 반복해 주면 되겠지요. 이를 위해서 R 프로그램 뿐만 아니라, 모든 프로그래밍 언어의 근간이라고 할 수 있는 ’반복문’과 위의 코드를 섞어 써 주면 됩니다.\n원하는 정보가 테이블 형태로 되어 있지 않다면 어떻게 해야 할까요? 그 때는 HTML에 포함된 &lt;table&gt; &lt;/table&gt; 이외의 다양한 테그들을 선택해 주면 됩니다. 예컨대 ’해당 웹페이지에 있는 세 번째\n\n\n테그의 문장을 복사해줘’ 같은 구체적인 지시를 할 수 있습니다. 이를 위해서는 rvest의 html_node(), html_text() 함수와 함께 xpath 또는 CSS selector라는 다른 툴을 같이 써 주어야 합니다. 이들은 어디에 있는 어떤 테그를 원한다는 것을 말해주기 위해 필요한 언어라고 이해하시면 되겠습니다.\nrvest는 앞서 우리가 ’정적 웹(Static Web)’이라고 부른 상대적으로 단순한 구조의 웹페이지를 스크레이핑 하기 위한 도구입니다. 정적 웹에서는 URL 주소를 웹브라우저에 치면, HTTP 규약을 이용해 한 번 HTML 문서를 주고 받으면 다음 URL을 이용한 요청이 있을 때까지 통신이 이루어지지 않는다고 했지요? 하지만, 조금 더 복잡한 웹페이지는 웹페이지가 브라우저에서 표현되고 난 이후에도 통신이 완전히 끊기지 않습니다. 예컨대, 구글맵 같은 것을 사용할 때, 마우스 휠을 움직이면 지도의 크기가 변하지요? 이는 서버와 여러분의 브라우저 사이에 계속해서 여러분의 행동을 데이터로 주고 받고 있기 때문입니다. 이러한 웹페이지를 ’동적 웹(dynamic Web)’이라고 합니다.\n이렇게 동적 웹으로 디자인된 웹피이지에서 정보를 스크레이핑 할 때는 rvest의 기능으로 역부족인 경우가 상당히 많이 있습니다. 그 때에는 R이 웹브라우저의 힘을 빌려야 합니다. 구체적으로, R이 가상의 웹브라우저를 열어서 여러분이 직접 웹서치를 하는 것과 거의 동일한 행동을 모사하도록 해 주어야 합니다. 이 때 쓰는 라이브러리로 Selenium이라는 유명한 프로그램이 있습니다. 이 프로그램은 사실 R과 독립적으로 개발된 프로그램이기 때문에 R에서 사용할 수도 있지만 파이썬과 같은 다른 언어와 함께 사용할 수도 있습니다. 이 정도까지 오게 되면 상당힌 많은 기술을 필요로 하기 때문에, 여러분이 직접 모든 스크레이핑 과정을 디자인 하기 보다는 전문가와 협업을 하시는 것을 추천합니다.\n스크레이핑을 넘어서, 어디에 어떤 정보가 있는지부터 찾아내야 하는 경우, 즉 ’웹 크롤링’을 해야 하는 경우에는 Rcrawler라는 패키지를 활용할 수 있습니다. 하지만, 크롤링 같은 복잡한 작업을 하기 위해서는 R이 꼭 최적의 프로그램이라고 하기는 어렵습니다. 이 역시 전문가와 협업을 통해 접근하시기를 권합니다."
  },
  {
    "objectID": "story.html#인간의-세-가지-기억-시스템과-뉴스",
    "href": "story.html#인간의-세-가지-기억-시스템과-뉴스",
    "title": "11  데이터 스토리텔링",
    "section": "11.1 인간의 세 가지 기억 시스템과 뉴스",
    "text": "11.1 인간의 세 가지 기억 시스템과 뉴스\n`영상심리’라고 해서 무언가 대단한 이론을 이야기하고자 하는 것은 아닙니다. 여기서 이야기 할 것은 우리가 이미 상식으로, 또는 경험에서 알고 있는 것들을 확인하는 것이라고 보아도 무방합니다.\n앞서 이야기 한 것처럼, 사람은 새로 접한 정보를 처리하는데 대단히 한정적인 자원을 가지고 있습니다. 대신, 한정된 자원을 나름대로 효율적으로 활용하기 위한 방안도 마련하고 있다고 합니다. 그 중 하나가, 여러 단계의 기억 시스템 입니다. 심리학자들은 인간이 시각을 통해 받아들이고 기억하는 방식이 하나가 아니라 여러개라고 합니다. 이를 구분하는 방법 중 하나가 영상기억(iconic memory)-단기기억(short-term memory)-장기기억(long-term memory)의 3단계 구분법 입니다. 각각의 기억 방식은 인간의 시각정보 처리 과정에서 다른 기능을 하며, 하나의 정보에 대해 동시에 작동하기도, 그렇지 않기도 합니다.\n**그림: 영상기억(시선끌기) - 단기기억(읽는 도중 기억) - 장기기억(take away)\n영상기억은 ‘기억’이라는 용어와 어울리지 않게, 1초 또는 그 이하의 짧은 시간 동안 작동하는 기억 시스템입니다. 이는 빠르게 시각 정보의 개략적인 내용을 파악하고 거르기 위한 영상 정보의 ’입력’ 방식이라고 할 수도 있습니다. 어떤 사람들은 이런 영상기억이 진화의 산물이라고 하는데, 예컨대 야생 상황에서 천적이나 먹잇감을 빠르게 알아차리고 대응하기 위해 기능하는 영상 정보 처리 방식이라는 것입니다. 이를 시각화 과정에 결부시켜 보면, 독자가 대략적으로 정보를 훑는 와중에 ‘시선을 끄는’ 요소에 주목하게 되는 과정이라고 볼 수 있습니다. 영상기억이 작동하는 데에는 전주의적속성(preattentive attributes)이라는 우리 뇌 속에 미리 장착되어 있는 틀이 작동한다고 합니다. 이러한 틀들은 우리가 주의를 기울이지 않아도(‘전주의적’) 순식간에 알아차릴 수 있 수 있는 시각 요소들입니다.\n전주의적 속성에는 방향, 길이, 너비, 크기, 형태, 곡률, 표시추가, 둘러싸기, 색상, 색조, 위치 공간적 그룹핑 등이 있습니다. 우리는 이를 이용해서 독자가 바로 알아차리고 주목했으면 하는 영상 정보를 강조할 수 있는 것이지요. 즉, 주목을 원하는 정보를 강조하기 위해 전주의적 속성을 이용할 수 있습니다.\n\n\n\n전주의적 속성\n\n\nhttps://goingslowly.tistory.com/entry/%EB%8D%94-%EB%82%98%EC%9D%80-%EC%8B%9C%EA%B0%81%ED%99%94%EB%A5%BC-%EC%9C%84%ED%95%B4-%EC%95%8C%EC%95%84%EC%95%BC%ED%95%A0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94%EC%9D%98-%EC%A0%84%EC%A3%BC%EC%9D%98%EC%A0%81-%EC%86%8D%EC%84%B1\nTo-do’s: 전주의적 속성을 이용한 그래프 사례\n단기기억은 영상기억보다는 길지만 초 단위에 해당하는 아주 짧은 기억 방식 입니다. 말하자면, 여러분이 새로운 전화번호를 듣고 머릿속에 기억했다가 금방 잊어버리는 경우가 있지요? 그 때 사용하는 기억 방식을 단기기억이라고 보아도 좋습니다. 뉴스의 경우를 생각해 보면, 독자가 시각 정보를 보면서, 관련된 글을 읽을 때 중간중간 사용하게 되는 정도의 기억 방식 입니다. 글을 읽다가, 관련 그래프를 보고 해당 정보를 이해한 뒤 다시 글로 돌아와야 하는 경우가 있지요? 아마 그 과정은 30초 이내가 될 것입니다. 그 때 사용되는 기억 능력은 기껏해야 우리가 전화 번호를 외울 때 사용하는 그다지도 불완전한 능력에 불과하다는 것이지요. 단기 기억을 이용할 때 인간이 기억할 수 있는 영상 정보는 흔히 기껐해야 3-5개의 아이템 정도라고 합니다. 따라서, 독자가 보도 내용과 시각화 결과를 잘 연결하기를 바란다면(즉, 스토리텔링을 잘 하길 바란다면), 3-5개 이상의 시각 요소가 한 번에 담긴 화려한 시각화를 이용해서는 안 되겠지요. 따라서, 중요한 정보와 중요하지 않은 정보를 가려내고(즉, 정보의 위계를 잘 파악하고), 중요하지 않은 정보를 과감하게 생략하는 것이 중요합니다.\n장기기억은 훨씬 더 큰 용량을 가지고 오랫 동안 지속되는 기억 입니다. 문제는 단기 기억에 포함되었던 모든 정보가 장기 기억으로 전달되지 않는다는 것입니다. 어떤 심리학자들은 이렇게 단기기억이 장기기억으로 넘어가는 과정에서 일종의 인코딩이 일어난다고 합니다. 즉, 원정보를 그대로 기억하는 것이 아니라, 장기기억에 적합한 방식으로 변형한 다음에야 저장할 수 있다는 것이지요. 그렇게 장기 기억에 도움을 주는 인코딩 방식으로 흔히 이야기 하는 것이 바로 ‘이야기(story)’ 입니다. 즉, 논리적으로 구성된 정보의 체계는 인간이 오래 기억하기 어렵지만, 인간의 언어로 다시 되풀이된, 심지어 기승전결을 가진 이야기는 훨씬 더 기억하기 좋다는 것입니다. 예전에 방송에서 김영하 작가가 “이야기는 인간의 기억을 위해 만든 도구이다”라는 말을 한 적이 있는데 같은 맥락이라고 할 수 있겠네요.\n시각화를 위해 이것이 의미하는 바는 여러분이 시각화 자료를 최종적으로 완성함에 앞서 전달하고 싶은 이야기가 명료해야 한다는 것입니다. 여기서 명료하다는 것은 논리적이라는 의미라기 보다는 단순하고 직관적이어야 한다는 것입니다. 이를 위해 많은 전문가들은 시각화 또는 기사 작성에 앞서 전달하고 싶은 이야기를 하나의 문장으로 표현할 것을 권합니다. 이는 막상 해 보면 대단히 어려운 작업이기도 하고, 한 번에 달성하기 어려운 작업 이기도 합니다. 대부분의 경우, 전달하고 싶은 이야기를 한 문단으로, 그것을 다시 두 세 문장으로, 그런 다음 하나의 문장으로 줄이는 순차적인 과정을 필요로 하지요. 그런 다음 여러분의 시각화 자료로 돌아가서 다시 물어보야 합니다. 나의 시각화 결과물은 그 한 문장을 전달하고 있는가? 그 한 문장과 관련이 없는 필요 없는 정보를 지나치게 많이 전달하려고 있지 않은가?"
  },
  {
    "objectID": "story.html#정보-생략과-게슈탈트-심리학",
    "href": "story.html#정보-생략과-게슈탈트-심리학",
    "title": "11  데이터 스토리텔링",
    "section": "11.2 정보 생략과 게슈탈트 심리학",
    "text": "11.2 정보 생략과 게슈탈트 심리학\n지금까지 이야기한 데이터 스토리텔링의 원리를 한 마디로 요약하자면, 가장 중요한 정보를 제외한 부수적인 정보는 가능한 한 빼라는 것입니다. 독자의 집중력을 고려하면, 초점을 맞추어야 하는 것은 중요한 정보를 강조하는 것보다 중요하지 않은 정보를 빼는 것이라고 할 수도 있겠습니다.\n일단 정보를 빼는 것이 얼마나 시각화 결과물의 가독성을 높이는지 다음의 예를 통해 보도록 하겠습니다.\nTo-do’s: 사례 넣고 설명하기\n그런데 위의 예에서도 주요 메시지를 전달하는 시각 요소가 아니더라도, 완전히 생략할 수 없는 정보들이 있습니다. 예컨대 그래프의 X축과 Y축의 단위나 눈금 같은 것들이 그렇지요. 이런 시각 요소들은 놀랍게도 여전히 독자의 인지자원을 소비하기 때문에, 생략을 할 수 있다면 생략하는 것이 좋습니다. 그러나 너무 많은 생략은 독자들로 하여금 그래프를 이해할 수 없도록 만들 수도 있겠지요.\n그렇다면 얼마나 많은 정보를 생략해도 되는 것일까요? 이에 대한 정답은 없지만, 실제로 결정하는데 있어 가이드라인으로 자주 인용이 되는 게슈탈트(Gestalt) 심리학 이라는 이론이 있습니다. 게슈탈트 심리학은 현대에 발전한 많은 심리학 이론들이 그런 것처럼 인간 심리나 뇌 기능의 부분 부분에 주목하기 보다는 그러한 부분들이루는 조합 또는 구조가 인지를 가능하게 한다고 보는 하나의 사조라고 볼 수 있습니다. 하지만 UI/UX 디자인에서 이야기 하는 게슈탈트 심리학에서 발달한 영상심리학 관련 특정 결과들에 주목하는데요, 특히 게슈탈트 심리학이 이야기 하는 여러 심리 원리 중에 인지적 원리로서 창발성(emergence) 또는 구상화(Reification)가 중요합니다. 창발성 또는 구상화는 인간이 감각 기관, 예컨대 시각을 통해 감각한 정보 이외/이상의 것을 인지할 수 있는 것을 의미합니다. 즉, 직접적으로 보여주지 않아도 알게되는 것들이 있다는 것이지요.\n예컨대 이를 설명하는 여러 법칙 중에 ‘근접성의 법칙(Law of Proximity)’ 이라는 것이 있습니다. 아래의 예에서 자연스럽게 우리는 가로로 배열되어 있는 원들이 아니라 새로로 배열되어 있는 원들 사이에 어떤 가까운 관계가 있다고 여기게 됩니다. 이 그림은 관계를 시각 정보를 통해 직접적으로 표현하지 않았지만 우리는 근접성의 원리를 통해 자연스럽게 이를 인지하는 것이지요. 그렇다면, 그 관계를 설명하기 위해 일부로 세로줄을 그어서 관계를 표현해줄 필요가 없습니다. 독자는 그것 없이도 관계를 인지할 수 있는 데다가, 그러한 부가적인 시각 요소는 독자가 가진 한정적인 인지자원을 소모하게 만들기 때문입니다.\nhttps://kimhaksung.tistory.com/entry/gestalt\n유사하게 ‘유사성의 법칙(Law of Similarity)’, ‘연속성의 법칙(Law of Continuity)’ 같은 것들도 있습니다. 즉, 모양이 비슷한 것, 연속적으로 이어져 있는 것을 통해 인간의 관계를 자연스럽게 인식한다는 것입니다.\n\n\n\n유사성과 연속성\n\n\n‘폐쇄성의 법칙(Law of Closure)’ 같은 것도 흥미롭습니다. 아래의 예를 보면, 사람은 삼각형이 명확하게 그려져 있지 않아도 이중 삼각형 구조를 이해할 수 있습니다. 인간의 뇌가 완성되어 있지 않은 폐쇄 구조를 알아서 완성하기 때문이지요.\n\n\n\n폐쇄성\n\n\n이러한 게슈탈트 법칙을 어떤 사람들의 ‘형상 인지의 경제 법칙’이라고 표현하기도 합니다. 즉, 인간이 한정된 인지 자원과 정보를 가지고도 ’효율적으로’, 많은 인지자원을 쓰지 않고 형상을 인지할 수 있게 해 주는 시스템 같은 것을 가지고 있다는 이야기지요. 그렇다면, 우리는 인간이 자연스럽게 받아 들일 수 있는 형상의 인지 능력을 어느 정도 믿고, 그러한 능력을 보완해주기 위한 부가 정보는 과감하게 생략해도 좋겠지요. 이제 시각화에서 그러한 예를 한 번 보도록 하겠습니다.\n 아주 익숙한 예이지요? 여러분들이 마이크로소프트 엑셀 등을 이용해서 그래프를 생성하면 기본적으로 얻을 수 있는 모양의 그래프 입니다. 전달해야 할 모든 거의 모든 정보를 충실하게 전달하고 있는 이 그래프의 문제점은 무엇일까요? 아마도 예상하실테지만, 독자로 하여금 지나치게 많은 정보를 처리할 것을 요구하고 있다는 것입니다. 그렇다면, 어떤 정보가 ‘과도한’ 정보일까요? 가장 직관적으로는 추가적인 정보를 전달하지 않는 중복된 시각화 요소들을 지울 수 있습니다. 예컨대, 날짜를 표시할 때 반복되는 연도표시는 생략해도 좋습니다. 중요하지 않아보이지만, 독자는 이런 사소한 정보를 처리하기 위해서도 두뇌의 자원을 소비합니다. 또, 같은 이유로 세로축에 표시된 숫자의 소숫점 역시 생략해도 좋겠지요. `.0’은 아무런 정보도 전달하지 않으니까요. 그래프와 그래프 상단의 텍스트를 구분하는 두꺼운 선 역시 필요하지 않습니다. 앞서 언급한 ’폐쇄성의 원칙’에 따라 독자들은 텍스트 부분과 그래프 부분을 적절하게 구분할 수 있기 때문에 그러한 구분선은 아까운 독자들으 집중력을 분산시키는 방해 요소에 불과합니다. 그러면 이렇게 최소한의 생략 작업만을 거친 그래프를 살펴볼까요?\n 이러한 생략 작업만으로도 가독성이 훨씬 높은 그래프라는 것이 한눈에 보이지요?\n이 이상 어떤 것들을 생략할 수 있을까요? 여기서부터는 여러분이 전달하고자 하는 ’이야기’에 따라 정해집니다. 이것이 중요합니다. 일반적으로 중요하지 않은 정보라는 것은 사실 없습니다. 전달하고자 하는 스토리를 고려했을 때 상대적으로 중요하지 않은 정보가 있는 것이지요.\n스토리에 대해 이야기하기 전에 이 그래프가 전달하고 있는 정보에 대해서 조금 더 이해해 보도록 합시다. 첫째, 이 그래프는 어떤 회사가 판매 계약을 채결하는데 걸리는 시간을 월별로 시각화 해 주고 있습니다. 그런데 판매는 직접 판매(초록색 막대)와 간접 판매(파란색 막대)로 구분되고, 각각 계약 체결에 걸리는 시간이 다르다는 것을 알 수 있네요. 또 하나 알 수 있는 것은 회사에 달성하고자 하는 목표가 있다는 것입니다. 위에 90일이 목표라고 쓰여 있지요? 다시 그래프로 돌아가 보니, 어떤 경우에는 계약 체결에 90일이 걸리지 않아 목표를 달성한 경우도 있고, 90일을 초과해서 목표를 달성하지 못한 경우도 있네요.\n이제 전달하고 싶은 주된 이야기를 가정해 봅시다. 예컨대, 직접 판매와 간접 판매의 계약 체결 기간이 비슷할 때도 있지만 상당히 차이가 나는 경우가 있지요? 이 차이가 주로 전달하고 싶은 이야기라고 해 보지요. 이제 전달하고 싶은 이야기가 결정되었으니, 그 이야기를 전달하는데 필요한 시각 정보 이외의 것들은 가능한 생략하는 것이 좋겠네요. 에컨대, 직접 판매와 간접 판매 사이의 ’차이’를 보이는 것이 스토리라면 각 판매방식의 계약 체결 기간을 표시할 필요성은 떨어집니다. 따라서 바 그래프 위의 숫자는 지워도 좋아 보입니다. 또, 막대 그래프는 차이를 보이기 위해서는 불필요한 시각 정보를 너무 많이 사용하는 방식의 그래프 입니다. 결국 중요한 것은 막대의 높이, 그리고 그 높이의 차이인데, 막대 그래프는 그것을 사각형의 꽉찬 도형으로 보여주고 있거든요. 이 역시 독자의 인지자원을 불필요하게 소비하는 요소입니다. 그런데, 가로축은 ’시간’이기 때문에, ’연속성의 원칙’에 따른 선그래프로 정보를 표현했을 때, 사람들은 자연스럽게 그래프를 좌에서 우로, 시간의 흐름에 따라 이해할 수 있습니다. 다음과 같이 말이죠.\n 이렇게 그래프 종류만 바꾸었는데도 여러가지 개선이 이루어졌습니다. 첫째, 높이 정보를 표현하는데 필요한 것 이외의 시각정보가 사라져 그래프를 읽기 쉬워졌습니다. 둘째, 불필요한 시각 정보가 사라지면서 두 선 사이의 차이에 더욱 주목할 수 있게 되었습니다. 셋째, 선 그래프를 통해 시간의 흐름에 따라 차이도 변화한다는 것을 쉽게 이해할 수 있게 되었습니다.\n만약, 전달하고자 하는 스토리가 단지 두 판매 방식의 차이보다는 간접 판매 방식이 간혹 목표치를 초과한다는 것이라고 해 볼까요? 그렇다면 정보의 위계에서 목표치에 해당하는 90일이 부수적인 시각요소로 표현되기 보다는 독자가 가장 먼저 주목하는 그래프 상에 함께 표현되는 것이 좋겠지요. 다음 그래프를 보시죠.\n 이제 (직접 판매가 아닌) 간접 판매가 경우에 따라 목표치를 종종 초과한다는 것이 명확해졌습니다. 다시 반복하지만, 여기서 중요한 것은 전달하고 싶은 주된 스토리에 따라 정보의 위계가 바뀌었고, 그에 따라 정보의 표현 방식이 바뀌었다는 것입니다.\n생략이 잘 이루어졌다면, 전주의적 속성을 이용한 강조를 고려해볼 수 있습니다. 여기서는 스토리에 따른 정보의 위계를 따지는 것이 더욱 중요합니다. 예컨대, 위의 예에서 간접 판매가 목표치를 초과하는 몇몇 사례들에 주목하고 싶다고 해 볼까요? 그렇다면, 과감하게 텍스트에 핵심 메시지를 전달함과 동시에, 그에 해당하는 시각 정보를 바로 강조하는 방식을 고려해볼 수 있습니다. 아래의 예를 보시죠.\n\n\n\n색상을 이용한 강조\n\n\n텍스트로 전달하고자 하는 메시지가 표현이 되었고, 해당 텍스트와 같은 색상을 선 그래프에서 목표치 초과 사례와 매칭 시켜, 해당 메시지를 이해하기 위해서는 그래프의 어느 부분에 주목해야 하는지를 지시해 주었습니다. 독자들이 같은 색상을 통해 자연스럽게 두 시각 정보를 연결할 것을 기대하는 것이지요. 대신 상대적으로 덜 중요한 목표치나 직접 판매액, 그리고 나머지 눈금 등은 회색으로 색상을 변경하여 정보의 위계를 분영히 했습니다.\n하지만, 전달하고 싶은 스토리가 같은 정보의 긍정적인 면, 즉, 위에서 강조한 세 번을 제외하고는 대부분의 경우 목표치를 달성했다는 것이라면, 오히려 직접 판매에 해당하는 그래프는 중요정보에 해당하므로, 회색으로 처리하기 보다는 눈에 띄는 색상으로 전달하는 것이 바람직하겠지요.\n\n\n\n색상을 이용한 강조의 다른 예"
  },
  {
    "objectID": "story.html#ggplot2를-이용한-데이터-스토리텔링-기초",
    "href": "story.html#ggplot2를-이용한-데이터-스토리텔링-기초",
    "title": "11  데이터 스토리텔링",
    "section": "11.3 ggplot2를 이용한 데이터 스토리텔링 기초",
    "text": "11.3 ggplot2를 이용한 데이터 스토리텔링 기초\n이 장에서 이야기한 데이터 스토리텔링 기법들을 앞서 배운 데이터 시각화 과정에 도입하려고 생각해 보면, 결국 ggplot2를 이용한 코드에 어떤 조작을 가해 그래프를 변형해야 한다는 것을 알 수 있습니다. ggplot2가 선풍적인 인기를 얻게 된 데에는 바로 출판할 수 있는 양질의 시각화를 프로그래밍을 통해 할 수 있다는 사실과 함께, 프로그래밍으로 가능한 최대한의 유연성을 제공한다는 이유도 있습니다. 이러한 유연성 덕분에 지금까지 이야기한 모든 스토리텔링 기법들은 ggplot2로 구현 가능합니다.\n단, 여기서 간단하게 언급할 ggplot2의 확장 기능들은 모든 스토리텔링 기법들을 구현할 수 있을 정도의 심화된 내용은 아닙니다. 조금 더 발전된 내용은 다소 복잡하기에 별도의 챕터에서 따로 설명하려고 합니다. 만약 여러분들이 스스로 그래픽 까지 만들어야 하는 기자라면 해당 장 역시 공부하시기를 권합니다. 반면, 여러분이 그래프 제작을 다른 누군가에게 맡길 수 있다고 하더라도, 이 챕터의 나머지 부분에서 언급하는 내용은 숙지하시는 것을 권합니다. 왜냐하면 여러분들이 지금까지 만들어낸 최소한의 시각화 결과물은 독자 뿐 아니라, 여러분의 시각화를 담당하는 파트너가 이해하기에도 난해할 가능성이 크기 때문이지요. 즉, 여기서 이 장에서 이야기 하는 ggplot2의 확장 기능은 독자 보다는 여러분들의 동료와 소통을 하기 위한 최소한의 시각화 개선 도구라고 생각하시면 되겠습니다.\n그러면 먼저, 지금까지 만든 시각화 결과물은 타인이 함께 일하는 동료도 이해하기 힘들 것이라는데 대한 이야기부터 해 볼까요? 다음은 시각화에 관한 장에서 donorschoose.org 데이터를 이용해 미국 하와이주(HI)와 뉴욕주(NY)의 연도별 평균 프로젝트 목표액 추이를 표현하는데 이용한 것과 동일한 코드입니다.\n\nlibrary(tidyverse)\nlibrary(lubridate)\noptions(scipen=999)\nprojects &lt;- read_csv(\"data/projects.csv\")\nSys.setlocale(\"LC_ALL\",\"Korean\")\n\n[1] \"LC_COLLATE=Korean_Korea.949;LC_CTYPE=Korean_Korea.949;LC_MONETARY=Korean_Korea.949;LC_NUMERIC=C;LC_TIME=Korean_Korea.949\"\n\n\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n이 그래프를 당장 시각화 담당자에게 전달하면 어떤 반응을 얻을까요? 제 예상에는 “avg_size가 뭐에요?”라고 할 것 같습니다. 우리는 코드를 직접 작성했으니 avg_size에서 “avg”가 평균이라는 것도 자명할테고, 그것이 프로젝트 목표액의 평균이라는 것도 분명하겠지만, 시각화 담당자는 그렇지 않겠지요. 이 때는 그래프의 avg_size라는 변수명 대신 y축의 이름(ggplot에서는 y축의 ’타이틀’이라고 합니다)만 바꾸어 주어도 오해의 소지가 줄어들 것입니다.\nggplot2의 좋은 점 중 하나는 이렇게 그래프의 세부사항을 수정하는 작업 역시 지금까지 해왔던 것과 같이 계층(layer)을 쌓는 방식으로 일관되게 할 수 있다는 점입니다. 에를들어 그래프 타이틀 변경은 labs()라는 함수를 새로운 계층으로 변경해서 수행합니다.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point() +\n    labs(x=\"연도\", y=\"평균 목표액\", color=\"주(State)\")\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n앞의 그래프에서 마지막 줄의 labs(x=\"연도\", y=\"평균 목표액\", color=\"주(State)\")만 + 기호를 통해 더해졌다는 점에 주목해주세요. 그래프 세부사항의 수정 역시 계층(layer)을 더해 할 수 있다는 것은 바로 이러한 방식을 의미합니다. 기존의 그래프를 생산하는 코드는 수정할 필요가 없는 것이지요. 그래서, 혼자 빠르게 시각화 결과를 확인해보고 싶을 때에는 그래프 작업을 위한 최소한의 골조만을 작성하고, 다른 사람과 협업할 필요가 있을 때에는 그래프를 수정하기 위한 계층을 몇 줄 덧대는 방식으로 그래프를 수정해서, 업무를 효율화할 수 있습니다.\n그 외의 다른 옵션을 추가한 그래프도 볼까요?\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point() +\n    labs(x=\"연도\", y=\"평균 목표액\", color=\"주(State)\") +\n    scale_x_continuous(breaks=2002:2014, labels=2002:2014) + \n    scale_y_continuous(breaks=seq(400, 1800, by=200), labels=seq(400, 1800, by=200)) +\n    scale_color_discrete(labels=c(\"하와이\", \"뉴욕\")) +\n    theme(panel.background = element_rect(fill = \"white\"),\n          panel.grid.major = element_line(size = 0.5, linetype = 'dashed',\n                                colour = \"grey\"), \n          panel.grid.minor = element_line(size = 0.25, linetype = 'dotted',\n                                colour = \"lightgrey\"))\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\ni Please use the `linewidth` argument instead.\n\n\n\n\n\n특별히 더 나은 그래프는 아닌 것 갓지만 여기서 보아야 할 것은 이렇게 추가적인 수정을 하는데에는 추가적인 계층을 덧붙이는 것으로 충분하는 것입니다. 위의 코드를 조금 더 자세히 살펴보면 다음과 같습니다.\n\nscale_x_continuous(breaks=2002:2014, labels=2002:2014)\n\n연속변수(contiuous)인 x축(연도)의 눈금 표현을 2002, 2003, …, 2014 각각에 대응해서(breaks), 동일한 숫자로 표현(labels)해 줄 것 (이전의 그래프에는 2005와 2010만 표시되었지요.)\n\nscale_y_continuous(breaks=seq(400, 1800, by=200), labels=seq(400, 1800, by=200))\n\n연속변수(contiuous)인 y축(평균 목표액)의 눈금 표현을 400, 600, …, 1800 값에 대응해서(brakes), 동일한 숫자로 표현(labels)해 줄것 (이전의 그래프에서는 간격이 200이 아닌 400이었습니다).\n\nscale_color_discrete(labels=c(\"하와이\", \"뉴욕\"))\n\n이산변수(discrete)인 color(주)의 변수값을 원래의 HI, NY 대신 “하와이”, “뉴욕”으로 표현해 줄 것.\n\ntheme(panel.background = element_rect(fill = \"white\"))\n\n그래프 패널의 배경(panel.background)를 하얀색으로 채워진(fill=\"white\") 사각형 요소(element_rect())로 채울 것.\n\ntheme(panel.grid.major = element_line(size = 0.5, linetype = 'dashed', colour = \"grey\"))\n\n그래프의 주눈금선(panel.grid.major)를 두께가 0.5인 회색 대쉬 선 요소(element_line())으로 변경할 것.\n\ntheme(panel.grid.minor = element_line(size = 0.25, linetype = 'dotted', colour = \"lightgrey\"))\n\n그래프의 부눈금선(panel.grid.minor)를 두께가 0.5인 옅은회식 점선 요소(element_line())으로 변경할 것.\n\n\n이미 약간 복잡하지요? ggplot2에는 이밖에도 그래프 수정을 위한 많은 함수들을 갖추고 있기 때문에 여기서 모든 기능을 설명할 수는 없습니다. 이를 모두 머리속에 기억하고 있다가 코딩할 때 꺼내 쓰는 사람도 별로 없지요. 다만 다음과 같은 원칙 정도를 기억하시면, 필요한 코드를 찾아 쓰는데 도움이 될 것입니다.\n\nlabs() 계층: 그래프에 표현되는 변수들의 이름을 바꾸어 줌.\nscale_..._...() 계층: ggplot2 내부 변수(x, y, color, fill 등)가 그래프로 표현되는 방식을 바꾸어 줌. 단, 함수명은 때에 따라 바뀜. scale_..._...()에서 첫번째 ...에는 내부 변수명이, 두번째 ...에는 해당 변수의 타입이 들어감. 즉, scale_x_contiuous()는 연속형은 x변수의 그래프 표현을 바꾸어주기 위한 계층을 생성하는 함수.\ntheme() 계층: 내부 변수의 표현과 무관한 그 외 미적 요소를 변경하는 역할을 함.\n\n한 가지만 더 첨언하자면, theme()을 어떻게 수정할 것인지 고민할 필요 없이 ggplot2가 미리 제공하는 테마 중 하나를 그냥 선택해도 좋습니다. 다음과 같이요.\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point() +\n    labs(x=\"연도\", y=\"평균 목표액\", color=\"주(State)\") +\n    scale_x_continuous(breaks=2002:2014, labels=2002:2014) + \n    scale_y_continuous(breaks=seq(400, 1800, by=200), labels=seq(400, 1800, by=200)) +\n    scale_color_discrete(labels=c(\"하와이\", \"뉴욕\")) +\n    theme_classic()\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n위 그래프에서는 복잡한 theme() 옵션이 theme_classic()이라는 단순한 옵션으로 바뀌었지요? 이는 ggplot2가 기본적으로 제공하는 테미입니다. 그 외에도 theme_bw(), theme_minimal() 여러가지가 존재합니다. 더 자세한 사항은 한국생명공학연구원 김하성 박사의 강의자료를 참조해 보시기를 권합니다.\n마지막으로 한 가지 더 재미있는 수정을 해 보겠습니다. 앞서 ggplot2가 theme_classic(), theme_bw() 등의 몇 가지 기본 테마를 제공한다고 했지요? 이러한 기본 테마를 추가해주는 패키지도 존재합니다. 다음과 같이 새로운 패키지를 설치해 보세요.\n\ninstall.packages(\"ggthemes\")\n\n설치가 되었으면 해당 패키지를 불러준 다음 다음과 같이 코드 마지막 줄을 수정해 줍니다.\n\nlibrary(ggthemes)\n\nWarning: 패키지 'ggthemes'는 R 버전 4.1.3에서 작성되었습니다\n\n\n\nprojects |&gt; \n    mutate(year = year(date_posted)) |&gt;\n    group_by(school_state, year) |&gt;\n    summarise(avg_size = mean(total_price_excluding_optional_support)) |&gt; \n    filter(school_state %in% c(\"HI\", \"NY\")) |&gt;\n    ggplot() +\n    aes(x=year, y=avg_size, color=school_state) +\n    geom_line() +\n    geom_point() +\n    labs(x=\"연도\", y=\"평균 목표액\", color=\"주(State)\") +\n    scale_x_continuous(breaks=2002:2014, labels=2002:2014) + \n    scale_colour_economist(labels=c(\"하와이\", \"뉴욕\")) +\n    theme_economist() +\n    ggtitle(\"donorschoose.org 연도별 평균 목표액액\")\n\n`summarise()` has grouped output by 'school_state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n한글이 섞여있어 익숙하게 보일지 모르겠습니다만, 이 테마는 영국의 유명한 주간지 가 사용하는 테마입니다. 유사하게 theme_wsj(), scale_colour_wsj() 함수를 이용해 &lt;월스트리트저널&gt;의 테마를 이용하는 것도 가능합니다."
  },
  {
    "objectID": "story2.html#코로나-백신-접종-의사-데이터-받기",
    "href": "story2.html#코로나-백신-접종-의사-데이터-받기",
    "title": "12  심화: 웹프로그래밍을 응용한 데이터 스토리텔링",
    "section": "12.1 코로나 백신 접종 의사 데이터 받기",
    "text": "12.1 코로나 백신 접종 의사 데이터 받기\n이 챕터에서 시각화에 활용할 데이터는 2020년 코로나가 기승을 부리던 당시, 세계 15개국에서 시행된 백신 접종 의사에 대한 설문조사 결과 입니다. 여기서 이야기할 내용은 미국 미시건 대학의 미생물학/면역학 교수인 Patrick Schloss의 강의를 일부 수정·전제한 것임을 밝힙니다. 관심이 있으신 분은 강의에 관한 Schloss 교수의 블로그 포스트와 깃허브 저장소 역시 참조해 보시면 더 많은 정보를 얻을 수 있습니다.\n먼저, 분석에 사용할 데이터를 불러오겠습니다.\n\ndata &lt;- read_csv(\"data/august_october_2020.csv\")\ndata\n\n# A tibble: 16 x 3\n   X.1            `Total Agree - August 2020` `Total Agree - October 2020`\n   &lt;chr&gt;                                &lt;dbl&gt;                        &lt;dbl&gt;\n 1 Total                                   77                           73\n 2 India                                   87                           87\n 3 China                                   97                           85\n 4 South Korea                             84                           83\n 5 Brazil                                  88                           81\n 6 Australia                               88                           79\n 7 United Kingdom                          85                           79\n 8 Mexico                                  75                           78\n 9 Canada                                  76                           76\n10 Germany                                 67                           69\n11 Japan                                   75                           69\n12 South Africa                            64                           68\n13 Italy                                   67                           65\n14 Spain                                   72                           64\n15 United States                           67                           64\n16 France                                  59                           54\n\n\n데이터에서 쉽게 확인할 수 있듯이, 해당 데이터는 각 행이 한 국가를 의미하며, 두번째 열은 8월 조사 결과, 세번째 열은 10월 조사 결과에 대한 정보를 담고 있습니다. 설문조사이니, 원 데이터는 설문 답변자 개개인의 답변 형태였겠지요. 여기서는 시각화 기법에만 집중하기 위해서 각 국가별 평균을 계산하는 전처리가 완료되었다고 가정하도록 하겠습니다.\n먼저, 편의상 데이터에서 다소 난삽한 변수명을 미리 수정해 두겠습니다. X.1과 같이 직관적인 의미가 없는 변수명, Total Agree - August 2020와 같이 대문자 소문자, 띄어쓰기 등이 섞여있는 변수명은 이후 코딩을 하는데 있어 혼란의 여지가 될 가능성이 큽니다.\n\ndata &lt;- data |&gt;\n    rename(country = X.1, august = `Total Agree - August 2020`,\n           october = `Total Agree - October 2020`)\ndata\n\n# A tibble: 16 x 3\n   country        august october\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 Total              77      73\n 2 India              87      87\n 3 China              97      85\n 4 South Korea        84      83\n 5 Brazil             88      81\n 6 Australia          88      79\n 7 United Kingdom     85      79\n 8 Mexico             75      78\n 9 Canada             76      76\n10 Germany            67      69\n11 Japan              75      69\n12 South Africa       64      68\n13 Italy              67      65\n14 Spain              72      64\n15 United States      67      64\n16 France             59      54\n\n\nTotal Agree - August 2020과 같은 변수명의 경우 띄어쓰기로 인해 R이 ‘Total’, ‘Agree’ 등을 모두 별도의 변수명으로 인식하게 되므로, backtick 기호를 통해 묶어줌으로써 Total Agree - August 2020가 하나의 변수명임을 명확하게 했다는 데 주목해 주세요."
  },
  {
    "objectID": "story2.html#중요-정보에-집중하기---한국의-변화-vs-다른-국가의-변화",
    "href": "story2.html#중요-정보에-집중하기---한국의-변화-vs-다른-국가의-변화",
    "title": "12  심화: 웹프로그래밍을 응용한 데이터 스토리텔링",
    "section": "12.2 중요 정보에 집중하기 - 한국의 변화 vs 다른 국가의 변화",
    "text": "12.2 중요 정보에 집중하기 - 한국의 변화 vs 다른 국가의 변화\n앞 장에서 데이터 스토리텔링의 주요 원칙으로 전달하고자 하는 이야기를 더 중요한 정보와 덜 중요한 정보, 즉 ‘정보의 위계’로 전환할 필요성에 대해 이야기 했습니다. 그러면 백신 접종 의사 데이터로 전달하고자 하는 스토리를 가정해 보도록 하죠. 여기서 가정하는 스토리는 ’한국의 접종 의사 변화가 다른 국가에 비해 높고, 8월과 10월 사이에 눈에 띄게 감소하지 않았다’ 입니다. 돌이켜보면, 처음 접종을 시작한 아스트라제네카 백신이 영국에서 긴급승인된 것이 2020년 12월말이니, 8월과 10월 사이는 백신의 안전성에 대한 갑론을박이 격심했던 시기입니다. 때문에 많은 나라에서는 백신 접종 의사가 하락하는 모습을 보여왔죠. 이를 다음과 같은 변화 그래프로 표현하고 싶다고 해 보죠.\n\ndata |&gt;\n    pivot_longer(!country, names_to=\"month\", values_to=\"agree\") |&gt;\n    ggplot() +\n    aes(x=month, y=agree) +\n    geom_point() +\n    geom_line(aes(group=country))\n\n\n\n\n물론, 이와 같은 그래프를 독자에게 보여줄 수는 없습니다. 무엇보다 어떤 선이 어떤 국가의 결과를 의미하는지도 알 수 없고, 더더군다나 한국이 어디에 해당하는지도 알 수 없죠. 그런데, 15개(사실 Total까지 포함해서 16개)의 국가를 그래프에 모두 표현해주면 어떻게 될까요? 독자들이 알아볼 수 없게 난삽한 그래프가 될 것입니다. 따라서, 여기서는 과감하게 기사의 스토리상 더 중요한 정보인 한국만을 다른 색으로 표현하고 덜 중요한 나머지 국가를 회색으로 표현하는 방식으로 정보의 위계를 표현해 보겠습니다.\n\ndata %&gt;%\n    pivot_longer(!country, names_to=\"month\", values_to=\"agree\") |&gt;\n    filter(country != \"Total\") |&gt;\n    # 한국을 다른 색상으로 표시하기 위한 변수\n    mutate(highlight = ifelse(country==\"South Korea\", TRUE, FALSE)) |&gt;   \n    ggplot(aes(x=month, y=agree, color=highlight)) +\n    # 색상 범례(legend) 삭제\n    geom_point(show.legend=FALSE) +\n    # 색상 범례(legend) 삭제\n    geom_line(aes(group=country, size=highlight), show.legend = FALSE) + \n    # 가로-세로 비율 조정\n    coord_fixed(ratio=0.03) +                                            \n    labs(x=\"\",\n         y=\"백신 투약 의사 비율\",\n         title=\"&lt;span style='color: blue'&gt;한국&lt;/span&gt;의 백신 투약 의사는&lt;br&gt;오히려 상승\") +\n    scale_color_manual(breaks=c(TRUE, FALSE),\n                         values=c(\"blue\", \"grey\")) +\n    scale_size_manual(breaks=c(TRUE, FALSE),\n                      values=c(1, 0.5)) +\n    scale_x_discrete(expand=c(0,0.1), \n                     breaks=c(\"august\", \"october\"),labels=c(\"8월\", \"10월\")) +\n    theme(panel.background = element_rect(fill=\"white\"),\n          axis.title.y = element_text(size=15),\n          # ggtext 사용\n          plot.title = element_markdown(size=18, color=\"grey\"),\n          plot.margin = unit(c(1,1,1,1), \"cm\"),\n          plot.title.position=\"plot\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` instead.\n\n\n\n\n\n위의 코드에서 사용한 몇 가지 테크닉에 주목해 보시기 바랍니다.\n\nhighlight 변수 생성/활용: 한국(“South Korea”)의 경우에만 TRUE 값을 같고, 나머지 국가는 모두 FALSE 값을 갖는 변수 highlight 변수를 만들어주었습니다. 이 변수는 geom_point()에서는 color에, geom_line()에서는 size (선의 두께)에 대응되어서 한국만을 다른 색과 두 두께로 표현하여, 한국에 특별히 주목할 수 있도록 했습니다.\n\nshow.legend=FALSE 인수를 활용해서, 옆에 자동으로 표현되는 color 변수, size 변수에 대한 범례가 표시되지 않도록 해 주었습니다. 위 그래프에서 보듯이 파란 선이 한국에 해당한다는 것은 범례가 없이도 분명하기 때문에, 불필요한 정보를 삭제해 주는 것입니다.\n\n색상을 이용한 문자와 시각요소의 대응: ’한국’이라는 문자와 그래프 상의 파란색 선 사이의 대응 관계는 앞장에서 언급한 ’전주의적 속성’에 따라 분명합니다. 이를 이용해 시각화에서 전달하고자 하는 메시지의 의미를 분명하게 드러낸 것이지요. 반면에, 나머지 국가는 한국에 대한 ’비교군’으로서의 의미만 가지므로, ’정보의 위계’에서 그 우선순위가 떨어집니다. 따라서 이를 분명하게 하기 위해서 나머지 국가는 회색에 대응한 것입니다. 이를 위해서 두 가지 중요한 테크닉을 사용했습니다:\n\nscale_color_manual() 함수에서 ggplot2의 내부변수 color가 갖는 TRUE, FALSE(breaks) 값에 파란색과 회색을 대응시켰습니다(values=). 앞서 color에는 외부변수 highligh를 대응시켰고, 이는 사실 한국을 의미하니, 한국만 파란 색으로 표현되고, 나머지 국가는 회색으로 표현되는 것입니다.\nlabs함수 안에서 title= 인수를 이용해 그래프 위의 텍스트를 더해주었는데, 그 때 “한국”이라는 글자를 그래프색과 동일한 파란색으로 만들어 주었습니다. 여기서 &lt;span style='color: blue'&gt; ... &lt;/span&gt;이라는 이상한 문자열이 사용되었는데요, 이는 사실 HTML 문법입니다. &lt;span&gt; ... &lt;/span&gt; 은 두 테그 사이에 들어간 텍스트에 색상, 글자체 등을 부여하기 위한 HTML 코드이고, style='color: blue'는 글자의 색상을 파란색으로 해 달라는 의미이지요. &lt;br&gt; 역시 줄 바꿈을 의미하는 HTML 코드입니다.\n이렇게 ggplot2 안에서 HTML 코드를 사용하기 위해서 앞서 로드한 패키지가 ggtext 입니다. ggtext는 아무 곳에서나 사용할 수 있는 것은 아니고요, 해당 문자열에서 ggtext를 사용할 것이라는 것을 알려주어야 합니다. 그 부분이 theme() 함수 안에 있는 plot.title = element_markdown() 옵션 입니다. 이 부분이 있어야 ggplot2는 그래프의 타이틀 텍스트에서 HTML 코드를 쓰고 있다는 것을 인식하게 됩니다.\n사실, 글자의 색상 등을 표현하는데 있어 꼭 HTML 코드를 사용해야 할 필요가 있는 것은 아닙니다. 다만, 그 외의 다른 방법들의 문법이 그렇게 직관적이지 않고, 기본적인 HTML 코드는 데이터 사이언스를 하면서 익숙해질 수밖에 없는 웹 표준 문법이기 때문에, R 문법과 섞어 사용하는 것이 시너지가 있을 것이라고 보아 권하는 방법이죠.\n\ncoord_fixed()를 이용한 그래프의 가로-세로 비율 조정. ggplot2가 자동으로 표현해 주는 가로-세로 비율이 마음에 들지 않는 경우가 있습니다. 이 때에는 coord_fixed() 함수의 ratio 인수를 이용해 비율을 조정해 줍니다. ratio 값을 조금씩 바꾸어가며 그래프가 변화하는 모습을 관찰해 보세요. 대략적으로 ratio의 값이 작을수록 그래프가 좌우로 넓게 표현된다고 생각하시면 되겠습니다."
  },
  {
    "objectID": "story2.html#프로페셔널한-바벨차트-그리기",
    "href": "story2.html#프로페셔널한-바벨차트-그리기",
    "title": "12  심화: 웹프로그래밍을 응용한 데이터 스토리텔링",
    "section": "12.3 프로페셔널한 바벨차트 그리기",
    "text": "12.3 프로페셔널한 바벨차트 그리기\n같은 데이터를 이용해 이번에는 조금 다른 스토리를 전달하고 싶다고 가정해 봅시다. 앞의 사례와 달리 이번에는 모든 국가의 백신 접종 의사에 대해서 관심을 가지고 있다고 해 볼까요? 다만, 그 중에서 어떤 국가에서 8월과 10월 사이 접종 의사에 더 큰 변화가 일어났는지, 국가별로 변화의 차이가 있는 이유는 무엇인지 등에 대해 보도한다고 생각해 보죠. 이 경우에는 각 국가에 모두 관심을 가지고 있기 때문에, 모든 국가가 그래프에 표현이 되어야 합니다. 그리고 각 국가 별로 일어난 의견 변화의 크기 비교에 관심을 가지고 있으니, 의견 변화가 잘 비교될 수 있는 방식으로 표현되어야 겠지요. 예컨대 위에서 사용했던 그래프라면, 전반적인 의견 변화 양상을 한 눈에 들어올 수 있지만, 각 국가의 개별적인 변화가 눈에 들어오지 않으니, 국가간 비교는 어렵습니다.\n이런 경우 최근 자주 사용되는 시각화 방법중 하나가 바벨 차트(barbell chart)라고 부르는 다음과 같은 그래프 입니다.\n\ndata |&gt;\n    pivot_longer(!country, names_to=\"month\", values_to=\"agree\") |&gt;\n    filter(country != \"Total\") |&gt;\n    ggplot(aes(x=agree, y=country, color=month)) +\n    geom_line(aes(group=country), linewidth=1.75, color=\"grey\", show.legend = FALSE) +\n    geom_point(size=2) +\n    theme_minimal() +\n    labs(x=\"\", y=\"\")\n\n\n\n\n여러분도 바벨 차트라는 이름이 붙은 이유가 분명히 보이실 것입니다. 각 국가별 다른 시점(8월과 10월)의 데이터가 각각 점으로 표시되고, 그 사이를 선으로 연결한 모습이 운동할 때 사용하는 바벨처럼 보인다고 해서 바벨 차트입니다. 이코노미스트, 월스트리트 저널 등의 보도에서 유독 자주 사용되기도 합니다.\n이 그래프를 만들어내기 위한 위의 코드와 앞서 작성한 코드 사이에 거의 차이가 없다는 점에 주목해 주세요! 우리는 지금 만들어낸 그래프를 ’바벨 차트’라고 부르지만, ggplot2를 이용해 이를 구현하기 위해서는 결국 geom_point()를 이용해 점을 찍고 geom_line(aes(group=country))라고 써 같은 국가에 해당하는 점들을 연결했습니다. 사실 어떤 그래프든 단순한 명령어들의 조합으로 구현할 수 있는 유연성이 ggplot2가 가지고 있는 매우 중요한 장점 중 하나입니다.\n그렇다면, 무엇을 바꾸었기에 다른 그래프의 모양이 된 것일까요? 앞서 작성한 그래프와 다른 점을 보기 위해 핵심이 되는 일부 코드만 가져와 보겠습니다.\n\nggplot(aes(x=month, y=agree, color=highlight)) +\n    geom_point(show.legend=FALSE) +\n    geom_line(aes(group=country, size=highlight), show.legend = FALSE) + \n\n차이점이 보이시나요? 네 단지, aes() 함수 안에서 이루어지는 내부변수, x,y,color와 외부변수 간의 매칭이 바뀌었을 뿐입니다. 앞선 그래프에서는 x=month, y=agree 였다면, 바벨 차트는 x=agree, y=country로 바뀌었을 뿐이지요. 이렇게 원하는 그래프를 그리기 위해서는 최종적으로 원하는 그래프를 그려본 후, 이를 ggplot2로 구현하기 위해 어떤 geometry 계층(즉, 사용할 geom_...() 함수들 선택)을 사용해야 하는지, aesthetics 계층에서 외부변수와 내부변수를 어떻게 매칭시켜주어야 하는지(즉, aes() 함수 안에 들어갈 인수 결정)만 정하면 그만입니다.\n이제 위의 바벨 차트를 조금 더 프로페셔널해 보이는 방식으로 수정해 봅시다. 다음의 코드와 결과물을 살펴보세요.\n\ndata %&gt;%\n    # 나라 이름을 한글로 변환\n    mutate(country = case_when(country==\"India\"~\"인도\", country==\"China\"~\"중국\", \n                               country==\"South Korea\"~\"한국\", country==\"Barzil\"~\"브라질\", \n                               country==\"Australia\"~\"호주\", country==\"United Kingdom\"~\"영국\", \n                               country==\"Mexico\"~\"멕시코\", country==\"Canada\"~\"캐나다\", \n                               country==\"Germany\"~\"독일\", country==\"Japan\"~\"일본\", \n                               country==\"South Africa\"~\"남아공\", country==\"Italy\"~\"이탈리아\", \n                               country==\"Spain\"~\"스페인\", country==\"United States\"~\"미국\", \n                               country==\"France\"~\"프랑스\")) |&gt;\n    pivot_longer(!country, names_to=\"month\", values_to=\"agree\") |&gt;\n    filter(country != \"Total\") |&gt;\n    group_by(country) %&gt;%\n    # 그래프상 수치 표현을 위한 위치 지정 \n    mutate(increase = ifelse(agree == max(agree), TRUE, FALSE),\n           bump = ifelse(increase, agree + 2, agree - 2)) |&gt;\n    ggplot(aes(x=agree, y=country, color=month)) +\n    geom_line(aes(group=country), size=1.75, color=\"#e6e6e6\", show.legend = FALSE) +\n    geom_point(size=2, show.legend = FALSE) +\n    # glue를 이용해 수치 뒤에 %를 삽입\n    geom_text(aes(label=glue(\"{agree}%\"), x=bump), show.legend=FALSE) +\n    scale_color_manual(name=NULL,\n                     breaks=c(\"august\", \"october\"),\n                     values=c(\"#727272\", \"#15607a\")) +\n    scale_x_continuous(limits=c(50, 100),\n                     breaks=seq(50, 100, by=5),\n                     labels=glue(\"{seq(50, 100, 5)}%\")) +\n    # 세로 여백을 확보\n    scale_y_discrete(expand=c(0, 1.5)) +\n    labs(x=NULL, y=NULL,\n       title=\"코로나 백신 접종이 시작되면 접종을 받겠다\",\n       caption=\"&lt;i&gt;15개 국가 16-74세 사이 18,526명에 대한 온라인 조사&lt;/i&gt;&lt;br&gt;출처: Ipsos\") +\n    theme(plot.title.position = \"plot\",\n          plot.title = element_text(face=\"bold\", margin= margin(b=20), size=20),\n          # ggtext이용해 HTML 문법 사용함 주의\n          plot.caption = element_markdown(hjust=0, color=\"darkgray\"),\n          plot.caption.position = \"plot\",\n          panel.background = element_blank(),\n          axis.ticks = element_blank(),\n          axis.text.x = element_text(color=\"darkgray\"),\n          panel.grid.major.x = element_line(color=\"gray\", size=0.1),\n          panel.grid.major.y = element_line(color=\"gray\", size=0.1, linetype=\"dotted\")) +\n    # 적절한 위치에 '8월', '10월' 표시\n    geom_richtext(x=79, y=14.7, label=\"&lt;span style='color:#15607a'&gt; 10월 &lt;/span&gt;\", \n                  fill = NA, label.color = NA, size=4, show.legend = FALSE) +\n    geom_richtext(x=88, y=14.7, label=\"&lt;span style='color:#727272'&gt; 8월 &lt;/span&gt;\", \n                  fill = NA, label.color = NA, size=4, show.legend = FALSE)\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\ni Please use the `linewidth` argument instead.\n\n\n\n\n\n이번엔 그래프가 상당히 복잡해 보이지만, 사실 대부분 이미 위에서 다룬 테크닉들입니다. 다음의 새로운 도구들에만 주의 깊게 봐주시길 바랍니다.\n\n그래프상 숫자(%) 표현:\n\n데이터상의 수치를 그대로 그래프에 표시하는 함수(즉, ggplot2의 geometry 계틍)는 geom_text()입니다. 해당 함수 안에서 aes()를 통해 내부변수 label과 텍스트로 표시하고자 하는 외부변수 (위의 예에서는 agree)를 매칭해 주시면 됩니다.\n그러나 geom_text(aes(label=agree)) 이렇게 바로 사용하게 되면 agree 변수가 단순히 숫자이므로 %로 표시되지 않고, 단순히 숫자로 표시될 것입니다. 이 때 사용하기 위에 우리는 앞서 glue라는 라이브러리를 불러왔습니다. glue 라이브러리의 glue() 함수를 이용하면, 쉽게 외부 데이터 변수에 특정 문자열을 붙여서 표현할 수 있습니다. 즉, glue({agree}%)라고 쓰면, agree 변수에 들어있는 각각의 값에 %기호를 붙여서 표현하라는 의미입니다.\n또 하나의 추가적인 문제는 숫자가 표시되는 위치입니다. 단순히 geom_text(aes(label=agree) 라고 쓰는 경우, 숫자는 정확히 해당 숫자에 해당하는 위치에 표시되게 됩니다. 문제는 그 위치가 geom_point() 함수가 점을 표현하는 위치와 동일하다는 것이지요. 따라서, 점과 숫자가 겹쳐 보이게 됩니다. 때문에, 숫자가 표시될 위치에 해당하는 변수를 하나 새로 만들어, 원래 agree 변수에서 작은 숫자는 왼쪽으로 (즉, 더 작게), 큰 숫자는 오른쪽으로 (즉, 더 크게) 수치 표시 위치를 표현해 줄 수 있도록 하고, 이를 내부변수 x 매칭시켜주어야 합니다. 다음 부분이 거기에 해당합니다.\n\n… \ngroup_by(country) %&gt;%\n    mutate(increase = ifelse(agree == max(agree), TRUE, FALSE),\n           bump = ifelse(increase, agree + 2, agree - 2))\n…\ngeom_text(aes(label=glue(\"{agree}%\"), x=bump), show.legend=FALSE) +\n...\n\n즉, 한 국가 안에서 더 큰 agree 수치(대부분의 경우는 8월 수치에 해당합니다)를 TRUE로, 더 작은 수치를 FALSE로 표현하는 increase라는 변수를 하나 만든 다음, increase가 TRUE에 해당하면(즉, 더 큰 수이면) 원래 agree 수치에 2를 더한 숫자를, increase가 FALSE에 해당하면(즉, 더 작은 수이면) 원래 agree수치에 2를 뺀 숫자를 갖는 bump라는 새로운 변수를 만들었고, geom_text()함수에서 원래의 agree 대신 새로운 변수 bump를 x에 대응시키는 방식으로 위치를 조정해 준 것입니다.\n\n\n\n\n‘8월’, ’10월’과 같은 데이터에 없는 문자 표현은 geom_richtext()라는 함수를 사용하였습니다. 이 역시 ggtext 라이브러리에 포함된 함수입니다.\n색상은 ‘grey’, ’white’와 같은 표현 대신에 “#727272”, “#15607a”와 같은 표현을 사용했습니다. 이는 ’헥사코드’라고 부르는 색상 표현 방식으로, 여섯자리 16진수를 이용해 1600만개가 넘는 다양한 색상을 표현할 수 있습니다. 훨씬 더 전문적으로 보이는 색상을 ggplot2로 구현하는데 이용할 수 있을 뿐만 아니라, 웹프로그래밍의 표준 색상 표현 방식이므로, 전문가들이 이미 만들어 둔 전문적인 색상 조합을 이용하는데에도 유리하고요. 원하는 색상의 헥사코드를 알려주는 [웹사이트](https://htmlcolorcodes.com/)가 이미 많이 있으므로, 이들을 이용해서 원하는 색상으로 완벽하게 커스터마이징 하는 것 역시 가능합니다."
  },
  {
    "objectID": "story2.html#section",
    "href": "story2.html#section",
    "title": "12  심화: 웹프로그래밍을 응용한 데이터 스토리텔링",
    "section": "12.4 ",
    "text": "12.4"
  },
  {
    "objectID": "spatial.html#아파트-실거래가-데이터-얻기",
    "href": "spatial.html#아파트-실거래가-데이터-얻기",
    "title": "13  심화: 공간정보를 이용한 분석",
    "section": "13.1 아파트 실거래가 데이터 얻기",
    "text": "13.1 아파트 실거래가 데이터 얻기\n여기서 사용할 데이터는 공공데이터 포털에서 얻을 수 있는 국토교통부 아파트매매 실거래 상세 자료 입니다. API키를 획득하는 방법등은 앞에서 이미 다루었으므로, 해당 부분을 참조하길 바랍니다. 먼저, 데이터를 얻는 가장 기초적인 방법을 반복해 보겠습니다.\n\nres &lt;- GET(url=\"http://openapi.molit.go.kr:8081/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade\",\n           query=list(LAWD_CD=11110,\n                      DEAL_YMD=201512,\n                      serviceKey=\"LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq/ea2CQUTUuisLvxlxaGm0YTp4f+89FfhplvwiQIe0cngpybTkdDHQ==\"))\ndtJSON &lt;- httr::content(res, as = \"text\", encoding=\"UTF-8\")\ndata &lt;- fromJSON(dtJSON)\ndf &lt;- data$response$body$items$item\n\ndf\n\n       거래금액 거래유형 건축년도   년 등기일자   법정동\n1        82,500              2008 2015            사직동\n2        60,000              1981 2015            당주동\n3       130,000              2004 2015            내수동\n4       105,000              2004 2015            내수동\n5       120,000              2003 2015            내수동\n6        17,000              2014 2015            연건동\n7        17,000              2014 2015            연건동\n8        57,000              2006 2015           명륜1가\n9        44,000              1995 2015           명륜2가\n10       52,000              1995 2015           명륜2가\n11       49,800              1995 2015           명륜2가\n12       41,000              1999 2015           명륜2가\n13       41,000              1999 2015            창신동\n14       19,500              1966 2015            창신동\n15       39,900              2003 2015            창신동\n16       20,800              1966 2015            창신동\n17       27,200              1993 2015            창신동\n18       39,000              1999 2015            창신동\n19       39,950              1993 2015            창신동\n20       34,500              1992 2015            창신동\n21       37,000              1992 2015            창신동\n22       42,800              1992 2015            창신동\n23       37,300              1992 2015            창신동\n24       50,000              1999 2015            창신동\n25       12,300              2013 2015            숭인동\n26       52,000              2009 2015            숭인동\n27       53,300              2008 2015            숭인동\n28       42,500              2009 2015            숭인동\n29       13,000              2014 2015            숭인동\n30       11,500              2014 2015            숭인동\n31       27,000              1997 2015            숭인동\n32       44,900              2009 2015            숭인동\n33       11,900              2014 2015            숭인동\n34       10,500              2013 2015            숭인동\n35       10,000              2013 2015            숭인동\n36       42,500              2008 2015            숭인동\n37       39,700              2008 2015            숭인동\n38       52,300              2008 2015            숭인동\n39       10,800              2013 2015            숭인동\n40       52,500              2009 2015            숭인동\n41       44,600              1995 2015            교북동\n42      115,000              2004 2015            평창동\n43      164,500              2009 2015            평창동\n44       31,500              1998 2015            평창동\n45       39,490              2000 2015            무악동\n46       63,490              2000 2015            무악동\n47       62,000              2008 2015            무악동\n48       63,400              2015 2015            무악동\n49       61,000              2008 2015            무악동\n                          아파트 월 일 전용면적 중개사소재지   지번 지역코드 층\n1  광화문스페이스본(101동~105동) 12 10  94.5100                   9    11110 11\n2           롯데미도파광화문빌딩 12 22 149.9500                 145    11110  8\n3                       킹스매너 12  8 194.4300              110-15    11110  6\n4              경희궁의아침2단지 12 14 124.1700                  71    11110  8\n5               경희궁파크팰리스 12 24 146.3300                  95    11110  4\n6                     이화에수풀 12 17  16.9800              195-10    11110  8\n7                     이화에수풀 12 18  16.9800              195-10    11110  4\n8                         렉스빌 12 29 106.9800                  19    11110  3\n9                          아남1 12  1  84.8000                   4    11110 18\n10                         아남1 12 10  84.9000                   4    11110 12\n11                         아남1 12 19  84.8000                   4    11110  1\n12                         아남3 12 19  61.1300                 237    11110  7\n13                          두산 12  2  59.9500                 232    11110  9\n14                        동대문 12  3  28.8000              328-17    11110  6\n15                      창신이수 12  3  68.0600              23-816    11110  8\n16                        동대문 12  7  28.8000              328-17    11110  3\n17                     창신쌍용2 12  7  64.6600                 703    11110  3\n18                          두산 12 10  59.9500                 232    11110 14\n19                     창신쌍용2 12 11 115.5300                 703    11110  2\n20                     창신쌍용1 12 12  79.8700                 702    11110  5\n21                     창신쌍용1 12 14  79.8700                 702    11110  3\n22                     창신쌍용1 12 22 106.6200                 702    11110 12\n23                     창신쌍용1 12 23  79.8700                 702    11110  9\n24                          두산 12 24  84.9000                 232    11110  4\n25                  종로아인스빌 12  2  12.1500              1392-1    11110 10\n26            종로청계힐스테이트 12  3  84.9478                 766    11110 19\n27                  종로센트레빌 12  5  84.9200                 2-1    11110 10\n28            종로청계힐스테이트 12  5  59.9426                 766    11110  2\n29                 삼전솔하임4차 12  8  15.0900               318-2    11110 15\n30                 숭인한양LEEPS 12  8  12.7800              1421-2    11110 10\n31        동문(비동,씨동)(494-0) 12  9  59.9400                 494    11110  3\n32            종로청계힐스테이트 12 14  59.9426                 766    11110 12\n33                 숭인한양LEEPS 12 14  12.7800              1421-2    11110 11\n34                  익성씨티하임 12 15  15.7600                1392    11110 13\n35                  익성씨티하임 12 15  14.4800                1392    11110 14\n36                  종로센트레빌 12 19  59.9200                 2-1    11110 12\n37                  종로센트레빌 12 22  59.9200                 2-1    11110  1\n38                  종로센트레빌 12 26  84.9200                 2-1    11110 12\n39                 종로유케이201 12 31  12.0100              201-11    11110  7\n40            종로청계힐스테이트 12 31  84.9478                 766    11110 11\n41                          동아 12  7  84.2800                 101    11110 10\n42            벽산블루밍평창힐스 12  2 210.5300                  45    11110  2\n43                  롯데캐슬로잔 12  3 219.7750                 108    11110  3\n44                          삼성 12  6  59.9700                 596    11110  9\n45                          현대 12 12  60.0000                  82    11110 15\n46                          현대 12 15 114.9000                  82    11110  6\n47                인왕산아이파크 12 16  84.8580                  60    11110  5\n48             인왕산2차아이파크 12 22  84.0284                  88    11110 10\n49                인왕산아이파크 12 25  84.8580                  60    11110 13\n   해제사유발생일 해제여부\n1                         \n2                         \n3                         \n4                         \n5                         \n6                         \n7                         \n8                         \n9                         \n10                        \n11                        \n12                        \n13                        \n14                        \n15                        \n16                        \n17                        \n18                        \n19                        \n20                        \n21                        \n22                        \n23                        \n24                        \n25                        \n26                        \n27                        \n28                        \n29                        \n30                        \n31                        \n32                        \n33                        \n34                        \n35                        \n36                        \n37                        \n38                        \n39                        \n40                        \n41                        \n42                        \n43                        \n44                        \n45                        \n46                        \n47                        \n48                        \n49                        \n\n\n처리 결과에서 볼 수 있는 것처럼 해당 데이터는 2015년 12월(DEAL_YMD=201512) 서울 종로구에서 이루어진(LAWD_CD=11110) 아파트 매매 자료를 포함하고 있습니다. 대단히 흥미로운 자료이지만, 결정적인 문제가 있습니다. 해당 데이터는 종로구라는 한정된 공간에 대한 데이터를 2015년12월이라는 아주 짧은 기간에 관해서만 제공하고 있다는 것이 바로 그점입니다.\n따라서, 다수의 연월과 공간에 대해 위의 작업을 반복해 줄 필요가 있습니다. 이를 위해서는 (1) 위의 작업 전체를 하나의 함수로 만든 다음, (2) 해당 함수를 여러개의 연월과 공간에 대해 반복해 주면 됩니다."
  },
  {
    "objectID": "spatial.html#함수-만들기",
    "href": "spatial.html#함수-만들기",
    "title": "13  심화: 공간정보를 이용한 분석",
    "section": "13.2 함수 만들기",
    "text": "13.2 함수 만들기\n먼저 함수를 만들도록 합시다. R에서 사용자가 직접 함수를 만들기 위한 문법은 다음과 같습니다.\n\n함수이름 &lt;- function(인수){\n    함수내용\n}\n\n\n함수이름: 원하는대로 함수의 이름을 만들어 줍니다. 물론, 해당 함수 이름은 함수가 실제로 행하는 작업의 내용을 반영해서 써 주는 것이 후에 함수를 기억하고 재사용하는데 유리합니다.\n인수: 사용자가 만들 함수의 투입물(input)의 이름을 적어줍니다. 우리는 앞으로 만들 함수가 다수의 연월과, 지역을 투입물(input)로 받아들이고, API로부터 해당 연월과 지역의 아파트 거래기업을 받아오는 작업을 하기를 원하니 인수는 아파트 연월과 지역 코드가 되어야 할 것입니다.\n함수내용: 함수가 실제로 어떠한 동작을 하는지를 써 주면 됩니다. 결국 위에서 사용한 코드를 그대로 사용하되, 11110, 201512 부분만 특정값으로 고정되는 것이 아니라 계속해서 변화될 수 있도록 인수 형태로 적어주면 됩니다.\n\n다음의 함수 정의를 보세요.\n\ngetApt &lt;- function(cd, ymd){\n    res &lt;- GET(url=\"http://openapi.molit.go.kr:8081/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade\",\n           query=list(LAWD_CD=cd,\n                      DEAL_YMD=ymd,\n                      serviceKey=\"LGvIXqsO1eCAKjgMBQWd5QYDOJ77cd4Tq/ea2CQUTUuisLvxlxaGm0YTp4f+89FfhplvwiQIe0cngpybTkdDHQ==\"))\n    dtJSON &lt;- httr::content(res, as = \"text\", encoding=\"UTF-8\")\n    data &lt;- fromJSON(dtJSON)\n    df &lt;- data$response$body$items$item\n\n    return(df)\n}\n\n여기서 getApt가 함수이름, cd, ymd가 인수에 해당합니다. 함수내용은 우리가 처음 다룬 코드와 동일하지만, 11110과 201512 부분만 인수인 cd, ymd로 대체되었습니다. 이제 꼭 “종로구”, “2015년 12월”에 관한 데이터 뿐만 아니라 cd, ymd에 어떤 값을 집어넣느냐에 따라 여러 지역과 기간에 관한 데이터를 얻을 수 있게 됩니다. 다음과 같이 말이죠.\n\ngetApt(cd=11110, ymd=201512)\n\n위의 API에서 사용하고 있는 지역코드는 ’행정표준관리시스템’을 따르는 것으로, 지역코드는 해당 웹사이트에서 확인 및 검색할 수 있습니다."
  },
  {
    "objectID": "spatial.html#아파트-실거래가-반복",
    "href": "spatial.html#아파트-실거래가-반복",
    "title": "13  심화: 공간정보를 이용한 분석",
    "section": "13.3 아파트 실거래가 (반복)",
    "text": "13.3 아파트 실거래가 (반복)\n이제 위의 함수를 여러 지역과 연도에 따라 반복해 줍니다. R에서 가장 간단하게 함수를 반복해 주는 문법은 다음과 같습니다.\n\nfor (컨테이너 in 벡터) {\n    컨테이너에 담겨있는 벡터의 요소를 이용해 반복할 작업 내용\n}\n\n\n벡터: 반복을 수행할 요소들을 묶어둔 벡터를 의미합니다. 예컨대 지역코드 벡터 c(11110, 11111)라면 11110에 해당하는 지역과 11111에 해당하는 지역에 대한 같은 작업을 반복하겠다는 뜻입니다.\n컨테이너: 컨테이너는 반복할 벡터의 요소를 한 번에 하나씩 담을 상자라고 생각하면 되겠습니다. 반복할 벡터가 c(11110, 11111)이고 컨테이너의 이름이 cd라면 첫번째 반복에서는 cd는 11110을 의미하고, 두번째 반복에서 cd는 11111을 의미하는 식입니다.\n작업 내용: 컨테이너에 들어있는 값을 가지고 어떤 작업을 차례차례 반복할 것인지를 여기에 서 주면 되겠습니다.\n\n먼저 반복할 벡터들을 만들어주겠습니다.\n\ncds &lt;- c(27260, 27140, 27290, 27110, 27170, 27200, 27230, 27710)\nymds &lt;- 202101:202112\n\ncds에 들어있는 숫자는 각각 대구광역시 수성구, 동구, 달서구, 중구, 서구, 남구, 북구, 달성군에 해당하는 지역 코드 입니다. 그리고 ymds에 해당하는 202101:202112은 202101부터 202112까지 12개의 정수, 즉, 2021년 1월부터 12월까지를 의미합니다.\n이제 두 개의 벡터에 대해 반복을 해야 합니다. 앞에서는 하나의 벡터에 대해서만 반복을 했는데, 두 개에 대해서는 어떻게 반복을 해야 할까요? 방법은 간단합니다. 반복문 안에 반복문이 있으면 됩니다. 다음과 같이 말이죠.\n\ndatalist &lt;- list()   # 데이터를 차례차례 입력할 빈 리스트 생성\ncounter &lt;- 1         # 리스트 안의 위치를 지정해주기 위한 카운터\nfor (cd in cds){\n    for (ymd in ymds) {\n        #dt &lt;- getApt(cd=cd, ymd=ymd)\n        #print(dt)\n        datalist[[counter]] &lt;- getApt(cd=cd, ymd=ymd)\n        counter &lt;- counter + 1\n    }\n}\n\n\ndatalist: list() 명령으로 만들어진 빈 리스트 입니다. 한 번 반복할 때마다 API로부터 하나의 테이블이 들어오므로, 이 테이블들을 하나하나 빈 리스트에 넣어두는 것입니다.\ncounter는 빈 리스트였던 datalist의 어느 자리에 새로운 리스트를 넣어줄 지를 정해주는 역할을 합니다. counter &lt;- counter + 1 이라고 되어 있으니, 반복이 한 번 이루어질 때마다 counter는 1에서 2, 3, 4, … 이렇게 더 큰 숫자를 가지게 됩니다. 따라서, 테이블에 새로 하나 전송될 때마다 datalist[[counte]] &lt;-에 따라 datalist의 첫번째 자리, 두번째 자리, 세번째 자리에, 차곡차고 쌓이게 되는 것이지요. 반복이 끝나고 나면 datalist는 12개월*8개지역=96개 테이블을 가지고 있는 리스트가 됩니다.\n\n이제 ’테이블들의 리스트’인 datalist에 들어있는 모든 테이블을 하나의 테이블로 합쳐줍니다.\n\ndtApt &lt;- bind_rows(datalist)\n\n이제 우리는 dtApt라는 상당히 큰 테이블을 가지게 되었습니다.\n\n#write_csv(dtApt, \"dtApt.csv\")\n\n\n#dtApt &lt;- read_csv(\"dtApt.csv\")"
  },
  {
    "objectID": "spatial.html#아파트-실거래가-시각화",
    "href": "spatial.html#아파트-실거래가-시각화",
    "title": "13  심화: 공간정보를 이용한 분석",
    "section": "13.4 아파트 실거래가 (시각화)",
    "text": "13.4 아파트 실거래가 (시각화)\n이제 주어진 데이터를 이용해 시각화를 시작해 보겠습니다. 당장의 목표는 각 연도별, 지역별 평균 매매 가격을 시각화하는 것입니다.\n\naggApt &lt;- dtApt %&gt;%\n    mutate(거래금액 = as.numeric(gsub(\",\", \"\", 거래금액)),\n           #yearmonth = 년*100 + 월,\n           district = case_when(지역코드 == 27260 ~ \"수성구\",\n                                지역코드 == 27140 ~ \"동구\",\n                                지역코드 == 27290 ~ \"달서구\",\n                                지역코드 == 27110 ~ \"중구\",\n                                지역코드 == 27170 ~ \"서구\",\n                                지역코드 == 27200 ~ \"남구\",\n                                지역코드 == 27230 ~ \"북구\", \n                                지역코드 == 27710 ~ \"달성군\")) %&gt;%\n    group_by(district, 월) %&gt;%\n    summarise(avgP = mean(거래금액)) \n\n`summarise()` has grouped output by 'district'. You can override using the\n`.groups` argument.\n\n\n거래금액을 재정의 한 부분에 주목하세요. 이 부분은 금액을 표현하는 숫자 표시에 쉽표(,)가 있어 R이 금액을 숫자가 아닌 문자처럼 인식하는 문제를 해결해 주는 코드 입니다. 즉, gsub() 함수를 이용해 쉼표를 제거해 준 다음, as.numeric() 함수를 이용해 문자를 숫자로 다시 인식시켜 줍니다. 그 외에는 이전 챕터에서 이미 연습한 바 있는 코드입니다.\n이제 시간에 따른 평균 매매 가격 변화를 지역별로 시각화해 보겠습니다.\n\naggApt %&gt;%\n    ggplot(aes(월, avgP, color=district)) +\n    geom_line() +\n    facet_wrap(~ district, nrow = 2) +\n    theme_classic()\n\n\n\n\n이를 조금 더 보기좋게 수정한 코드는 다음과 같습니다.\n\naggApt %&gt;%\n    ggplot(aes(as.integer(월), avgP, color=district)) +\n    geom_line() +\n    facet_wrap(~ district, nrow = 2) +\n    theme_classic() +\n    ylab(\"아파트 가격\") + \n    xlab(\"월\") +\n    scale_x_continuous(breaks=seq(1,12,by=2)) +\n    scale_y_continuous(breaks=c(25000, 35000, 45000)) +\n    theme(legend.position = \"none\")"
  },
  {
    "objectID": "spatial.html#지도를-이용한-시각화",
    "href": "spatial.html#지도를-이용한-시각화",
    "title": "13  심화: 공간정보를 이용한 분석",
    "section": "13.5 지도를 이용한 시각화",
    "text": "13.5 지도를 이용한 시각화\n앞서 실습해 본 시각화는 공간정보 그 자체를 시각화에 이용하기 보다는 통상적인 데이터 분석에 이용했던 바와 같이 일종이 카테고리 변수로 활용했습니다. 공간 정보를 조금 더 원래 뜻에 맞게 사용하는 방식으로 지도를 이용한 시각화가 있습니다. 먼저, 대한민국 지도 정보를 포함하고 있는 데이터 파일을 getData() 함수를 이용해 불러오겠습니다. 해당 함수는 raster 라이브러리에 포함되어 있습니다.\n\nkorea &lt;- getData('GADM', country='kor', level=2)\n\nWarning in getData(\"GADM\", country = \"kor\", level = 2): getData will be removed in a future version of raster\n. Please use the geodata package instead\n\n#korea &lt;- shapefile('data/TL_SCCO_SIG.shp')\n\n여기서 ’GADM’은 getData() 함수를 이용해 불러올 수 있는 공간 정보 중 하나로, 전세계 행정 경계에 관한 데이터 입니다. GADM 데이터에서 level=1은 광역시도 경계를 의미한다면, level=2는 자치구와 자치군 수준의 경계를 의미합니다.\n우리 예에서는 대구의 정보만을 표현하면 족하기 때문에 대구에 해당하는 공간 정보만을 서브세팅 하겠습니다.\n\ndaegu_gadm &lt;- korea[korea$NAME_1 == 'Daegu', ]\n\n공간정보를 표현하는 방식은 여러가지가 있을 수 있으나, 위의 데이터는 Polygon이라고 부르는 형태를 표현하는 방식을 사용하고 있습니다. 놀랍게도 우리가 지금까지 사용해 온 ggplot2는 Polygon 방식의 공간데이터를 시각화해줄 수 있습니다. 단지 geometry 계층으로 geom_polygon()을 선택해 주기만 하면 됩니다.\n\ndaegu_gadm |&gt;\n    ggplot() +\n    geom_polygon(aes(x=long, y=lat, group=group), fill='white', color='black')\n\nRegions defined for each Polygons\n\n\n\n\n\n벌써 시각화를 할 지도의 바탕이 그려졌습니다. 이제 지도 데이터와 우리가 위에서 분석한 아파트 가격 상승 정보를 결합할 차례입니다. 여기에도 여러가지 방식이 있지만, 가장 간단한 방법 중 하나는 위의 polygon 형식의 공간 데이터를 데이터 프레임으로 강제로 변환해 준 다음 이 공간정보를 가지고 있는 데이터 프레임과 우리 분석 결과를 join해주는 것입니다.\n먼저, polygon 데이터를 데이터프레임으로 변환하는 함수로는 ggplot2의 fortify() 함수를 이용할 수 있습니다.\n\ndaegu &lt;- fortify(daegu_gadm, region=\"NL_NAME_2\")\n\nrgeos version: 0.6-4, (SVN revision 699)\n GEOS runtime version: 3.10.2-CAPI-1.16.0 \n Please note that rgeos will be retired during October 2023,\nplan transition to sf or terra functions using GEOS at your earliest convenience.\nSee https://r-spatial.org/r/2023/05/15/evolution4.html for details.\n GEOS using OverlayNG\n Linking to sp version: 1.6-0 \n Polygon checking: TRUE \n\n#daegu\n\n이렇게 강제로 변환된 데이터 프레임은 행정 구역의 위도(lat)와 경도(long), 그리고, 해당 구역의 이름(id)으로 구성되어 있습니다. id는 대구 광역시의 자치구와 자치군 이름이니, 이를 이용해 앞서 계산한 분석 결과와 연결하는 것이 가능할 것입니다. 단, 자치군구 이름에 한자 등이 섞여있으니, 연결이 가능하도록 값을 조금 수정해 주어야 하겠습니다.\n\ndaegu &lt;- daegu %&gt;%\n    mutate(district = case_when(id == \"남구 | 南區\" ~ \"남구\",\n                                id == \"달서구 | 達西區\" ~ \"달서구\",\n                                id == \"달성군 | 達城郡\" ~ \"달성군\",\n                                id == \"동구 | 東區\" ~ \"동구\",\n                                id == \"북구 | 北區\" ~ \"북구\", \n                                id == \"서구 | 西區\" ~ \"서구\",\n                                id == \"수성구 |  壽城區\" ~ \"수성구\",\n                                id == \"중구| 中區\" ~ \"중구\"))\n\n그리고 편의상, 구별-월별 평균매매가격 평균을 붙이기 보다는 1월과 12월 사이의 성장률을 다음과 같이 계산해서 join해 주도록 하겠습니다.\n\ngrowth &lt;- aggApt %&gt;%\n    group_by(district) %&gt;%\n    summarise(growth = (last(avgP) - first(avgP)) / first(avgP) * 100)\ngrowth\n\n# A tibble: 8 x 2\n  district  growth\n  &lt;chr&gt;      &lt;dbl&gt;\n1 남구      0.743 \n2 달서구   14.3   \n3 달성군   16.2   \n4 동구     -0.0971\n5 북구      7.40  \n6 서구     -6.90  \n7 수성구   -7.39  \n8 중구     -7.13  \n\n\n\ndaegu %&gt;%\n    left_join(growth, by=\"district\") %&gt;%\n    ggplot() +\n    geom_polygon(aes(x=long, y=lat, group=group, fill=growth))\n\n\n\n\n이제 지도상에 구별 연간 아파트 매매가격 평균이 표현되었습니다. 그런데 지도가 아직 너무 단순해 어떤 정보를 담고 있는지 분명치 않아 보입니다. 이해가 쉽도록 정보를 조금 더해보겠습니다. 그리고 매매 가격이 하락한 지역과 상승한 지역이 모두 푸른 색으로 표현되니 상승과 하락의 대비가 분명치 않습니다. 따라서 scale_fill_gradient2() 함수를 이용해 상승을 푸른 색으로, 하락을 붉은 색으로 표현해 보겠습니다.\n\ndaegu %&gt;%\n    left_join(growth, by=\"district\") %&gt;%\n    ggplot() +\n    geom_polygon(aes(x=long, y=lat, group=group, fill=growth), color=\"black\") +\n    labs(title=\"대구 연평균 아파트 가격 상승폭\") +\n    theme_void() +\n    theme(legend.position = \"bottom\", \n          plot.title = element_text(size=18, face=\"bold.italic\", hjust=0.5)) +\n    scale_fill_continuous(name=\"연간 가격 성장률(%)\") +\n    scale_fill_gradient2()\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n어떤가요? polygon이라는 새로운 데이터 형식만 받아들일 수 있다면, 기존에 이용해 온 ggplot2와 tidyverse의 함수들로 간단한 공간정보 활용과 지도를 이용한 시각화 역시 가능합니다. 물론, 공간 정보 분석은 너무도 방대한 분야라, 여기서 모든 내용을 다룰 수는 없고, 전문 교재를 참조하시기를 권합니다. 그러나, 일반적으로 사용하는 테크닉들 중 하나에만 익숙해지면, 우리가 엄두도 내지 못할 고급 기술만은 아닙니다."
  },
  {
    "objectID": "appendix-install.html#r-설치",
    "href": "appendix-install.html#r-설치",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.1 R 설치",
    "text": "14.1 R 설치\nR을 설치하기 위해서는 R다운로드 페이지로 이동해야 합니다.\n\n\n\nR 다운로드 페이지\n\n\n여기에서 사용하는 운영체제에 맞추어 링크를 선택합니다. 여기서는 윈도우즈 사용환경을 가정하고 ’Download R for Windows’를 클릭합니다. 그러면 다음과 같은 화면이 나타날 것입니다.\n 윈도우즈 이용자들은 두 가지를 설치해야 합니다. 하나는 ’base’라고 표시되어 있는 R프로그램 그 자체입니다. 해당 하이퍼링크를 클릭하면 이동하는 페이지에 ’Download R-4.3.1 for Windows’라고 표시된 하이퍼링크가 있을 것입니다 (4.3.1이라는 버전을 나타내는 숫자는 최신 업데이트에 따라 달라질 수 있습니다). 이를 클릭하면 다음 설치 파일이 다운로드 됩니다. 두번째로 다운로드 받을 파일은 위의 화면 캡춰에서 ’Rtools’라고 표시되어 있는 R의 확장 프로그램 입니다. 이 역시 R의 다양한 기능을 활용하기 위해서 반드시 필요합니다. 해당 링크를 클릭하여 앞서 다운 받은 R 버전에 맞는 RTools를 다운받습니다. 예컨대 앞서 R 4.3.1버전을 다운 받았으니, ’RTools 4.3’을 다운받는 것이지요.\n\n\n\n\n\n\n노트\n\n\n\n윈도우즈 사용자는 반드시 R과 RTools 모두를 설치해야 합니다.\n단, 맥 사용자는 R만 설치하면 됩니다.\n\n\n이제 두 설치파일을 다운로드 받은 순서대로 더블클릭하여 설치를 완료하면 됩니다. 여기서도, 한 가지 주의사항이 있습니다. R은 오픈소스 언어이기 때문에, 상업 프로그램처럼 다양한 언어를 부드럽게 처리하지못하는 경우가 있습니다. 관련해서 가장 많은 에러를 양산하는 문제 중 하나가 R이 설치된 경로상에 한글이 섞여 있는 경우 입니다. 예컨대, 윈도우즈의 이용자 이름이 자신의 이름으로 되어 있다면, 설치경로가 에러를 만들어 내는 경우가 많습니다. 따라서, 윈도우즈 이용자 이름에 알파벳이 아닌 다른 문자가 섞여 있다면, R 설치시 설정하는 모든 경로를 이용자 이름이 섞이지 않도록 적절하게 수정해 주는 것이 좋습니다.\n\n\n\n\n\n\n노트\n\n\n\nR 설치 경로는 알파벳만으로 이루어지도록 주의하세요."
  },
  {
    "objectID": "appendix-install.html#rstudio-설치",
    "href": "appendix-install.html#rstudio-설치",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.2 Rstudio 설치",
    "text": "14.2 Rstudio 설치\nRstudio는 오픈소스 프로젝트가 아니라 사기업인 Posit에 의해 관리되기 때문에 다운로드 및 설치가 더욱 쉽습니다. 다음 링크를 따라가서, 각자의 운영체제에 맞는 설치파일을 다운 받은 후 실행해 주면 됩니다. 다만, Rstuio의 설치는 R 설치가 모두 완료된 다음 해 주는 것이 불필요한 에러를 방지할 수 있습니다.\nR은 통계학자들이 만든 언어입니다. 원래는 S라는 유명한 Bell Lab에서 만든 상용 언어였다가, 이를 Ross Ihaka와 Robert Gentleman이라는 두 명의 뉴질랜드 교수가 뉴질랜드 오클랜드 대학에서 통계학 수업 시간에 이용할 언어로 다시 implement한 버전입니다. Implement라는 말이 이상하게 들릴 수도 있는데, 내부가 어떻게 작동하는지와는 상관 없이 같은 문법으로 작동할 수 있도록 만들었다고 생각하면 됩니다. 즉, 자동차의 부속품은 완전히 다르지만, 운전하는 방식은 완전하게 같은 두 대의 자동차를 생각하면 되겠습니다. 내부 작동 방식은 소스 코드, 이용자의 운전 방식은 implemetation이라고 간단히 생각하면 되겠습니다.\n이 두 교수는 S와는 달리 이 내부가 어떻게 작동하는지 그 설계까지 공개해 버렸습니다. 이것을 보통 컴퓨터 공학자들은 ’오픈소스로 풀었다’고 표현합니다. 더 나아가 이 설계를 조금 변경해서 자기만의 R을 만들거나 그것을 파는 것도 이론적으로 가능합니다.\nR이 ’통계학자들의 보편 언어’라고 하는 데에는 여러가지 뜻이 숨어있습니다. 먼저 통계학자들이 만든 언어라는 것은 중요합니다. 통계학자들은 수학을 그들의 언어로 사용하고 이는 중고등 교육을 받은 우리의 직관과 유사하기 때문에, 통계학자들의 머리에서 나온 이 언어는 우리의 직관에서 크게 벗어나지 않습니다. 당장, 우리가 계산기 두드리듯 식을 넣고 엔터를 치면 동작합니다.\n두번쨰로 ’보편언어’라는 말도 중요합니다. 어지간한 것은 다 된다고 봐도 무방합니다.\n설치 방법은 뒤로 돌리자!\n여기서는 R과 Rstudio를 설명하고 기본적인 용어법, 개념을 설명합니다. 다소 지루할 수 있는 내용이지만,꼭 알아야 하니 정독해 주세요!\nR은 설치도 쉽고, 간단한 이용환경을 가지고 있습니다. 프로그래밍에서 이는 통합개발환경(IDE)라고 하는데, 이는 Posithttps://posit.co/이라는 회사가 개발 및 배포하고 있습니다.\nR과 Rstudio의 관계에 대한 그림"
  },
  {
    "objectID": "appendix-install.html#r의-역사와-이용.",
    "href": "appendix-install.html#r의-역사와-이용.",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.3 R의 역사와 이용.",
    "text": "14.3 R의 역사와 이용."
  },
  {
    "objectID": "appendix-install.html#r-설치-1",
    "href": "appendix-install.html#r-설치-1",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.4 R 설치",
    "text": "14.4 R 설치\n이렇게 하면 설치가 완료됩니다."
  },
  {
    "objectID": "appendix-install.html#rstudio-설치-1",
    "href": "appendix-install.html#rstudio-설치-1",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.5 Rstudio 설치",
    "text": "14.5 Rstudio 설치"
  },
  {
    "objectID": "appendix-install.html#rstudio-환경-설명",
    "href": "appendix-install.html#rstudio-환경-설명",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.6 Rstudio 환경 설명",
    "text": "14.6 Rstudio 환경 설명"
  },
  {
    "objectID": "appendix-install.html#프로그래밍-언어의-작동과-r환경",
    "href": "appendix-install.html#프로그래밍-언어의-작동과-r환경",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.7 프로그래밍 언어의 작동과 R환경",
    "text": "14.7 프로그래밍 언어의 작동과 R환경\n\n14.7.1 변수, 함수\nR의 작동 방식을 이해하기 위해서는 다음과 같은 것들을 알아야 합니다.\n먼저 컴퓨터가 작동하는 방식에 대해서 간단하게만 알아봅시다. 컴퓨터에 데이터를 저장되는 곳은 크게 세 군데가 있습니다.\n연산장치(CPU, GPU) - 메모리 - 저장장치(HDD, SSD)\n이는 ’악마의 두뇌’를 가졌다고 일컬어지기도 하는 저 유명한 수학자 존 폰 노이만(John von Neumann; 1903-1957)이 고안해 낸 컴퓨터의 구조입니다. 여기에 대해 알고 있는 것은 앞으로 불필요한 에러를 피하는데 큰 도움이 됩니다.\n아직 소개하지 않았지만, 여러분이 사용할 데이터들은 HDD, SSD와 같은 저장 장치에 살고 있습니다. 파일을 저장한다는 행위는 여러분들도 익숙하실 것이라고 믿습니다. 여러분들이 데이터를 이용해서 어떤 계산을 하고 싶다면, 그 계산은 ’연산장치’에서 일어납니다. CPU도 아마 많이 들어보셨을테고, 최근 인공신경망(ANN)이나, 암호화폐 채굴이 CPU 대신 GPU라는 연산장치 위에서 돌아간다는 이야기도 들어보셨을 것입니다. CPU건, GPU건, 컴퓨팅이라는 것은 결국 그들이 어떤 계산을 해 주기를 바라는 것이지요.\n\n메모리 위에 쓰여진 값은 휘발한다 (전원이 꺼지면 없어진다)\n메모리 위에 쓰여진 값은 이름이 없으면 없는 것이나 다름 없다\n\n문제는 저장장치에 있는 데이터를 연산장치가 바로 사용하는 것이 아니라는 것입니다. 연산장치가 계산을 하기 위해서는 중간 단계에 해당하는 메모리 위에 값이 기록되어야 합니다. 그리고 아마도 여러분들이 알고 계실 것처럼, 메모리에 기록된 데이터는 휘발합니다. 즉, 컴퓨터 전원이 꺼지면 없어지는 것이죠. 이 때문에 저장장치들이 필요합니다.\n그런데, 메모리에 대해서는 그것 말고도 알아야 하는 것이 있습니다. 메모리 위에 기록된 값은 ’이름’이 없으면 존재하지 않는 것이나 다름 없다는 사실입니다. 이게 무슨 말인지 알기 위해 다음과 같은 예를 살펴 봅시다.\n\n3+4\n\n[1] 7\n\n\n이러한 연산이 이루어지기 위해서는 3이라는 ’값’과 4라는 ’값’이 메모리에 먼저 기록되어야 합니다. 그 다음에 연산 장치가 메모리에 저장된 두 값을 더하는 ’연산’을 해 준 후, 그 결과 값이 7을 메모리 위에 기록합니다. 우리는 메모리 위에 기록된 결과를 모니터를 통해 보는 셈입니다. 그런데, 문제는 3, 4, 7이라는 모든 값에 별도의 이름을 붙이지 않았다는 것이지요. 앞서 말했듯이 ’이름’이 없는 값은 존재하지 않는 것이나 다름 없습니다. 따라서, 우리는 메모리에 쓰여진 이 값들을 다시 사용할 수 없습니다. 모니터에서 한 번 확인하고 날려보낸 것입니다.\n이는 반대로 이야기 하면, 이름을 부여한다면, 적어도 이름을 부여하는 프로그램, 즉 우리의 경우 R을 켜 놓은 동안은 재사용할 수 있다는 것입니다. 위의 프로그램을 다시 써 보죠.\n\na &lt;- 3\nb &lt;- 4\nc &lt;- a + b\nprint(c)\n\n[1] 7\n\n\n모니터에서 확인하는 결과는 같습니다. 그러나 우리는 몇 가지 작업을 더 했는데요, 3과 4를 각각 a와 b라는 이름에 할당(assign) 했습니다. 이름을 부여한 것이지요. 또 a에 해당하는 값과 b에 해당하는 값을 더한 결과 역시 c라는 이름에 할당했습니다. 이제 이 값들은 이름이 있으니 R을 켜둔 동안은 다시 불러 사용할 수 있는 것입니다.\n\na * b\n\n[1] 12\n\n\n이제 앞으로 사용할 몇 가지 용어를 정의하도록 하죠. - 값(value): 데이터 그 자체 - 변수(variable): 거기에 붙은 이름 - 할당(assign): 값을 변수로 만드는 행위. R에서는 &lt;- 부호를 사용함. (사실은 =을 사용할 수도 있지만, 구분하겠습니다.)\n그림\n사람의 언어에 비유해서 설명하자면, 값과 변수는 명사, 또는 목적어에 해당합니다. 많은 경우에는 이렇게 주어진 대상에 어떤 행위를 하고 싶어하지요. 우리는 그것을 연산이라고 합니다. 그리고 그러한 연산을 문법으로 표현한 것을 함수(function)라고 하지요. 인간의 언어에서라면 함수는 동사에 해당합니다.\n그림\n우리는 위의 예에서 이미 함수를 보았습니다. print()가 그것입니다. 이것은 주어진 값을 콘솔에 출력하는 동작을 의미하는 것이니 동사라고 할 수 있습니다. 그러면 동사와 명사를 구분하듯, R에서 변수와 함수를 구분할 수 있을까요? 구분할 수 있습니다. 여러 방법이 있지만, 가장 간단한 방법은 문자열 뒤에 괄호가 있는지 보는 것입니다. 변수는 괄호가 없습니다. 하지만, 함수는 print()처럼 괄호가 있지요.\n괄호는 왜 있는 것일까요? 괄호 안에 무언가를 써넣어야 하기 때문입니다. 즉, 함수가 표현하는 행위의 대상이 되는 목적어를 집어 넣어야 하기 때문이죠. 예컨대 print(c)에서 c라는 변수는 바로 그 목적어에 해당하요. 앞서 값이나 변수가 목적어의 역할을 하게 될 것이라고 했던 것을 기억할 것입니다. print(c)를 사람의 언어로 표현하면 다음과 같습니다.\n\nc를 콘솔에 print()하라.\n\n그림 (변수, 함수)\n이렇게 값이나 변수가 함수가 하는 연산의 대상이 되면, 즉, 함수의 괄호 안에 들어가면, 이를 입력값(input), 또는 인수(argument)라고 합니다. 입력값을 받았으니 함수는 연산의 결과로 출력값(output)을 내어놓겠지요. 사실 더 정확한 표현은 다음과 같습니다.\n\nprint(x=c)\n\n[1] 7\n\n\n여기서 x는 print()라는 함수의 매개변수(parameter), c는 그 매개변수에 집어넣은 인수, 또는 입력값입니다. 매개변수는 print()라는 함수가 그 내부에서 사용하는 변수입니다. print()라는 함수는 내부에서 x라는 변수를 이용해 행위를 하지, c라는 함수 밖에 존재하는 변수에 대해서는 알지 못합니다. 그런데 x=c라고 하는 순간, 이용자는 함수에게 “네가 이용할 x가 바로 바로 c라는 변수에 들어있는 값이야”라고 연결해 주는 것입니다.\n그림 (x=c)\n그러면 print()는 자신이 이용하는 x라는 그릇에 c에 이미 연결되어 있는 값을 담고 그것을 출력하는 행위를 하게 됩니다.\n그런데 왜 첫번째 예에서는 x=을 생략하고 print(c)라고 했는데도 작동했을까요? 그것은 print() 함수 자체가 첫번째로 입력한 숫자를 x에 대응하는 인수로 자동으로 인식하도록 프로그램 되어 있기 때문입니다. 무언가를 출력하라고 하는 명령은 수없이 사용하게 될텐대, 매번 매개변수를 반복행 하면 너무 귀찮겠지요.\n그런데, 모든 함수가 인수를 필요로 하는 것은 아닙니다. 자연언어에서 동사 역시 자동사와 타동사로 구분되는 것과 같은 이치입니다. 예컨대 다음과 같은 함수는 인수 없이 실행 됩니다.\n\ngetwd()\n\ngetwd()라는 함수가 working directory 즉, 현재 R이 작업을 하고 있는 컴퓨터의 경로를 표시하는 동작을 의미하니, 인수가 따로 필요하지는 않겠지요. 어떤 경우에는 함수가 인수를 필요로 하지만 (즉, 타동사 이지만), 인수를 쓰지 않아도 작동하는 경우가 있습니다. 그런 경우에는 함수가 자신이 필요로 하는 인수에 대해 디폴트 값을 가지고 있는 경우 입니다. 즉, 사용자가 아무 인수도 주지 않으면 자동으로 인수로 가정하는 값이 있는 경우도 있다는 것입니다. 우리가 “밥 먹어”하는 대신 상대방이 알아들을만 한 상황에서는 “먹어”라고 하는 것과 비슷한 이치입니다.\ngetwd()라는 함수가 working directory 즉, 현재 R이 작업을 하고 있는 컴퓨터의 경로를 표시하는 동작을 의미하니, 인수가 따로 필요하지는 않겠지요. 어떤 경우에는 함수가 인수를 필요로 하지만 (즉, 타동사 이지만), 인수를 쓰지 않아도 작동하는 경우가 있습니다. 그런 경우에는 함수가 자신이 필요로 하는 인수에 대해 디폴트 값을 가지고 있는 경우 입니다. 즉, 사용자가 아무 인수도 주지 않으면 자동으로 인수로 가정하는 값이 있는 경우도 있다는 것입니다. 우리가 “밥 먹어”하는 대신 상대방이 알아들을만 한 상황에서는 “먹어”라고 하는 것과 비슷한 이치입니다.\n\n\n14.7.2 경로\n앞서 작업폴더(working directory) 이야기를 했는데요, 이것은 무슨 의미일까요? 작업폴더는 현재 R이 자신이 위치하고 있다고 생각하는 저장장치 안의 폴더를 의미합니다. 보통은 지금 작성하고 있는 코드가 저장되어 있는 곳이 작업폴더가 되지만, 이는 경우에 따라 다릅니다. 그래서 앞에서처럼 getwd()를 이용해 현재 작업 폴더가 어디인지 확인하는 것이지요.\n작업폴더가 중요한 이유는, 저장장치로부터 R이 데이터를 불러올 때, 특별한 이야기가 없으면 작업폴더로부터 불러와야 한다고 생각하기 때문입니다. 하지만, R이 현재 작업폴더로 이용하고 있는 장소와 이용자가 작업폴더라고 믿고 있는 장소 사이에 차이가 있는 경우가 종종 있습니다. 프로그래밍을 처음 해 보시는 분들이 처음에 제일 많이 겪는 에러의 원인입니다. 만약 이런 차이가 발생한다면, 해법은 세 가지가 있습니다. 첫째, R에게 작업폴더를 바꿀 것을 지시하면 됩니다.\n\nsetwd()\n\n둘째, 불러올 데이터가 저장되어 있는 곳을 자세하게 알려주면 됩니다. 나중에 더 자세히 설명하겠지만, 다음과 같은 명령어를 볼까요?\n\nread.csv(\"\")\n\n이는 저 파일(csv라는 확장자를 처음 보신 분들은 나중에 배우게 될테니, 일단 엑셀 파일보다 간단한 형태의 테이블 데이터 파일이라고 생각해 주세요)이 있을 경우에 파일을 불러들여서 콘솔에 출력할 것입니다 (quiz: 그렇다면 이 데이터는 우리가 앞으로 분석에 사용할 수 있는 것일까요? 아까 이름과 메모리에 대해 이야기 했던 것을 떠올려 보세요).\n하지만, 해당 작업폴더에 저장되어있지 않은 데이터 파일을 불러오려고 하면, R은 에러를 뱉어낼 것입니다.\n\nread.csv(\"\")\n\n이 때, 이렇게 써 보세요.\n\nread.csv(\"/\")\n\n이것이 작동한 이유는 현재 작업폴더 아래에 있는 폴더 안에 파일이 저장되어 있기 때문입니다. 이렇게 파일로 가는 길을 경로(path)라고 표현하고, 특히 위의 예에서처럼 현재 작업폴더를 기준으로 경로를 설정해 주는 것을 상대경로라고 표현합니다. 상대경로가 있으면, 절대경로가 있겠지요? 다음과 같은 경우를 절대경로라고 합니다.\n\nread.csv(\"C:/\")\n\n즉, 가장 높은 폴더, 흔히 루트 디렉토리라고 부르는 장소에서부터 원하는 폴더까지 이동하는 경로를 완전히 알려주는 방식이지요.\n사실 가장 권장하는 방식은 세번째 방식입니다. 프로젝트라고 부르는 이 방식은 R의 기능을 활용하는 것이라기 보다는 Rstudio의 기능을 활용한 방식인데요, 가장 에러를 효과적으로 최소화하는 방식이라고 할 수 있습니다.\n\n\n14.7.3 프로젝트"
  },
  {
    "objectID": "appendix-install.html#그-외-권장사항",
    "href": "appendix-install.html#그-외-권장사항",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.8 그 외 권장사항",
    "text": "14.8 그 외 권장사항\n프로젝트 말고도 앞으로의 학습을 위해 지키면 좋을 권장사항들이 있습니다. ### 한글 설정 R은 다른 많은 프로그래밍 언어들과 마찬가지로 영어권에서 개발되고 오랫동안 사용되어 왔기 때문에, 한글을 포함한 데이터를 다룰 때 자잘한 문제들을 발생시키게 됩니다. 앞서 프로젝트를 이용해서 제어하기로 한 경로 문제만큼이나 초보자에게 많은 에러를 안겨주는 이유 중 하나가 바로 이 언어의 문제 입니다. 이는 정확한 표현으로는 인코딩 문제라고 하는데, 인코딩은 사람이 읽을 수 있는 자연 언어를 컴퓨터가 이해하는 유일한 정보인 0,1로 이루어진 이진수로 바꾸는 과정을 의미합니다. 문제는 이러한 인코딩 방식이 무수히 많다는 것입니다. 예컨대 예전에 주로 사용하던 인코딩 방식은 알파벳 이외의 문자를 이진수로 바꾸는 룰을 포함하지 않고 있기도 했습니다. 여기서 발생하는 문제를 최소화하기 위해 다음과 같은 설정을 해 줄 것을 권합니다.\n\nSys.setlocale(\"LC_ALL\", \"Korean\")\n\n[1] \"LC_COLLATE=Korean_Korea.949;LC_CTYPE=Korean_Korea.949;LC_MONETARY=Korean_Korea.949;LC_NUMERIC=C;LC_TIME=Korean_Korea.949\"\n\n\n이렇게 하면 R의 언어 설정이 바뀌면서 한글을 올바르게 출력하게 됩니다. 덤으로 에러 메시지도 한글로 바뀌지요. 그런데 에러 메시지가 한글로 나오는 것은 장점이 되기도, 단점이 되기도 합니다. 왜냐하면, 여러분이 이해할 수 없는 에러가 발생하면, 인터넷에서 해결책을 검색해야 하는데, 영어로 된 정보의 질이 압도적으로 좋기 때문입니다. 영어 에러 메시지를 이용해 해법을 검색하면 영어 이용자가 작성한 답변을 검색할 수 있지만, 한글 에러 메시지를 이용해 검색하게 되면 이용할 수 있는 정보의 풀이 크게 줄어들게 됩니다. 이 경우, 언어 세팅을 다시 영어로 돌려놓고 싶을 수 있겠지요. 그럴 때는 다음과 같은 명령어를 실행시킵니다.\n\nSys.setlocale(\"LC_ALL\", \"C\")\n\n[1] \"C\"\n\n\n또 하나 주의해야 할 것은, 이 혼경설정은 여러분이 코딩을 마치고 Rstudio를 끄는 순간 날아가버린다는 것입니다. 따라서 한글 데이터를 다룰 때에는 코딩을 시작하기 전에 이 세팅을 먼저 해 주는 것이 좋습니다.\n\n14.8.1 숫자 표시 설정\nR은 애초에 우리와 같은 문과생들이 이용하라고 만든 언어가 아닙니다. 그래서 우리의 머리로써는 이해하기 힘든 초기 설정을 가지고 있는 경우가 종종 있는데요, 그 중 대표적인 것이 숫자 표시 설정입니다. 많은 분들이 아시겠지만, 공학에서는 숫자를 과학적 기수법 이라는 것을 통해 표시하는 경우가 많습니다.\n그림\n이는 공학에서 너무 작거나, 너무 큰 수를 다루어야 하는 경우가 많다보니, 숫자를 길게 쓰는 수고를 줄이고자 도입된 것입니다. 그러나 이러한 표기법에 익숙한 우리나, 우리가 작성한 기사를 읽을 독자 중 다수는 이러한 표기법에 익숙하지 못할 것입니다. 따라서 다음과 같은 명령어를 실행시켜 숫자 표시 설정을 바꾸어주는 것이 좋습니다.\n\noptions(scipen=999)\n\n사실 위의 명령어에 들어가는 숫자는 999자리 이상이 아니면 과학적 기수법을 사용하지 말라는 것이니꼭 999이어야 하는 것은 아닙니다. 충분히 큰 수이면 됩니다. 이 설정 역시 Rstudio를 끄는 순간 메모리에서 지워지니, 코딩을 시작하실 때마다 다시 설정해주시는 것이 좋습니다.\n\n\n14.8.2 에러 메시지 읽기\n사실 에러 메시지는 매우 중요한 정보들을 담고 있습니다. 에러 메시지를 얼마나 정성들여 읽느냐에 따라 코딩 실력이 느는 속도가 천차만별로 차이가 나게 되니, 꼭 에러 메시지를 소중하게 읽기를 권합니다."
  },
  {
    "objectID": "appendix-install.html#마크다운과-마크업",
    "href": "appendix-install.html#마크다운과-마크업",
    "title": "14  부록: R과 Rstudio 설치하기",
    "section": "14.9 마크다운과 마크업",
    "text": "14.9 마크다운과 마크업\n사실 “마크다운”이라는 용어는 일종의 말장난입니다. 원래는 “마크업(markup)”이라는 용어가 먼저 있었지요. 마크업이라는 것은 일반 텍스트에 “여러 표시를 해서(mark up)”, 텍스트에 여러 효과와 형식을 부여하는 문법을 의미합니다. 가장 대표적인 예가 바로 HTML 이죠.\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n\n&lt;h1&gt; 이것은 제목 입니다&lt;/h1&gt;\n\n&lt;p&gt; 이것은 문단 입니다 &lt;/p&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n여기에 쓰여진 “이것은 제목 입니다”, “이것은 문단 입니다” 등의 텍스트들은 바로 우리가 전달하고 싶은 텍스트 정보 입니다. 하지만 효율적으로 이를 독자들에게 전달하기 위해서는 약간의 양식이 있으면 좋겠죠. 따라서 제목은 제목처럼 보이게 문단은 문단처럼 보이게 하는 양식 정보를 전달하는 것이 ’\n\n\n‘,’\n\n\n’ 같은 HTML 문법입니다. 구글 크롬, 마이크로소프트 엣지 같은 웹브라우저는 이러한 양식을 이해해서 이용자에게 텍스트를 그대로 전달하는 것이 아니라, 양식이 부여된 텍스트 시각화해서(이를 “Render”라고 합니다) 보여주는 역할을 합니다.\n사실 이렇게 텍스트에다 여러 양식정보를 부가하는(즉, 마크업하는) 문법은 HTML말고도 여러개가 있습니다. 이들을 통틀어 ’마크업 언어’라고 하지요. 그런데, 위의 HTML 문서에서 알 수 있듯이, 단 두문장을 전달하는 데에도 사용해야 할 문법이 꽤나 복잡하고 많습니다. 이 때문에 개발자들은 텍스트에 양식을 부과하되, 사람이 직관적으로 이해할 수 있는 좀 간단한 문법이 없을까? 라는 생각을 하게되었습니다. 그 결과물이 바로 ’마크다운’이지요, 즉, 마크’업’이 너무 복잡해서 간단하게 만든 새로운 마크업 문법이 마크’다운’이라는 것입니다.\n이제 간단한 마크다운 문법을 알면 이용자는 HTML 같이 복잡한 마크업 문법을 몰라도 웹페이지를 간단하게 만들 수 있습니다. Rstudio가 내장하고 있는 프로그램이 마크다운 문서를 HTML로 다시 재번역해 주거든요(그것이 여러분이 Rstudio에서 이용하는 Render 버튼의 의미입니다). 여러분들이 매일 이용하는 웹브라우저는 이렇게 번역된 HTML을 이해할 수 있으니 여러분은 뉴스 작성을 위해 HTML을 따로 공부할 필요가 없습니다.\n마크업 -&gt; pandoc -&gt; HTML -&gt; 웹브라우저\n명심하세요! 여러분들은 이 책을 통해 연습을 하는 동안 항상 qmd 파일을 하나 만들어 마크다운 문법을 이요해 코드와 텍스트를 동시에 작성하고 이를 HTML로 렌더하는 작업을 반복할 것입니다. 그 외에도 R을 사용하는 여러 방법이 있지만, 일단 가장 쉽고 기사 작성을 위해 유용한 이 방법을 반복해서 사용하세요!"
  }
]